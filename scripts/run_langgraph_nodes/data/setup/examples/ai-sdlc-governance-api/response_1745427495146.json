{
  "repo_url": "https://github.com/DEFRA/ai-sdlc-governance-api",
  "file_structure": "├── compose/\n│   ├── aws.env\n│   └── start-localstack.sh\n├── defra-ai-sdlc-playbook/\n├── docs/\n│   ├── checklist-item-ordering.md\n│   └── workflow-ordering.md\n├── governance-admin-vault/\n├── scripts/\n│   ├── migrations/\n│   │   ├── add-checklist-item-order.js\n│   │   └── add-workflow-order.js\n│   ├── git_cleanup.sh\n│   ├── manage-mongodb.js\n│   └── start_dev_server.sh\n├── src/\n│   ├── api/\n│   │   ├── checklist-item-instances/\n│   │   │   ├── controller.js\n│   │   │   ├── index.js\n│   │   │   ├── model.js\n│   │   │   └── validation.js\n│   │   ├── checklist-item-templates/\n│   │   │   ├── controller.js\n│   │   │   ├── index.js\n│   │   │   ├── model.js\n│   │   │   └── validation.js\n│   │   ├── common/\n│   │   │   ├── constants/\n│   │   │   │   └── status-codes.js\n│   │   │   └── helpers/\n│   │   │       ├── logging/\n│   │   │       │   ├── logger-options.js\n│   │   │       │   ├── logger.js\n│   │   │       │   └── request-logger.js\n│   │   │       ├── migrations/\n│   │   │       │   └── index.js\n│   │   │       ├── proxy/\n│   │   │       │   ├── setup-proxy.js\n│   │   │       │   └── setup-proxy.test.js\n│   │   │       ├── secure-context/\n│   │   │       │   ├── get-trust-store-certs.js\n│   │   │       │   ├── get-trust-store-certs.test.js\n│   │   │       │   ├── index.js\n│   │   │       │   ├── secure-context.js\n│   │   │       │   └── secure-context.test.js\n│   │   │       ├── fail-action.js\n│   │   │       ├── fail-action.test.js\n│   │   │       ├── metrics.js\n│   │   │       ├── metrics.test.js\n│   │   │       ├── mongo-lock.js\n│   │   │       ├── mongo-lock.test.js\n│   │   │       ├── mongodb.js\n│   │   │       ├── mongodb.test.js\n│   │   │       ├── pulse.js\n│   │   │       ├── request-tracing.js\n│   │   │       ├── start-server.js\n│   │   │       └── start-server.test.js\n│   │   ├── example/\n│   │   │   ├── controllers/\n│   │   │   │   ├── example-find-all.js\n│   │   │   │   ├── example-find-all.test.js\n│   │   │   │   ├── example-find-one.js\n│   │   │   │   ├── example-find-one.test.js\n│   │   │   │   └── index.js\n│   │   │   ├── helpers/\n│   │   │   │   ├── find-all-example-data.js\n│   │   │   │   └── find-example-data.js\n│   │   │   ├── README.md\n│   │   │   └── index.js\n│   │   ├── governance-templates/\n│   │   │   ├── controller.js\n│   │   │   ├── index.js\n│   │   │   ├── model.js\n│   │   │   └── validation.js\n│   │   ├── health/\n│   │   │   ├── controller.js\n│   │   │   ├── controller.test.js\n│   │   │   └── index.js\n│   │   ├── projects/\n│   │   │   ├── controller.js\n│   │   │   ├── index.js\n│   │   │   ├── model.js\n│   │   │   └── validation.js\n│   │   ├── workflow-instances/\n│   │   │   ├── controller.js\n│   │   │   ├── index.js\n│   │   │   ├── model.js\n│   │   │   └── validation.js\n│   │   ├── workflow-templates/\n│   │   │   ├── controller.js\n│   │   │   ├── index.js\n│   │   │   ├── model.js\n│   │   │   └── validation.js\n│   │   ├── index.js\n│   │   └── router.js\n│   ├── config/\n│   │   └── index.js\n│   └── index.js\n├── test_data/\n│   └── mongodb_dumps/\n│       └── test_governance_template.json\n├── tests/\n│   └── api/\n│       ├── checklist-item-templates.spec.js\n│       ├── governance-templates.spec.js\n│       ├── project-crud.spec.js\n│       └── workflow-templates.spec.js\n├── Dockerfile\n├── LICENCE\n├── README.md\n├── babel.config.cjs\n├── compose.yml\n├── jest-mongodb-config.cjs\n├── jest.config.js\n├── nodemon.json\n├── package.json\n├── playwright.config.js\n├── sonar-project.properties\n├── tsconfig.json\n└── tsconfig.test.json",
  "languages_used": [
    "javascript"
  ],
  "ingested_repo_chunks": [
    {
      "chunk_id": "governance_template_management",
      "description": "Functionality for creating, retrieving, updating, and deleting governance templates",
      "files": [
        "src/api/governance-templates/controller.js",
        "src/api/governance-templates/index.js",
        "src/api/governance-templates/model.js",
        "src/api/governance-templates/validation.js",
        "tests/api/governance-templates.spec.js"
      ],
      "content": "\n\n--- src/api/governance-templates/controller.js ---\nimport { createGovernanceTemplate } from './model.js'\nimport Boom from '@hapi/boom'\nimport { ObjectId } from 'mongodb'\n\nexport const createGovernanceTemplateHandler = async (request, h) => {\n  try {\n    const template = createGovernanceTemplate(request.payload)\n    const result = await request.db\n      .collection('governanceTemplates')\n      .insertOne(template)\n    return h.response({ ...template, _id: result.insertedId }).code(200)\n  } catch (error) {\n    if (error.code === 11000) {\n      throw Boom.conflict(\n        'A template with this name and version already exists'\n      )\n    }\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getGovernanceTemplateHandler = async (request, h) => {\n  try {\n    const template = await request.db\n      .collection('governanceTemplates')\n      .findOne({ _id: new ObjectId(request.params.id) })\n\n    if (!template) {\n      throw Boom.notFound('Governance template not found')\n    }\n    return h.response(template).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const updateGovernanceTemplateHandler = async (request, h) => {\n  try {\n    const now = new Date()\n    const result = await request.db\n      .collection('governanceTemplates')\n      .findOneAndUpdate(\n        { _id: new ObjectId(request.params.id) },\n        { $set: { ...request.payload, updatedAt: now } },\n        { returnDocument: 'after' }\n      )\n\n    if (!result) {\n      throw Boom.notFound('Governance template not found')\n    }\n    return h.response(result).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    if (error.code === 11000) {\n      throw Boom.conflict(\n        'A template with this name and version already exists'\n      )\n    }\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const deleteGovernanceTemplateHandler = async (request, h) => {\n  try {\n    const governanceId = new ObjectId(request.params.id)\n\n    // Find all workflow templates for this governance template\n    const workflowTemplates = await request.db\n      .collection('workflowTemplates')\n      .find({ governanceTemplateId: governanceId })\n      .toArray()\n\n    // Delete all associated checklist items for each workflow template\n    for (const workflow of workflowTemplates) {\n      await request.db\n        .collection('checklistItemTemplates')\n        .deleteMany({ workflowTemplateId: workflow._id })\n    }\n\n    // Delete all workflow templates\n    await request.db\n      .collection('workflowTemplates')\n      .deleteMany({ governanceTemplateId: governanceId })\n\n    // Delete the governance template\n    const result = await request.db\n      .collection('governanceTemplates')\n      .deleteOne({ _id: governanceId })\n\n    if (result.deletedCount === 0) {\n      throw Boom.notFound('Governance template not found')\n    }\n\n    return h.response().code(204)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getAllGovernanceTemplatesHandler = async (request, h) => {\n  try {\n    const templates = await request.db\n      .collection('governanceTemplates')\n      .find({})\n      .sort({ createdAt: -1 })\n      .toArray()\n\n    // For each governance template, fetch and include its workflow templates\n    for (const template of templates) {\n      const workflowTemplates = await request.db\n        .collection('workflowTemplates')\n        .find({ governanceTemplateId: template._id })\n        .sort({ order: 1 }) // Sort by order field (ascending)\n        .toArray()\n\n      // Add the sorted workflow templates to the governance template\n      template.workflowTemplates = workflowTemplates\n    }\n\n    return h.response(templates).code(200)\n  } catch (error) {\n    throw Boom.badRequest(error.message)\n  }\n}\n\n\n--- src/api/governance-templates/index.js ---\nimport {\n  createGovernanceTemplateHandler,\n  getGovernanceTemplateHandler,\n  updateGovernanceTemplateHandler,\n  deleteGovernanceTemplateHandler,\n  getAllGovernanceTemplatesHandler\n} from './controller.js'\nimport {\n  createGovernanceTemplateSchema,\n  updateGovernanceTemplateSchema,\n  idSchema\n} from './validation.js'\nimport Joi from 'joi'\n\n// Define the workflow template schema for inclusion in the governance template response\nconst workflowTemplateSchema = Joi.object({\n  _id: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .description('MongoDB ObjectId')\n    .example('60d21bbfe3d5d533d9fc1e4c'),\n  governanceTemplateId: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .description('MongoDB ObjectId')\n    .example('60d21bbfe3d5d533d9fc1e4d'),\n  name: Joi.string().example('Model Development Workflow'),\n  description: Joi.string().example(\n    'Workflow for developing and validating AI models'\n  ),\n  metadata: Joi.object().example({\n    priority: 'high',\n    category: 'development'\n  }),\n  order: Joi.number().integer().min(0).example(1),\n  createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n  updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n})\n\nconst governanceTemplateResponseSchema = Joi.object({\n  _id: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .description('MongoDB ObjectId')\n    .example('60d21bbfe3d5d533d9fc1e4c'),\n  version: Joi.string().example('1.0.0'),\n  name: Joi.string().example('AI Model Governance'),\n  description: Joi.string().example(\n    'Governance template for AI model development and deployment'\n  ),\n  createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n  updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n  workflowTemplates: Joi.array()\n    .items(workflowTemplateSchema)\n    .description('Workflow templates sorted by order')\n})\n\n/**\n * @type { import('@hapi/hapi').Plugin<void> }\n */\nexport default {\n  name: 'governance-template-routes',\n  register: (server) => {\n    server.route([\n      {\n        method: 'POST',\n        path: '/api/v1/governance-templates',\n        handler: createGovernanceTemplateHandler,\n        options: {\n          tags: ['api', 'governance-template'],\n          description: 'Create a new governance template',\n          validate: {\n            payload: createGovernanceTemplateSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully created governance template',\n                  schema: governanceTemplateResponseSchema\n                },\n                400: { description: 'Bad request' },\n                409: {\n                  description:\n                    'Template with this name and version already exists'\n                }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/governance-templates/{id}',\n        handler: getGovernanceTemplateHandler,\n        options: {\n          tags: ['api', 'governance-template'],\n          description: 'Get a governance template by ID',\n          validate: {\n            params: idSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully retrieved governance template',\n                  schema: governanceTemplateResponseSchema\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'PUT',\n        path: '/api/v1/governance-templates/{id}',\n        handler: updateGovernanceTemplateHandler,\n        options: {\n          tags: ['api', 'governance-template'],\n          description: 'Update a governance template',\n          validate: {\n            params: idSchema,\n            payload: updateGovernanceTemplateSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully updated governance template',\n                  schema: governanceTemplateResponseSchema\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' },\n                409: {\n                  description:\n                    'Template with this name and version already exists'\n                }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'DELETE',\n        path: '/api/v1/governance-templates/{id}',\n        handler: deleteGovernanceTemplateHandler,\n        options: {\n          tags: ['api', 'governance-template'],\n          description: 'Delete a governance template',\n          validate: {\n            params: idSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                204: {\n                  description: 'Successfully deleted governance template'\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/governance-templates',\n        handler: getAllGovernanceTemplatesHandler,\n        options: {\n          tags: ['api', 'governance-template'],\n          description:\n            'Get all governance templates with their workflow templates sorted by order',\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description:\n                    'Successfully retrieved governance templates with sorted workflow templates',\n                  schema: Joi.array().items(governanceTemplateResponseSchema)\n                },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      }\n    ])\n  }\n}\n\n\n--- src/api/governance-templates/model.js ---\n/**\n * @typedef {object} GovernanceTemplate\n * @property {import('mongodb').ObjectId} _id - The unique identifier\n * @property {string} version - The version of the template (required)\n * @property {string} name - The name of the template (required)\n * @property {string} [description] - The description of the template\n * @property {Date} createdAt - When the template was created (required)\n * @property {Date} updatedAt - When the template was last updated (required)\n */\n\n/**\n * Creates a new governance template\n * @param {object} data - The template data\n * @param {string} data.version - The version of the template\n * @param {string} data.name - The name of the template\n * @param {string} [data.description] - The description of the template\n * @returns {Omit<GovernanceTemplate, '_id'>}\n */\nexport function createGovernanceTemplate(data) {\n  const now = new Date()\n  return {\n    version: data.version,\n    name: data.name,\n    description: data.description,\n    createdAt: now,\n    updatedAt: now\n  }\n}\n\n\n--- src/api/governance-templates/validation.js ---\nimport Joi from 'joi'\nimport { ObjectId } from 'mongodb'\n\n// Custom Joi extension for MongoDB ObjectId validation\nconst objectIdSchema = Joi.string().custom((value, helpers) => {\n  if (!ObjectId.isValid(value)) {\n    return helpers.error('any.invalid')\n  }\n  return value\n}, 'MongoDB ObjectId validation')\n\nexport const createGovernanceTemplateSchema = Joi.object({\n  version: Joi.string().required(),\n  name: Joi.string().required(),\n  description: Joi.string().allow('')\n})\n\nexport const updateGovernanceTemplateSchema = Joi.object({\n  version: Joi.string(),\n  name: Joi.string(),\n  description: Joi.string().allow('')\n})\n\nexport const idSchema = Joi.object({\n  id: objectIdSchema.required().description('MongoDB ObjectId')\n})\n\n\n--- tests/api/governance-templates.spec.js ---\nimport { test, expect } from '@playwright/test'\n\nconst getUniqueId = () =>\n  `test_${Date.now()}_${Math.random().toString(36).substring(2, 7)}`\n\nconst createGovernanceTemplate = (uniqueId) => ({\n  name: `Test Governance Template ${uniqueId}`,\n  version: '1.0.0',\n  description: 'Test governance template for E2E testing'\n})\n\ntest.describe('Governance Template API', () => {\n  let governanceTemplateId\n  const uniqueId = getUniqueId()\n  const governanceTemplate = createGovernanceTemplate(uniqueId)\n\n  test.afterAll(async ({ request }) => {\n    if (governanceTemplateId) {\n      await request.delete(\n        `/api/v1/governance-templates/${governanceTemplateId}`\n      )\n    }\n  })\n\n  test('should create a new governance template', async ({ request }) => {\n    const response = await request.post('/api/v1/governance-templates', {\n      data: governanceTemplate\n    })\n\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    expect(data).toHaveProperty('_id')\n    expect(data.name).toBe(governanceTemplate.name)\n    expect(data.version).toBe(governanceTemplate.version)\n    expect(data.description).toBe(governanceTemplate.description)\n\n    governanceTemplateId = data._id\n  })\n\n  test('should get a governance template by id', async ({ request }) => {\n    const response = await request.get(\n      `/api/v1/governance-templates/${governanceTemplateId}`\n    )\n\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    expect(data._id).toBe(governanceTemplateId)\n    expect(data.name).toBe(governanceTemplate.name)\n  })\n\n  test('should update a governance template', async ({ request }) => {\n    const updatedTemplate = {\n      ...governanceTemplate,\n      description: 'Updated description'\n    }\n\n    const response = await request.put(\n      `/api/v1/governance-templates/${governanceTemplateId}`,\n      {\n        data: updatedTemplate\n      }\n    )\n\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    expect(data.description).toBe(updatedTemplate.description)\n  })\n\n  test('should cascade delete workflow templates and checklist items when deleting governance template', async ({\n    request\n  }) => {\n    const cascadeUniqueId = getUniqueId()\n    // Create a new governance template specifically for testing deletion\n    const govResponse = await request.post('/api/v1/governance-templates', {\n      data: {\n        name: `Cascade Delete Test Template ${cascadeUniqueId}`,\n        version: '2.0.0',\n        description: 'Testing cascade deletion'\n      }\n    })\n    expect(govResponse.ok()).toBeTruthy()\n    const cascadeGovId = (await govResponse.json())._id\n\n    // Create multiple workflow templates\n    const workflowIds = []\n    const checklistIds = []\n\n    for (let i = 0; i < 2; i++) {\n      const workflowResponse = await request.post(\n        '/api/v1/workflow-templates',\n        {\n          data: {\n            name: `Workflow Template ${cascadeUniqueId}-${i}`,\n            description: 'Testing cascade deletion',\n            governanceTemplateId: cascadeGovId,\n            metadata: { test: true }\n          }\n        }\n      )\n      expect(workflowResponse.ok()).toBeTruthy()\n      const workflowId = (await workflowResponse.json())._id\n      workflowIds.push(workflowId)\n\n      // Create checklist items for each workflow\n      for (let j = 0; j < 2; j++) {\n        const checklistResponse = await request.post(\n          '/api/v1/checklist-item-templates',\n          {\n            data: {\n              name: `Checklist Template ${cascadeUniqueId}-${i}-${j}`,\n              description: 'Testing cascade deletion',\n              type: 'approval',\n              workflowTemplateId: workflowId,\n              dependencies_requires: []\n            }\n          }\n        )\n        expect(checklistResponse.ok()).toBeTruthy()\n        checklistIds.push((await checklistResponse.json())._id)\n      }\n    }\n\n    // Delete the governance template\n    const deleteResponse = await request.delete(\n      `/api/v1/governance-templates/${cascadeGovId}`\n    )\n    expect(deleteResponse.ok()).toBeTruthy()\n\n    // Verify that all workflow templates have been deleted\n    for (const workflowId of workflowIds) {\n      const workflowResponse = await request.get(\n        `/api/v1/workflow-templates/${workflowId}`\n      )\n      expect(workflowResponse.ok()).toBeFalsy()\n      expect(workflowResponse.status()).toBe(404)\n    }\n\n    // Verify that all checklist items have been deleted\n    for (const checklistId of checklistIds) {\n      const checklistResponse = await request.get(\n        `/api/v1/checklist-item-templates/${checklistId}`\n      )\n      expect(checklistResponse.ok()).toBeFalsy()\n      expect(checklistResponse.status()).toBe(404)\n    }\n  })\n})\n"
    },
    {
      "chunk_id": "workflow_template_management",
      "description": "Functionality for managing workflow templates within governance templates",
      "files": [
        "src/api/workflow-templates/controller.js",
        "src/api/workflow-templates/index.js",
        "src/api/workflow-templates/model.js",
        "src/api/workflow-templates/validation.js",
        "tests/api/workflow-templates.spec.js"
      ],
      "content": "\n\n--- src/api/workflow-templates/controller.js ---\nimport { createWorkflowTemplate } from './model.js'\nimport Boom from '@hapi/boom'\nimport { ObjectId } from 'mongodb'\n\n/**\n * Checks if there are any duplicate orders in the workflow templates\n * @param {object} db - MongoDB database instance\n * @param {import('mongodb').ObjectId} governanceTemplateId - Governance template ID\n * @param {number} order - Order to check\n * @param {import('mongodb').ObjectId} [excludeId] - Template ID to exclude from check\n * @returns {Promise<boolean>} - True if duplicate found\n */\nasync function hasDuplicateOrder(db, governanceTemplateId, order, excludeId) {\n  const query = {\n    governanceTemplateId,\n    order\n  }\n\n  if (excludeId) {\n    query._id = { $ne: excludeId }\n  }\n\n  const duplicate = await db.collection('workflowTemplates').findOne(query)\n  return !!duplicate\n}\n\n/**\n * Resequences all orders to ensure they are sequential starting from 0\n * @param {object} db - MongoDB database instance\n * @param {import('mongodb').ObjectId} governanceTemplateId - Governance template ID\n */\nasync function resequenceOrders(db, governanceTemplateId) {\n  // Get all templates ordered by current order\n  const templates = await db\n    .collection('workflowTemplates')\n    .find({ governanceTemplateId })\n    .sort({ order: 1 })\n    .toArray()\n\n  // Update each template with its new sequential order\n  for (let i = 0; i < templates.length; i++) {\n    await db\n      .collection('workflowTemplates')\n      .updateOne({ _id: templates[i]._id }, { $set: { order: i } })\n  }\n}\n\nexport const createWorkflowTemplateHandler = async (request, h) => {\n  try {\n    // Verify governanceTemplateId exists\n    const governanceTemplate = await request.db\n      .collection('governanceTemplates')\n      .findOne({ _id: new ObjectId(request.payload.governanceTemplateId) })\n\n    if (!governanceTemplate) {\n      throw Boom.notFound('Governance template not found')\n    }\n\n    // Find the maximum order value for workflow templates with the same governance template ID\n    const maxOrderResult = await request.db\n      .collection('workflowTemplates')\n      .find({\n        governanceTemplateId: new ObjectId(request.payload.governanceTemplateId)\n      })\n      .sort({ order: -1 })\n      .limit(1)\n      .toArray()\n\n    // Calculate the new order value (max + 1 or 0 if no templates exist)\n    const maxOrder = maxOrderResult.length > 0 ? maxOrderResult[0].order : -1\n    const newOrder = maxOrder + 1\n\n    // Check for duplicate order\n    const hasDuplicate = await hasDuplicateOrder(\n      request.db,\n      new ObjectId(request.payload.governanceTemplateId),\n      newOrder\n    )\n    if (hasDuplicate) {\n      throw Boom.badRequest('Duplicate order number detected')\n    }\n\n    // Create the template with the calculated order\n    const template = createWorkflowTemplate({\n      ...request.payload,\n      order: newOrder\n    })\n\n    const result = await request.db\n      .collection('workflowTemplates')\n      .insertOne(template)\n\n    return h.response({ ...template, _id: result.insertedId }).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    if (error.code === 11000) {\n      throw Boom.conflict('A workflow template with this name already exists')\n    }\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getWorkflowTemplateHandler = async (request, h) => {\n  try {\n    const template = await request.db\n      .collection('workflowTemplates')\n      .findOne({ _id: new ObjectId(request.params.id) })\n\n    if (!template) {\n      throw Boom.notFound('Workflow template not found')\n    }\n    return h.response(template).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const updateWorkflowTemplateHandler = async (request, h) => {\n  try {\n    const now = new Date()\n\n    // Get the current workflow template to check if order is changing\n    const currentTemplate = await request.db\n      .collection('workflowTemplates')\n      .findOne({ _id: new ObjectId(request.params.id) })\n\n    if (!currentTemplate) {\n      throw Boom.notFound('Workflow template not found')\n    }\n\n    // Check if order is being updated\n    if (\n      request.payload.order !== undefined &&\n      request.payload.order !== currentTemplate.order\n    ) {\n      const newOrder = request.payload.order\n      const oldOrder = currentTemplate.order\n\n      // Update other workflow templates' order based on the direction of movement\n      if (newOrder > oldOrder) {\n        // Moving down in the list (increasing order value)\n        // Decrement order for templates with order > oldOrder and <= newOrder\n        await request.db.collection('workflowTemplates').updateMany(\n          {\n            governanceTemplateId: currentTemplate.governanceTemplateId,\n            order: { $gt: oldOrder, $lte: newOrder }\n          },\n          { $inc: { order: -1 } }\n        )\n      } else if (newOrder < oldOrder) {\n        // Moving up in the list (decreasing order value)\n        // Increment order for templates with order >= newOrder and < oldOrder\n        await request.db.collection('workflowTemplates').updateMany(\n          {\n            governanceTemplateId: currentTemplate.governanceTemplateId,\n            order: { $gte: newOrder, $lt: oldOrder }\n          },\n          { $inc: { order: 1 } }\n        )\n      }\n\n      // Update the workflow template\n      await request.db\n        .collection('workflowTemplates')\n        .findOneAndUpdate(\n          { _id: new ObjectId(request.params.id) },\n          { $set: { ...request.payload, updatedAt: now } }\n        )\n\n      // Resequence all orders to ensure they are sequential\n      await resequenceOrders(request.db, currentTemplate.governanceTemplateId)\n\n      // Get the updated template with the final order\n      const result = await request.db\n        .collection('workflowTemplates')\n        .findOne({ _id: new ObjectId(request.params.id) })\n\n      return h.response(result).code(200)\n    } else {\n      // If not updating order, just update the template normally\n      const result = await request.db\n        .collection('workflowTemplates')\n        .findOneAndUpdate(\n          { _id: new ObjectId(request.params.id) },\n          { $set: { ...request.payload, updatedAt: now } },\n          { returnDocument: 'after' }\n        )\n\n      return h.response(result).code(200)\n    }\n  } catch (error) {\n    if (error.isBoom) throw error\n    if (error.code === 11000) {\n      throw Boom.conflict('A workflow template with this name already exists')\n    }\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const deleteWorkflowTemplateHandler = async (request, h) => {\n  try {\n    const workflowId = new ObjectId(request.params.id)\n\n    // Get the workflow template to be deleted\n    const workflowTemplate = await request.db\n      .collection('workflowTemplates')\n      .findOne({ _id: workflowId })\n\n    if (!workflowTemplate) {\n      throw Boom.notFound('Workflow template not found')\n    }\n\n    // Store the order and governanceTemplateId for reordering\n    const { order, governanceTemplateId } = workflowTemplate\n\n    // Delete all associated checklist items\n    await request.db\n      .collection('checklistItemTemplates')\n      .deleteMany({ workflowTemplateId: workflowId })\n\n    // Delete the workflow template\n    const result = await request.db\n      .collection('workflowTemplates')\n      .deleteOne({ _id: workflowId })\n\n    if (result.deletedCount === 0) {\n      throw Boom.notFound('Workflow template not found')\n    }\n\n    // Reorder remaining workflow templates\n    await request.db.collection('workflowTemplates').updateMany(\n      {\n        governanceTemplateId,\n        order: { $gt: order }\n      },\n      { $inc: { order: -1 } }\n    )\n\n    return h.response().code(204)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getAllWorkflowTemplatesHandler = async (request, h) => {\n  try {\n    const query = {}\n    if (request.query.governanceTemplateId) {\n      query.governanceTemplateId = new ObjectId(\n        request.query.governanceTemplateId\n      )\n    }\n\n    const templates = await request.db\n      .collection('workflowTemplates')\n      .find(query)\n      .sort(\n        request.query.governanceTemplateId ? { order: 1 } : { createdAt: -1 }\n      )\n      .toArray()\n    return h.response(templates).code(200)\n  } catch (error) {\n    throw Boom.badRequest(error.message)\n  }\n}\n\n\n--- src/api/workflow-templates/index.js ---\nimport {\n  createWorkflowTemplateHandler,\n  getWorkflowTemplateHandler,\n  updateWorkflowTemplateHandler,\n  deleteWorkflowTemplateHandler,\n  getAllWorkflowTemplatesHandler\n} from './controller.js'\nimport {\n  createWorkflowTemplateSchema,\n  updateWorkflowTemplateSchema\n} from './validation.js'\nimport Joi from 'joi'\n\n/**\n * @type { import('@hapi/hapi').Plugin<void> }\n */\nexport default {\n  name: 'workflow-template-routes',\n  register: (server) => {\n    server.route([\n      {\n        method: 'POST',\n        path: '/api/v1/workflow-templates',\n        handler: createWorkflowTemplateHandler,\n        options: {\n          tags: ['api', 'workflow-template'],\n          description:\n            'Create a new workflow template. The order is automatically calculated as max order + 1 for the governance template.',\n          validate: {\n            payload: createWorkflowTemplateSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description:\n                    'Successfully created workflow template. The order is automatically set to max order + 1 for the governance template.',\n                  schema: Joi.object({\n                    _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                    governanceTemplateId: Joi.string().example(\n                      '60d21bbfe3d5d533d9fc1e4d'\n                    ),\n                    name: Joi.string().example('Model Development Workflow'),\n                    description: Joi.string().example(\n                      'Workflow for developing and validating AI models'\n                    ),\n                    metadata: Joi.object().example({\n                      priority: 'high',\n                      category: 'development'\n                    }),\n                    order: Joi.number().integer().min(0).example(1),\n                    createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                    updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                  })\n                },\n                400: { description: 'Bad request' },\n                404: { description: 'Governance template not found' },\n                409: { description: 'Template with this name already exists' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/workflow-templates/{id}',\n        handler: getWorkflowTemplateHandler,\n        options: {\n          tags: ['api', 'workflow-template'],\n          description: 'Get a workflow template by ID',\n          validate: {\n            params: Joi.object({\n              id: Joi.string().required().description('Workflow template ID')\n            })\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully retrieved workflow template',\n                  schema: Joi.object({\n                    _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                    governanceTemplateId: Joi.string().example(\n                      '60d21bbfe3d5d533d9fc1e4d'\n                    ),\n                    name: Joi.string().example('Model Development Workflow'),\n                    description: Joi.string().example(\n                      'Workflow for developing and validating AI models'\n                    ),\n                    metadata: Joi.object().example({\n                      priority: 'high',\n                      category: 'development'\n                    }),\n                    order: Joi.number().integer().min(0).example(1),\n                    createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                    updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                  })\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'PUT',\n        path: '/api/v1/workflow-templates/{id}',\n        handler: updateWorkflowTemplateHandler,\n        options: {\n          tags: ['api', 'workflow-template'],\n          description: 'Update a workflow template',\n          validate: {\n            params: Joi.object({\n              id: Joi.string().required().description('Workflow template ID')\n            }),\n            payload: updateWorkflowTemplateSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully updated workflow template',\n                  schema: Joi.object({\n                    _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                    governanceTemplateId: Joi.string().example(\n                      '60d21bbfe3d5d533d9fc1e4d'\n                    ),\n                    name: Joi.string().example('Model Development Workflow'),\n                    description: Joi.string().example(\n                      'Workflow for developing and validating AI models'\n                    ),\n                    metadata: Joi.object().example({\n                      priority: 'high',\n                      category: 'development'\n                    }),\n                    order: Joi.number().integer().min(0).example(1),\n                    createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                    updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                  })\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' },\n                409: { description: 'Template with this name already exists' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'DELETE',\n        path: '/api/v1/workflow-templates/{id}',\n        handler: deleteWorkflowTemplateHandler,\n        options: {\n          tags: ['api', 'workflow-template'],\n          description: 'Delete a workflow template',\n          validate: {\n            params: Joi.object({\n              id: Joi.string().required().description('Workflow template ID')\n            })\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                204: { description: 'Successfully deleted workflow template' },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/workflow-templates',\n        handler: getAllWorkflowTemplatesHandler,\n        options: {\n          tags: ['api', 'workflow-template'],\n          description: 'Get all workflow templates',\n          validate: {\n            query: Joi.object({\n              governanceTemplateId: Joi.string()\n                .description('Filter by governance template ID')\n                .example('60d21bbfe3d5d533d9fc1e4c')\n            })\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully retrieved workflow templates',\n                  schema: Joi.array().items(\n                    Joi.object({\n                      _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                      governanceTemplateId: Joi.string().example(\n                        '60d21bbfe3d5d533d9fc1e4d'\n                      ),\n                      name: Joi.string().example('Model Development Workflow'),\n                      description: Joi.string().example(\n                        'Workflow for developing and validating AI models'\n                      ),\n                      metadata: Joi.object().example({\n                        priority: 'high',\n                        category: 'development'\n                      }),\n                      order: Joi.number().integer().min(0).example(1),\n                      createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                      updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                    })\n                  )\n                },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      }\n    ])\n  }\n}\n\n\n--- src/api/workflow-templates/model.js ---\nimport { ObjectId } from 'mongodb'\n\n/**\n * @typedef {object} WorkflowTemplate\n * @property {import('mongodb').ObjectId} _id - The unique identifier\n * @property {import('mongodb').ObjectId} governanceTemplateId - Reference to parent GovernanceTemplate (required)\n * @property {string} name - The name of the workflow (required)\n * @property {string} [description] - The description of the workflow\n * @property {object} [metadata] - Additional workflow configuration\n * @property {number} [order] - Manual ordering position for the workflow\n * @property {Date} createdAt - When the template was created (required)\n * @property {Date} updatedAt - When the template was last updated (required)\n */\n\n/**\n * Creates a new workflow template\n * @param {object} data - The template data\n * @param {string|import('mongodb').ObjectId} data.governanceTemplateId - Reference to parent GovernanceTemplate\n * @param {string} data.name - The name of the workflow\n * @param {string} [data.description] - The description of the workflow\n * @param {object} [data.metadata] - Additional workflow configuration\n * @param {number} data.order - Manual ordering position for the workflow\n * @returns {Omit<WorkflowTemplate, '_id'>}\n */\nexport function createWorkflowTemplate(data) {\n  const now = new Date()\n  return {\n    governanceTemplateId:\n      typeof data.governanceTemplateId === 'string'\n        ? new ObjectId(data.governanceTemplateId)\n        : data.governanceTemplateId,\n    name: data.name,\n    description: data.description,\n    metadata: data.metadata ?? {},\n    order: data.order,\n    createdAt: now,\n    updatedAt: now\n  }\n}\n\n\n--- src/api/workflow-templates/validation.js ---\nimport Joi from 'joi'\nimport { ObjectId } from 'mongodb'\n\n// Custom Joi extension for MongoDB ObjectId validation\nconst objectIdSchema = Joi.string().custom((value, helpers) => {\n  if (!ObjectId.isValid(value)) {\n    return helpers.error('any.invalid')\n  }\n  return value\n}, 'MongoDB ObjectId validation')\n\nexport const createWorkflowTemplateSchema = Joi.object({\n  governanceTemplateId: objectIdSchema.required(),\n  name: Joi.string().required(),\n  description: Joi.string().allow(''),\n  metadata: Joi.object().default({})\n})\n\nexport const updateWorkflowTemplateSchema = Joi.object({\n  name: Joi.string(),\n  description: Joi.string().allow(''),\n  metadata: Joi.object(),\n  order: Joi.number().integer().min(0)\n}).min(1)\n\nexport const idSchema = Joi.object({\n  id: objectIdSchema.required().description('MongoDB ObjectId')\n})\n\n\n--- tests/api/workflow-templates.spec.js ---\nimport { test, expect } from '@playwright/test'\n\nconst getUniqueId = () =>\n  `test_${Date.now()}_${Math.random().toString(36).substring(2, 7)}`\n\nconst createWorkflowTemplate = (uniqueId) => ({\n  name: `Test Workflow Template ${uniqueId}`,\n  description: 'Test workflow template for E2E testing',\n  metadata: {\n    category: 'test',\n    priority: 'high'\n  }\n})\n\ntest.describe('Workflow Template API', () => {\n  let governanceTemplateId\n  let workflowTemplateId\n  const uniqueId = getUniqueId()\n  const workflowTemplate = createWorkflowTemplate(uniqueId)\n\n  test.beforeAll(async ({ request }) => {\n    // Create a governance template for testing\n    const response = await request.post('/api/v1/governance-templates', {\n      data: {\n        name: `Test Governance Template ${uniqueId}`,\n        version: '1.0.0',\n        description: 'Test governance template for workflow tests'\n      }\n    })\n    const data = await response.json()\n    governanceTemplateId = data._id\n  })\n\n  test.afterAll(async ({ request }) => {\n    if (workflowTemplateId) {\n      await request.delete(`/api/v1/workflow-templates/${workflowTemplateId}`)\n    }\n    if (governanceTemplateId) {\n      await request.delete(\n        `/api/v1/governance-templates/${governanceTemplateId}`\n      )\n    }\n  })\n\n  test('should create a new workflow template', async ({ request }) => {\n    const workflowData = {\n      ...workflowTemplate,\n      governanceTemplateId\n    }\n\n    const response = await request.post('/api/v1/workflow-templates', {\n      data: workflowData\n    })\n\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    expect(data).toHaveProperty('_id')\n    expect(data.name).toBe(workflowTemplate.name)\n    expect(data.governanceTemplateId).toBe(governanceTemplateId)\n\n    workflowTemplateId = data._id\n  })\n\n  test('should get a workflow template by id', async ({ request }) => {\n    const response = await request.get(\n      `/api/v1/workflow-templates/${workflowTemplateId}`\n    )\n\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    expect(data._id).toBe(workflowTemplateId)\n    expect(data.name).toBe(workflowTemplate.name)\n  })\n\n  test('should reorder workflow templates after deletion', async ({\n    request\n  }) => {\n    // Create three more workflow templates with sequential order\n    const workflowData1 = {\n      name: `Test Workflow Template 1 ${uniqueId}`,\n      description: 'Test workflow template 1',\n      governanceTemplateId\n    }\n    const workflowData2 = {\n      name: `Test Workflow Template 2 ${uniqueId}`,\n      description: 'Test workflow template 2',\n      governanceTemplateId\n    }\n    const workflowData3 = {\n      name: `Test Workflow Template 3 ${uniqueId}`,\n      description: 'Test workflow template 3',\n      governanceTemplateId\n    }\n\n    // Create the workflow templates\n    const response1 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData1\n    })\n    const data1 = await response1.json()\n    const workflowId1 = data1._id\n    const order1 = data1.order\n\n    const response2 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData2\n    })\n    const data2 = await response2.json()\n    const workflowId2 = data2._id\n    const order2 = data2.order\n\n    const response3 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData3\n    })\n    const data3 = await response3.json()\n    const workflowId3 = data3._id\n    const order3 = data3.order\n\n    // Verify the initial orders are sequential\n    expect(order2).toBe(order1 + 1)\n    expect(order3).toBe(order2 + 1)\n\n    // Delete the middle workflow template\n    const deleteResponse = await request.delete(\n      `/api/v1/workflow-templates/${workflowId2}`\n    )\n    expect(deleteResponse.ok()).toBeTruthy()\n\n    // Verify the first workflow template's order remains unchanged\n    const getResponse1 = await request.get(\n      `/api/v1/workflow-templates/${workflowId1}`\n    )\n    const updatedData1 = await getResponse1.json()\n    expect(updatedData1.order).toBe(order1)\n\n    // Verify the third workflow template's order has been decremented\n    const getResponse3 = await request.get(\n      `/api/v1/workflow-templates/${workflowId3}`\n    )\n    const updatedData3 = await getResponse3.json()\n    expect(updatedData3.order).toBe(order2) // Should now have the order of the deleted template\n\n    // Clean up the remaining test workflow templates\n    await request.delete(`/api/v1/workflow-templates/${workflowId1}`)\n    await request.delete(`/api/v1/workflow-templates/${workflowId3}`)\n  })\n\n  test('should update a workflow template', async ({ request }) => {\n    const updatedTemplate = {\n      ...workflowTemplate,\n      description: 'Updated workflow description'\n    }\n\n    const response = await request.put(\n      `/api/v1/workflow-templates/${workflowTemplateId}`,\n      {\n        data: updatedTemplate\n      }\n    )\n\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    expect(data.description).toBe(updatedTemplate.description)\n  })\n\n  test('should reorder workflow templates when updating order', async ({\n    request\n  }) => {\n    // Create three workflow templates with sequential order\n    const workflowData1 = {\n      name: `Test Workflow Template 1 ${uniqueId}`,\n      description: 'Test workflow template 1',\n      governanceTemplateId\n    }\n    const workflowData2 = {\n      name: `Test Workflow Template 2 ${uniqueId}`,\n      description: 'Test workflow template 2',\n      governanceTemplateId\n    }\n    const workflowData3 = {\n      name: `Test Workflow Template 3 ${uniqueId}`,\n      description: 'Test workflow template 3',\n      governanceTemplateId\n    }\n\n    // Create the workflow templates\n    const response1 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData1\n    })\n    const data1 = await response1.json()\n    const workflowId1 = data1._id\n    const order1 = data1.order\n\n    const response2 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData2\n    })\n    const data2 = await response2.json()\n    const workflowId2 = data2._id\n    const order2 = data2.order\n\n    const response3 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData3\n    })\n    const data3 = await response3.json()\n    const workflowId3 = data3._id\n    const order3 = data3.order\n\n    // Verify the initial orders are sequential\n    expect(order2).toBe(order1 + 1)\n    expect(order3).toBe(order2 + 1)\n\n    // Move the first workflow template to the end (order 2)\n    const updateResponse = await request.put(\n      `/api/v1/workflow-templates/${workflowId1}`,\n      {\n        data: { order: order3 }\n      }\n    )\n    expect(updateResponse.ok()).toBeTruthy()\n\n    // Verify the updated order of the first workflow template\n    const getResponse1 = await request.get(\n      `/api/v1/workflow-templates/${workflowId1}`\n    )\n    const updatedData1 = await getResponse1.json()\n    expect(updatedData1.order).toBe(order3)\n\n    // Verify the second workflow template's order has been decremented\n    const getResponse2 = await request.get(\n      `/api/v1/workflow-templates/${workflowId2}`\n    )\n    const updatedData2 = await getResponse2.json()\n    expect(updatedData2.order).toBe(order1)\n\n    // Verify the third workflow template's order has been decremented\n    const getResponse3 = await request.get(\n      `/api/v1/workflow-templates/${workflowId3}`\n    )\n    const updatedData3 = await getResponse3.json()\n    expect(updatedData3.order).toBe(order2)\n\n    // Now move the third workflow template to the beginning (order 0)\n    const updateResponse2 = await request.put(\n      `/api/v1/workflow-templates/${workflowId3}`,\n      {\n        data: { order: order1 }\n      }\n    )\n    expect(updateResponse2.ok()).toBeTruthy()\n\n    // Verify the updated order of the third workflow template\n    const getResponse3b = await request.get(\n      `/api/v1/workflow-templates/${workflowId3}`\n    )\n    const updatedData3b = await getResponse3b.json()\n    expect(updatedData3b.order).toBe(order1)\n\n    // Verify the first workflow template's order has been incremented\n    const getResponse1b = await request.get(\n      `/api/v1/workflow-templates/${workflowId1}`\n    )\n    const updatedData1b = await getResponse1b.json()\n    expect(updatedData1b.order).toBe(order3)\n\n    // Verify the second workflow template's order has been incremented\n    const getResponse2b = await request.get(\n      `/api/v1/workflow-templates/${workflowId2}`\n    )\n    const updatedData2b = await getResponse2b.json()\n    expect(updatedData2b.order).toBe(order1 + 1)\n\n    // Clean up the test workflow templates\n    await request.delete(`/api/v1/workflow-templates/${workflowId1}`)\n    await request.delete(`/api/v1/workflow-templates/${workflowId2}`)\n    await request.delete(`/api/v1/workflow-templates/${workflowId3}`)\n  })\n\n  test('should cascade delete checklist items when deleting workflow template', async ({\n    request\n  }) => {\n    const cascadeUniqueId = getUniqueId()\n    // Create a new workflow template specifically for testing deletion\n    const workflowResponse = await request.post('/api/v1/workflow-templates', {\n      data: {\n        name: `Cascade Delete Test Workflow ${cascadeUniqueId}`,\n        description: 'Testing cascade deletion',\n        governanceTemplateId,\n        metadata: { test: true }\n      }\n    })\n    expect(workflowResponse.ok()).toBeTruthy()\n    const cascadeWorkflowId = (await workflowResponse.json())._id\n\n    // Create multiple checklist items with dependencies between them\n    const checklistIds = []\n\n    // Create first checklist item\n    const firstChecklistResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `First Checklist Template ${cascadeUniqueId}`,\n          description: 'Testing cascade deletion',\n          type: 'approval',\n          workflowTemplateId: cascadeWorkflowId,\n          dependencies_requires: []\n        }\n      }\n    )\n    expect(firstChecklistResponse.ok()).toBeTruthy()\n    const firstChecklistId = (await firstChecklistResponse.json())._id\n    checklistIds.push(firstChecklistId)\n\n    // Create dependent checklist items\n    for (let i = 0; i < 2; i++) {\n      const checklistResponse = await request.post(\n        '/api/v1/checklist-item-templates',\n        {\n          data: {\n            name: `Dependent Checklist Template ${cascadeUniqueId}-${i}`,\n            description: 'Testing cascade deletion',\n            type: 'approval',\n            workflowTemplateId: cascadeWorkflowId,\n            dependencies_requires: [firstChecklistId] // These depend on the first checklist item\n          }\n        }\n      )\n      expect(checklistResponse.ok()).toBeTruthy()\n      checklistIds.push((await checklistResponse.json())._id)\n    }\n\n    // Delete the workflow template\n    const deleteResponse = await request.delete(\n      `/api/v1/workflow-templates/${cascadeWorkflowId}`\n    )\n    expect(deleteResponse.ok()).toBeTruthy()\n\n    // Verify that all checklist items have been deleted\n    for (const checklistId of checklistIds) {\n      const checklistResponse = await request.get(\n        `/api/v1/checklist-item-templates/${checklistId}`\n      )\n      expect(checklistResponse.ok()).toBeFalsy()\n      expect(checklistResponse.status()).toBe(404)\n    }\n  })\n\n  test('should filter workflow templates by governanceTemplateId', async ({\n    request\n  }) => {\n    // Create another governance template for testing filtering\n    const anotherGovResponse = await request.post(\n      '/api/v1/governance-templates',\n      {\n        data: {\n          name: `Another Gov Template ${uniqueId}`,\n          version: '1.0.0',\n          description: 'Another governance template for filter tests'\n        }\n      }\n    )\n    expect(anotherGovResponse.ok()).toBeTruthy()\n    const anotherGovId = (await anotherGovResponse.json())._id\n\n    // Create another workflow template with the new governance template\n    const anotherWorkflowResponse = await request.post(\n      '/api/v1/workflow-templates',\n      {\n        data: {\n          name: `Another Workflow Template ${uniqueId}`,\n          description: 'Another workflow template for filter tests',\n          governanceTemplateId: anotherGovId,\n          metadata: { test: true }\n        }\n      }\n    )\n    expect(anotherWorkflowResponse.ok()).toBeTruthy()\n    const anotherWorkflowId = (await anotherWorkflowResponse.json())._id\n\n    // Test filtering by original governanceTemplateId\n    const filterResponse = await request.get(\n      `/api/v1/workflow-templates?governanceTemplateId=${governanceTemplateId}`\n    )\n    expect(filterResponse.ok()).toBeTruthy()\n    const filteredData = await filterResponse.json()\n\n    // Verify filtered results\n    expect(Array.isArray(filteredData)).toBeTruthy()\n    expect(filteredData.length).toBeGreaterThan(0)\n    expect(\n      filteredData.every(\n        (template) => template.governanceTemplateId === governanceTemplateId\n      )\n    ).toBeTruthy()\n    expect(\n      filteredData.some(\n        (template) => template.governanceTemplateId === anotherGovId\n      )\n    ).toBeFalsy()\n\n    // Clean up\n    await request.delete(`/api/v1/workflow-templates/${anotherWorkflowId}`)\n    await request.delete(`/api/v1/governance-templates/${anotherGovId}`)\n  })\n\n  test('should return workflow templates in order when filtering by governanceTemplateId', async ({\n    request\n  }) => {\n    // Create three workflow templates with different orders\n    const orderTestUniqueId = getUniqueId()\n\n    // Create workflow templates with specific orders\n    const workflowData1 = {\n      name: `Order Test Workflow 1 ${orderTestUniqueId}`,\n      description: 'First workflow for order test',\n      governanceTemplateId\n    }\n    const workflowData2 = {\n      name: `Order Test Workflow 2 ${orderTestUniqueId}`,\n      description: 'Second workflow for order test',\n      governanceTemplateId\n    }\n    const workflowData3 = {\n      name: `Order Test Workflow 3 ${orderTestUniqueId}`,\n      description: 'Third workflow for order test',\n      governanceTemplateId\n    }\n\n    // Create the workflow templates\n    const response1 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData1\n    })\n    const data1 = await response1.json()\n    const workflowId1 = data1._id\n    const order1 = data1.order\n\n    const response2 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData2\n    })\n    const data2 = await response2.json()\n    const workflowId2 = data2._id\n    const order2 = data2.order\n\n    const response3 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData3\n    })\n    const data3 = await response3.json()\n    const workflowId3 = data3._id\n    const order3 = data3.order\n\n    // Verify the initial orders are sequential\n    expect(order2).toBe(order1 + 1)\n    expect(order3).toBe(order2 + 1)\n\n    // Reorder the templates: move the third template to the beginning\n    await request.put(`/api/v1/workflow-templates/${workflowId3}`, {\n      data: { order: 0 }\n    })\n\n    // Get all workflow templates filtered by governanceTemplateId\n    const filterResponse = await request.get(\n      `/api/v1/workflow-templates?governanceTemplateId=${governanceTemplateId}`\n    )\n    expect(filterResponse.ok()).toBeTruthy()\n    const filteredData = await filterResponse.json()\n\n    // Find our test templates in the filtered results\n    const testTemplates = filteredData.filter(\n      (template) =>\n        template._id === workflowId1 ||\n        template._id === workflowId2 ||\n        template._id === workflowId3\n    )\n\n    // Verify they are sorted by order\n    for (let i = 1; i < testTemplates.length; i++) {\n      expect(testTemplates[i - 1].order).toBeLessThanOrEqual(\n        testTemplates[i].order\n      )\n    }\n\n    // Verify the third template is now first in our test templates\n    const sortedIds = testTemplates.map((t) => t._id)\n    expect(sortedIds.indexOf(workflowId3)).toBeLessThan(\n      sortedIds.indexOf(workflowId1)\n    )\n    expect(sortedIds.indexOf(workflowId3)).toBeLessThan(\n      sortedIds.indexOf(workflowId2)\n    )\n\n    // Clean up the test workflow templates\n    await request.delete(`/api/v1/workflow-templates/${workflowId1}`)\n    await request.delete(`/api/v1/workflow-templates/${workflowId2}`)\n    await request.delete(`/api/v1/workflow-templates/${workflowId3}`)\n  })\n\n  test('should prevent duplicate order numbers', async ({ request }) => {\n    // Create first workflow template\n    const workflowData1 = {\n      name: `Test Workflow Template 1 ${uniqueId}`,\n      description: 'Test workflow template 1',\n      governanceTemplateId\n    }\n\n    const response1 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData1\n    })\n    expect(response1.ok()).toBeTruthy()\n    const data1 = await response1.json()\n    const workflowId1 = data1._id\n    const order1 = data1.order\n\n    // Create second workflow template\n    const workflowData2 = {\n      name: `Test Workflow Template 2 ${uniqueId}`,\n      description: 'Test workflow template 2',\n      governanceTemplateId\n    }\n\n    const response2 = await request.post('/api/v1/workflow-templates', {\n      data: workflowData2\n    })\n    expect(response2.ok()).toBeTruthy()\n    const data2 = await response2.json()\n    const workflowId2 = data2._id\n\n    // Try to update second template to have same order as first\n    const updateResponse = await request.put(\n      `/api/v1/workflow-templates/${workflowId2}`,\n      {\n        data: { order: order1 }\n      }\n    )\n    expect(updateResponse.ok()).toBeFalsy()\n    expect(updateResponse.status()).toBe(400)\n\n    const errorData = await updateResponse.json()\n    expect(errorData.message).toBe('Duplicate order number detected')\n\n    // Clean up\n    await request.delete(`/api/v1/workflow-templates/${workflowId1}`)\n    await request.delete(`/api/v1/workflow-templates/${workflowId2}`)\n  })\n})\n"
    },
    {
      "chunk_id": "checklist_item_template_management",
      "description": "Functionality for managing checklist item templates within workflow templates",
      "files": [
        "src/api/checklist-item-templates/controller.js",
        "src/api/checklist-item-templates/index.js",
        "src/api/checklist-item-templates/model.js",
        "src/api/checklist-item-templates/validation.js",
        "tests/api/checklist-item-templates.spec.js"
      ],
      "content": "\n\n--- src/api/checklist-item-templates/controller.js ---\nimport { createChecklistItemTemplate } from './model.js'\nimport Boom from '@hapi/boom'\nimport { ObjectId } from 'mongodb'\n\n/**\n * Checks if there are any duplicate orders in the checklist item templates\n * @param {object} db - MongoDB database instance\n * @param {import('mongodb').ObjectId} workflowTemplateId - Workflow template ID\n * @param {number} order - Order to check\n * @param {import('mongodb').ObjectId} [excludeId] - Template ID to exclude from check\n * @returns {Promise<boolean>} - True if duplicate found\n */\nasync function hasDuplicateOrder(db, workflowTemplateId, order, excludeId) {\n  const query = {\n    workflowTemplateId,\n    order\n  }\n\n  if (excludeId) {\n    query._id = { $ne: excludeId }\n  }\n\n  const duplicate = await db.collection('checklistItemTemplates').findOne(query)\n  return !!duplicate\n}\n\n/**\n * Resequences all orders to ensure they are sequential starting from 0\n * @param {object} db - MongoDB database instance\n * @param {import('mongodb').ObjectId} workflowTemplateId - Workflow template ID\n */\nasync function resequenceOrders(db, workflowTemplateId) {\n  // Get all templates ordered by current order\n  const templates = await db\n    .collection('checklistItemTemplates')\n    .find({ workflowTemplateId })\n    .sort({ order: 1 })\n    .toArray()\n\n  // Update each template with its new sequential order\n  for (let i = 0; i < templates.length; i++) {\n    await db\n      .collection('checklistItemTemplates')\n      .updateOne({ _id: templates[i]._id }, { $set: { order: i } })\n  }\n}\n\nexport const createChecklistItemTemplateHandler = async (request, h) => {\n  try {\n    // Verify workflowTemplateId exists\n    const workflowTemplate = await request.db\n      .collection('workflowTemplates')\n      .findOne({ _id: new ObjectId(request.payload.workflowTemplateId) })\n\n    if (!workflowTemplate) {\n      throw Boom.notFound('Workflow template not found')\n    }\n\n    // Find the maximum order value for checklist item templates with the same workflow template ID\n    const maxOrderResult = await request.db\n      .collection('checklistItemTemplates')\n      .find({\n        workflowTemplateId: new ObjectId(request.payload.workflowTemplateId)\n      })\n      .sort({ order: -1 })\n      .limit(1)\n      .toArray()\n\n    // Calculate the new order value (max + 1 or 0 if no templates exist)\n    const maxOrder = maxOrderResult.length > 0 ? maxOrderResult[0].order : -1\n    const newOrder = maxOrder + 1\n\n    // Check for duplicate order\n    const hasDuplicate = await hasDuplicateOrder(\n      request.db,\n      new ObjectId(request.payload.workflowTemplateId),\n      newOrder\n    )\n    if (hasDuplicate) {\n      throw Boom.badRequest('Duplicate order number detected')\n    }\n\n    // Create the template with the calculated order\n    const template = createChecklistItemTemplate({\n      ...request.payload,\n      order: newOrder\n    })\n\n    const result = await request.db\n      .collection('checklistItemTemplates')\n      .insertOne(template)\n\n    return h.response({ ...template, _id: result.insertedId }).code(201)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getChecklistItemTemplateHandler = async (request, h) => {\n  try {\n    const template = await request.db\n      .collection('checklistItemTemplates')\n      .findOne({ _id: new ObjectId(request.params.id) })\n\n    if (!template) {\n      throw Boom.notFound('Checklist item template not found')\n    }\n\n    // If there are dependencies, populate them\n    if (\n      template.dependencies_requires &&\n      template.dependencies_requires.length > 0\n    ) {\n      const dependencies = await request.db\n        .collection('checklistItemTemplates')\n        .find({ _id: { $in: template.dependencies_requires } })\n        .toArray()\n\n      template.dependencies_requires = dependencies\n    }\n\n    // Find all templates that require this template\n    const requiredBy = await request.db\n      .collection('checklistItemTemplates')\n      .find({ dependencies_requires: template._id })\n      .toArray()\n\n    template.dependencies_requiredBy = requiredBy\n\n    return h.response(template).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const updateChecklistItemTemplateHandler = async (request, h) => {\n  try {\n    const now = new Date()\n    const updatePayload = { ...request.payload }\n    const templateId = new ObjectId(request.params.id)\n\n    // Get the current checklist item template to check if order is changing\n    const currentTemplate = await request.db\n      .collection('checklistItemTemplates')\n      .findOne({ _id: templateId })\n\n    if (!currentTemplate) {\n      throw Boom.notFound('Checklist item template not found')\n    }\n\n    // Convert dependencies_requires to ObjectIds if present and filter out self-dependency\n    if (updatePayload.dependencies_requires) {\n      updatePayload.dependencies_requires = updatePayload.dependencies_requires\n        .map((id) => new ObjectId(id))\n        .filter((id) => !id.equals(templateId))\n    }\n\n    // Check if order is being updated\n    if (\n      updatePayload.order !== undefined &&\n      updatePayload.order !== currentTemplate.order\n    ) {\n      const newOrder = updatePayload.order\n      const oldOrder = currentTemplate.order\n\n      // Update other checklist item templates' order based on the direction of movement\n      if (newOrder > oldOrder) {\n        // Moving down in the list (increasing order value)\n        // Decrement order for templates with order > oldOrder and <= newOrder\n        await request.db.collection('checklistItemTemplates').updateMany(\n          {\n            workflowTemplateId: currentTemplate.workflowTemplateId,\n            order: { $gt: oldOrder, $lte: newOrder }\n          },\n          { $inc: { order: -1 } }\n        )\n      } else if (newOrder < oldOrder) {\n        // Moving up in the list (decreasing order value)\n        // Increment order for templates with order >= newOrder and < oldOrder\n        await request.db.collection('checklistItemTemplates').updateMany(\n          {\n            workflowTemplateId: currentTemplate.workflowTemplateId,\n            order: { $gte: newOrder, $lt: oldOrder }\n          },\n          { $inc: { order: 1 } }\n        )\n      }\n\n      // Update the checklist item template\n      await request.db\n        .collection('checklistItemTemplates')\n        .findOneAndUpdate(\n          { _id: templateId },\n          { $set: { ...updatePayload, updatedAt: now } }\n        )\n\n      // Resequence all orders to ensure they are sequential\n      await resequenceOrders(request.db, currentTemplate.workflowTemplateId)\n\n      // Get the updated template with the final order and populate dependencies\n      const result = await request.db\n        .collection('checklistItemTemplates')\n        .findOne({ _id: templateId })\n\n      if (!result) {\n        throw Boom.notFound('Checklist item template not found')\n      }\n\n      // If there are dependencies, populate them\n      if (\n        result.dependencies_requires &&\n        result.dependencies_requires.length > 0\n      ) {\n        const dependencies = await request.db\n          .collection('checklistItemTemplates')\n          .find({ _id: { $in: result.dependencies_requires } })\n          .toArray()\n\n        result.dependencies_requires = dependencies\n      }\n\n      // Find all templates that require this template\n      const requiredBy = await request.db\n        .collection('checklistItemTemplates')\n        .find({ dependencies_requires: result._id })\n        .toArray()\n\n      result.dependencies_requiredBy = requiredBy\n\n      return h.response(result).code(200)\n    } else {\n      // If not updating order, just update the template normally\n      const result = await request.db\n        .collection('checklistItemTemplates')\n        .findOneAndUpdate(\n          { _id: templateId },\n          { $set: { ...updatePayload, updatedAt: now } },\n          { returnDocument: 'after' }\n        )\n\n      if (!result) {\n        throw Boom.notFound('Checklist item template not found')\n      }\n\n      // If there are dependencies, populate them\n      if (\n        result.dependencies_requires &&\n        result.dependencies_requires.length > 0\n      ) {\n        const dependencies = await request.db\n          .collection('checklistItemTemplates')\n          .find({ _id: { $in: result.dependencies_requires } })\n          .toArray()\n\n        result.dependencies_requires = dependencies\n      }\n\n      // Find all templates that require this template\n      const requiredBy = await request.db\n        .collection('checklistItemTemplates')\n        .find({ dependencies_requires: result._id })\n        .toArray()\n\n      result.dependencies_requiredBy = requiredBy\n\n      return h.response(result).code(200)\n    }\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const deleteChecklistItemTemplateHandler = async (request, h) => {\n  try {\n    const templateId = new ObjectId(request.params.id)\n\n    // Get the checklist item template to be deleted\n    const template = await request.db\n      .collection('checklistItemTemplates')\n      .findOne({ _id: templateId })\n\n    if (!template) {\n      throw Boom.notFound('Checklist item template not found')\n    }\n\n    // Store the order and workflowTemplateId for reordering\n    const { order, workflowTemplateId } = template\n\n    // Remove this template from dependencies_requires arrays of other templates\n    await request.db\n      .collection('checklistItemTemplates')\n      .updateMany(\n        { dependencies_requires: templateId },\n        { $pull: { dependencies_requires: templateId } }\n      )\n\n    // Delete the template\n    const result = await request.db\n      .collection('checklistItemTemplates')\n      .deleteOne({ _id: templateId })\n\n    if (result.deletedCount === 0) {\n      throw Boom.notFound('Checklist item template not found')\n    }\n\n    // Reorder remaining checklist item templates\n    await request.db.collection('checklistItemTemplates').updateMany(\n      {\n        workflowTemplateId,\n        order: { $gt: order }\n      },\n      { $inc: { order: -1 } }\n    )\n\n    return h.response().code(204)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getAllChecklistItemTemplatesHandler = async (request, h) => {\n  try {\n    const query = {}\n\n    if (request.query.governanceTemplateId) {\n      // First find all workflow templates for this governance template\n      const workflowTemplates = await request.db\n        .collection('workflowTemplates')\n        .find({\n          governanceTemplateId: new ObjectId(request.query.governanceTemplateId)\n        })\n        .toArray()\n\n      // Get all workflow template IDs\n      const workflowTemplateIds = workflowTemplates.map((wt) => wt._id)\n\n      // Add workflow template IDs to query\n      if (workflowTemplateIds.length > 0) {\n        query.workflowTemplateId = { $in: workflowTemplateIds }\n      } else {\n        // If no workflow templates found, return empty array\n        return h.response([]).code(200)\n      }\n    } else if (request.query.workflowTemplateId) {\n      query.workflowTemplateId = new ObjectId(request.query.workflowTemplateId)\n    }\n\n    const templates = await request.db\n      .collection('checklistItemTemplates')\n      .find(query)\n      .sort({ order: 1 }) // Sort by order instead of createdAt\n      .toArray()\n\n    // If there are templates with dependencies, populate them\n    for (const template of templates) {\n      if (\n        template.dependencies_requires &&\n        template.dependencies_requires.length > 0\n      ) {\n        const dependencies = await request.db\n          .collection('checklistItemTemplates')\n          .find({ _id: { $in: template.dependencies_requires } })\n          .toArray()\n\n        template.dependencies_requires = dependencies\n      }\n\n      // Find all templates that require this template\n      const requiredBy = await request.db\n        .collection('checklistItemTemplates')\n        .find({ dependencies_requires: template._id })\n        .toArray()\n\n      template.dependencies_requiredBy = requiredBy\n    }\n\n    return h.response(templates).code(200)\n  } catch (error) {\n    throw Boom.badRequest(error.message)\n  }\n}\n\n\n--- src/api/checklist-item-templates/index.js ---\nimport {\n  createChecklistItemTemplateHandler,\n  getChecklistItemTemplateHandler,\n  updateChecklistItemTemplateHandler,\n  deleteChecklistItemTemplateHandler,\n  getAllChecklistItemTemplatesHandler\n} from './controller.js'\nimport {\n  createChecklistItemTemplateSchema,\n  updateChecklistItemTemplateSchema\n} from './validation.js'\nimport Joi from 'joi'\n\n/**\n * @type { import('@hapi/hapi').Plugin<void> }\n */\nexport default {\n  name: 'checklist-item-template-routes',\n  register: (server) => {\n    server.route([\n      {\n        method: 'POST',\n        path: '/api/v1/checklist-item-templates',\n        handler: createChecklistItemTemplateHandler,\n        options: {\n          tags: ['api', 'checklist-item-template'],\n          description: 'Create a new checklist item template',\n          validate: {\n            payload: createChecklistItemTemplateSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                201: {\n                  description: 'Successfully created checklist item template',\n                  schema: Joi.object({\n                    _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                    workflowTemplateId: Joi.string().example(\n                      '60d21bbfe3d5d533d9fc1e4d'\n                    ),\n                    name: Joi.string().example('Model Validation'),\n                    description: Joi.string().example(\n                      'Validate the AI model performance and fairness'\n                    ),\n                    type: Joi.string().example('task'),\n                    dependencies_requires: Joi.array()\n                      .items(Joi.string())\n                      .example(['60d21bbfe3d5d533d9fc1e4e']),\n                    dependencies_requiredBy: Joi.array().items(\n                      Joi.object({\n                        _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4f'),\n                        workflowTemplateId: Joi.string().example(\n                          '60d21bbfe3d5d533d9fc1e4d'\n                        ),\n                        name: Joi.string().example('Model Deployment'),\n                        description: Joi.string().example(\n                          'Deploy the validated AI model'\n                        ),\n                        type: Joi.string().example('approval'),\n                        dependencies_requires: Joi.array()\n                          .items(Joi.string())\n                          .example(['60d21bbfe3d5d533d9fc1e4c']),\n                        metadata: Joi.object().example({ priority: 'high' }),\n                        createdAt: Joi.date().example(\n                          '2024-03-20T10:00:00.000Z'\n                        ),\n                        updatedAt: Joi.date().example(\n                          '2024-03-20T10:00:00.000Z'\n                        )\n                      })\n                    ),\n                    metadata: Joi.object().example({\n                      priority: 'high',\n                      category: 'validation'\n                    }),\n                    createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                    updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                  })\n                },\n                400: { description: 'Bad request' },\n                404: { description: 'Workflow template not found' }\n              },\n              payloadType: 'json',\n              validate: {\n                payload: Joi.object({\n                  workflowTemplateId: Joi.string()\n                    .required()\n                    .example('60d21bbfe3d5d533d9fc1e4d'),\n                  name: Joi.string()\n                    .required()\n                    .example('Upload Approval Document'),\n                  description: Joi.string()\n                    .required()\n                    .example(\n                      'Checklist item for uploading an approval document'\n                    ),\n                  type: Joi.string()\n                    .required()\n                    .valid('approval', 'document', 'task')\n                    .example('approval'),\n                  dependencies_requires: Joi.array()\n                    .items(Joi.string())\n                    .default([])\n                    .example(['60d21bbfe3d5d533d9fc1e4d']),\n                  metadata: Joi.object().default({}).example({})\n                })\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/checklist-item-templates/{id}',\n        handler: getChecklistItemTemplateHandler,\n        options: {\n          tags: ['api', 'checklist-item-template'],\n          description: 'Get a checklist item template by ID',\n          validate: {\n            params: Joi.object({\n              id: Joi.string()\n                .required()\n                .description('Checklist item template ID')\n            })\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully retrieved checklist item template',\n                  schema: Joi.object({\n                    _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                    workflowTemplateId: Joi.string().example(\n                      '60d21bbfe3d5d533d9fc1e4d'\n                    ),\n                    name: Joi.string().example('Model Validation'),\n                    description: Joi.string().example(\n                      'Validate the AI model performance and fairness'\n                    ),\n                    type: Joi.string().example('task'),\n                    dependencies_requires: Joi.array()\n                      .items(Joi.string())\n                      .example(['60d21bbfe3d5d533d9fc1e4e']),\n                    dependencies_requiredBy: Joi.array().items(\n                      Joi.object({\n                        _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4f'),\n                        workflowTemplateId: Joi.string().example(\n                          '60d21bbfe3d5d533d9fc1e4d'\n                        ),\n                        name: Joi.string().example('Model Deployment'),\n                        description: Joi.string().example(\n                          'Deploy the validated AI model'\n                        ),\n                        type: Joi.string().example('approval'),\n                        dependencies_requires: Joi.array()\n                          .items(Joi.string())\n                          .example(['60d21bbfe3d5d533d9fc1e4c']),\n                        metadata: Joi.object().example({ priority: 'high' }),\n                        createdAt: Joi.date().example(\n                          '2024-03-20T10:00:00.000Z'\n                        ),\n                        updatedAt: Joi.date().example(\n                          '2024-03-20T10:00:00.000Z'\n                        )\n                      })\n                    ),\n                    metadata: Joi.object().example({\n                      priority: 'high',\n                      category: 'validation'\n                    }),\n                    createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                    updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                  })\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'PUT',\n        path: '/api/v1/checklist-item-templates/{id}',\n        handler: updateChecklistItemTemplateHandler,\n        options: {\n          tags: ['api', 'checklist-item-template'],\n          description: 'Update a checklist item template',\n          validate: {\n            params: Joi.object({\n              id: Joi.string()\n                .required()\n                .description('Checklist item template ID')\n            }),\n            payload: updateChecklistItemTemplateSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully updated checklist item template',\n                  schema: Joi.object({\n                    _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                    workflowTemplateId: Joi.string().example(\n                      '60d21bbfe3d5d533d9fc1e4d'\n                    ),\n                    name: Joi.string().example('Model Validation'),\n                    description: Joi.string().example(\n                      'Validate the AI model performance and fairness'\n                    ),\n                    type: Joi.string().example('task'),\n                    dependencies_requires: Joi.array()\n                      .items(Joi.string())\n                      .example(['60d21bbfe3d5d533d9fc1e4e']),\n                    dependencies_requiredBy: Joi.array().items(\n                      Joi.object({\n                        _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4f'),\n                        workflowTemplateId: Joi.string().example(\n                          '60d21bbfe3d5d533d9fc1e4d'\n                        ),\n                        name: Joi.string().example('Model Deployment'),\n                        description: Joi.string().example(\n                          'Deploy the validated AI model'\n                        ),\n                        type: Joi.string().example('approval'),\n                        dependencies_requires: Joi.array()\n                          .items(Joi.string())\n                          .example(['60d21bbfe3d5d533d9fc1e4c']),\n                        metadata: Joi.object().example({ priority: 'high' }),\n                        createdAt: Joi.date().example(\n                          '2024-03-20T10:00:00.000Z'\n                        ),\n                        updatedAt: Joi.date().example(\n                          '2024-03-20T10:00:00.000Z'\n                        )\n                      })\n                    ),\n                    metadata: Joi.object().example({\n                      priority: 'high',\n                      category: 'validation'\n                    }),\n                    createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                    updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                  })\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'DELETE',\n        path: '/api/v1/checklist-item-templates/{id}',\n        handler: deleteChecklistItemTemplateHandler,\n        options: {\n          tags: ['api', 'checklist-item-template'],\n          description: 'Delete a checklist item template',\n          validate: {\n            params: Joi.object({\n              id: Joi.string()\n                .required()\n                .description('Checklist item template ID')\n            })\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                204: {\n                  description: 'Successfully deleted checklist item template'\n                },\n                404: { description: 'Template not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/checklist-item-templates',\n        handler: getAllChecklistItemTemplatesHandler,\n        options: {\n          tags: ['api', 'checklist-item-template'],\n          description: 'Get all checklist item templates',\n          validate: {\n            query: Joi.object({\n              workflowTemplateId: Joi.string()\n                .description('Filter by workflow template ID')\n                .example('60d21bbfe3d5d533d9fc1e4d'),\n              governanceTemplateId: Joi.string()\n                .description('Filter by governance template ID')\n                .example('60d21bbfe3d5d533d9fc1e4c')\n            })\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description:\n                    'Successfully retrieved checklist item templates',\n                  schema: Joi.array().items(\n                    Joi.object({\n                      _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4c'),\n                      workflowTemplateId: Joi.string().example(\n                        '60d21bbfe3d5d533d9fc1e4d'\n                      ),\n                      name: Joi.string().example('Model Validation'),\n                      description: Joi.string().example(\n                        'Validate the AI model performance and fairness'\n                      ),\n                      type: Joi.string().example('task'),\n                      dependencies_requires: Joi.array()\n                        .items(Joi.string())\n                        .example(['60d21bbfe3d5d533d9fc1e4e']),\n                      dependencies_requiredBy: Joi.array().items(\n                        Joi.object({\n                          _id: Joi.string().example('60d21bbfe3d5d533d9fc1e4f'),\n                          workflowTemplateId: Joi.string().example(\n                            '60d21bbfe3d5d533d9fc1e4d'\n                          ),\n                          name: Joi.string().example('Model Deployment'),\n                          description: Joi.string().example(\n                            'Deploy the validated AI model'\n                          ),\n                          type: Joi.string().example('approval'),\n                          dependencies_requires: Joi.array()\n                            .items(Joi.string())\n                            .example(['60d21bbfe3d5d533d9fc1e4c']),\n                          metadata: Joi.object().example({ priority: 'high' }),\n                          createdAt: Joi.date().example(\n                            '2024-03-20T10:00:00.000Z'\n                          ),\n                          updatedAt: Joi.date().example(\n                            '2024-03-20T10:00:00.000Z'\n                          )\n                        })\n                      ),\n                      metadata: Joi.object().example({\n                        priority: 'high',\n                        category: 'validation'\n                      }),\n                      createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n                      updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n                    })\n                  )\n                },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      }\n    ])\n  }\n}\n\n\n--- src/api/checklist-item-templates/model.js ---\nimport { ObjectId } from 'mongodb'\n\n/**\n * @typedef {object} ChecklistItemTemplate\n * @property {import('mongodb').ObjectId} _id - The unique identifier\n * @property {import('mongodb').ObjectId} workflowTemplateId - Reference to parent WorkflowTemplate (required)\n * @property {string} name - Display name of the checklist item (required)\n * @property {string} [description] - Detailed description\n * @property {string} type - Type of checklist item (e.g. 'approval', 'document', 'task') (required)\n * @property {import('mongodb').ObjectId[]} dependencies_requires - Array of checklist item template IDs that this item depends on\n * @property {object} [metadata] - Additional configuration\n * @property {number} [order] - Manual ordering position for the checklist item\n * @property {Date} createdAt - When the template was created (required)\n * @property {Date} updatedAt - When the template was last updated (required)\n */\n\n/**\n * Creates a new checklist item template\n * @param {object} data - The template data\n * @param {string|import('mongodb').ObjectId} data.workflowTemplateId - Reference to parent WorkflowTemplate\n * @param {string} data.name - Display name of the checklist item\n * @param {string} data.type - Type of checklist item\n * @param {string} [data.description] - Detailed description\n * @param {string[]} [data.dependencies_requires] - Array of checklist item template IDs that this item depends on\n * @param {object} [data.metadata] - Additional configuration\n * @param {number} data.order - Manual ordering position for the checklist item\n * @returns {Omit<ChecklistItemTemplate, '_id'>}\n */\nexport function createChecklistItemTemplate(data) {\n  const now = new Date()\n  return {\n    workflowTemplateId:\n      typeof data.workflowTemplateId === 'string'\n        ? new ObjectId(data.workflowTemplateId)\n        : data.workflowTemplateId,\n    name: data.name,\n    description: data.description,\n    type: data.type,\n    dependencies_requires: (data.dependencies_requires ?? []).map((id) =>\n      typeof id === 'string' ? new ObjectId(id) : id\n    ),\n    metadata: data.metadata ?? {},\n    order: data.order,\n    createdAt: now,\n    updatedAt: now\n  }\n}\n\n\n--- src/api/checklist-item-templates/validation.js ---\nimport Joi from 'joi'\nimport { ObjectId } from 'mongodb'\n\n// Custom Joi extension for MongoDB ObjectId validation\nconst objectIdSchema = Joi.string().custom((value, helpers) => {\n  if (!ObjectId.isValid(value)) {\n    return helpers.error('any.invalid')\n  }\n  return value\n}, 'MongoDB ObjectId validation')\n\nexport const createChecklistItemTemplateSchema = Joi.object({\n  workflowTemplateId: objectIdSchema.required(),\n  name: Joi.string().required(),\n  description: Joi.string().allow(''),\n  type: Joi.string().required().valid('approval', 'document', 'task'),\n  dependencies_requires: Joi.array().items(objectIdSchema).default([]),\n  metadata: Joi.object().default({})\n})\n\nexport const updateChecklistItemTemplateSchema = Joi.object({\n  name: Joi.string(),\n  description: Joi.string().allow(''),\n  type: Joi.string().valid('approval', 'document', 'task'),\n  dependencies_requires: Joi.array().items(objectIdSchema),\n  metadata: Joi.object(),\n  order: Joi.number().integer().min(0)\n}).min(1)\n\nexport const idSchema = Joi.object({\n  id: objectIdSchema.required().description('MongoDB ObjectId')\n})\n\n\n--- tests/api/checklist-item-templates.spec.js ---\n/* eslint-disable */\nimport { test, expect } from '@playwright/test'\n\nconst getUniqueId = () =>\n  `test_${Date.now()}_${Math.random().toString(36).substring(2, 7)}`\n\nconst createChecklistItemTemplate = (uniqueId) => ({\n  name: `Test Checklist Item Template ${uniqueId}`,\n  description: 'Test checklist item template for E2E testing',\n  type: 'approval',\n  metadata: {\n    approver: 'manager',\n    requiredEvidence: true\n  }\n})\n\ntest.describe('Checklist Item Template API', () => {\n  let governanceTemplateId\n  let workflowTemplateId\n  let checklistItemTemplateId\n  let dependentTemplateId\n  let dependencyTemplateId\n  const uniqueId = getUniqueId()\n  const checklistItemTemplate = createChecklistItemTemplate(uniqueId)\n\n  test.beforeAll(async ({ request }) => {\n    // Create a governance template for testing\n    const govResponse = await request.post('/api/v1/governance-templates', {\n      data: {\n        name: `Test Governance Template ${uniqueId}`,\n        version: '1.0.0',\n        description: 'Test governance template for checklist tests'\n      }\n    })\n\n    if (!govResponse.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create governance template: ${await govResponse.text()}`\n      })\n    }\n    expect(govResponse.ok()).toBeTruthy()\n\n    const govData = await govResponse.json()\n    governanceTemplateId = govData._id\n\n    // Create a workflow template for testing\n    const workflowResponse = await request.post('/api/v1/workflow-templates', {\n      data: {\n        name: `Test Workflow Template ${uniqueId}`,\n        description: 'Test workflow template for checklist tests',\n        governanceTemplateId,\n        metadata: {\n          category: 'test',\n          priority: 'high'\n        }\n      }\n    })\n\n    if (!workflowResponse.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create workflow template: ${await workflowResponse.text()}`\n      })\n    }\n    expect(workflowResponse.ok()).toBeTruthy()\n\n    const workflowData = await workflowResponse.json()\n    workflowTemplateId = workflowData._id\n  })\n\n  test.afterAll(async ({ request }) => {\n    // Clean up all created templates\n    const templatesForDeletion = [\n      dependentTemplateId,\n      dependencyTemplateId,\n      checklistItemTemplateId\n    ].filter(Boolean)\n\n    for (const id of templatesForDeletion) {\n      await request.delete(`/api/v1/checklist-item-templates/${id}`)\n    }\n\n    if (workflowTemplateId) {\n      await request.delete(`/api/v1/workflow-templates/${workflowTemplateId}`)\n    }\n    if (governanceTemplateId) {\n      await request.delete(\n        `/api/v1/governance-templates/${governanceTemplateId}`\n      )\n    }\n  })\n\n  test('should create a new checklist item template', async ({ request }) => {\n    const checklistData = {\n      ...checklistItemTemplate,\n      workflowTemplateId,\n      dependencies_requires: []\n    }\n\n    const response = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData\n    })\n\n    if (!response.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create checklist item template: ${await response.text()}`\n      })\n    }\n    expect(response.ok()).toBeTruthy()\n\n    const data = await response.json()\n    expect(data).toHaveProperty('_id')\n    expect(data.name).toBe(checklistItemTemplate.name)\n    expect(data.workflowTemplateId).toBe(workflowTemplateId)\n\n    checklistItemTemplateId = data._id\n  })\n\n  test('should create a dependency template and update main template to depend on it', async ({\n    request\n  }) => {\n    // First create a template that will be a dependency\n    const dependencyData = {\n      name: `Dependency Template ${uniqueId}`,\n      description: 'This template will be a dependency',\n      type: 'approval',\n      workflowTemplateId,\n      dependencies_requires: []\n    }\n\n    const dependencyResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: dependencyData\n      }\n    )\n\n    expect(dependencyResponse.ok()).toBeTruthy()\n    const dependency = await dependencyResponse.json()\n    dependencyTemplateId = dependency._id\n\n    // Update the main template to depend on the new template\n    const updateResponse = await request.put(\n      `/api/v1/checklist-item-templates/${checklistItemTemplateId}`,\n      {\n        data: {\n          dependencies_requires: [dependencyTemplateId]\n        }\n      }\n    )\n\n    expect(updateResponse.ok()).toBeTruthy()\n    const updatedTemplate = await updateResponse.json()\n\n    // Verify dependencies_requires is populated with full template data\n    expect(updatedTemplate.dependencies_requires).toHaveLength(1)\n    expect(updatedTemplate.dependencies_requires[0]).toMatchObject({\n      _id: dependencyTemplateId,\n      name: `Dependency Template ${uniqueId}`\n    })\n  })\n\n  test('should create a dependent template that requires the main template', async ({\n    request\n  }) => {\n    const dependentData = {\n      name: `Dependent Template ${uniqueId}`,\n      description: 'This template depends on the main template',\n      type: 'approval',\n      workflowTemplateId,\n      dependencies_requires: [checklistItemTemplateId]\n    }\n\n    const dependentResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: dependentData\n      }\n    )\n\n    expect(dependentResponse.ok()).toBeTruthy()\n    const dependent = await dependentResponse.json()\n    dependentTemplateId = dependent._id\n\n    // Verify the dependency relationship by getting the main template\n    const mainTemplateResponse = await request.get(\n      `/api/v1/checklist-item-templates/${checklistItemTemplateId}`\n    )\n\n    expect(mainTemplateResponse.ok()).toBeTruthy()\n    const mainTemplate = await mainTemplateResponse.json()\n\n    // Check that the dependent template appears in dependencies_requiredBy\n    expect(mainTemplate.dependencies_requiredBy).toContainEqual(\n      expect.objectContaining({\n        _id: dependentTemplateId,\n        name: `Dependent Template ${uniqueId}`\n      })\n    )\n  })\n\n  test('should get a template with full dependency information', async ({\n    request\n  }) => {\n    const response = await request.get(\n      `/api/v1/checklist-item-templates/${checklistItemTemplateId}`\n    )\n\n    expect(response.ok()).toBeTruthy()\n    const template = await response.json()\n\n    // Verify dependencies_requires is populated\n    expect(template.dependencies_requires).toHaveLength(1)\n    expect(template.dependencies_requires[0]).toMatchObject({\n      _id: dependencyTemplateId,\n      name: `Dependency Template ${uniqueId}`\n    })\n\n    // Verify dependencies_requiredBy is populated\n    expect(template.dependencies_requiredBy).toHaveLength(1)\n    expect(template.dependencies_requiredBy[0]).toMatchObject({\n      _id: dependentTemplateId,\n      name: `Dependent Template ${uniqueId}`\n    })\n  })\n\n  test('should update dependencies and verify relationships', async ({\n    request\n  }) => {\n    // Remove all dependencies\n    const updateResponse = await request.put(\n      `/api/v1/checklist-item-templates/${checklistItemTemplateId}`,\n      {\n        data: {\n          dependencies_requires: []\n        }\n      }\n    )\n\n    expect(updateResponse.ok()).toBeTruthy()\n    const updatedTemplate = await updateResponse.json()\n\n    // Verify dependencies_requires is empty\n    expect(updatedTemplate.dependencies_requires).toHaveLength(0)\n\n    // But dependencies_requiredBy should still show templates that depend on this one\n    expect(updatedTemplate.dependencies_requiredBy).toHaveLength(1)\n    expect(updatedTemplate.dependencies_requiredBy[0]).toMatchObject({\n      _id: dependentTemplateId,\n      name: `Dependent Template ${uniqueId}`\n    })\n  })\n\n  test('should remove deleted template from dependencies_requires of other templates', async ({\n    request\n  }) => {\n    // Create template A that will be a dependency\n    const templateAResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Template A ${uniqueId}`,\n          description: 'This template will be deleted',\n          type: 'approval',\n          workflowTemplateId,\n          dependencies_requires: []\n        }\n      }\n    )\n    expect(templateAResponse.ok()).toBeTruthy()\n    const templateA = await templateAResponse.json()\n\n    // Create template B that depends on template A\n    const templateBResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Template B ${uniqueId}`,\n          description: 'This template depends on Template A',\n          type: 'approval',\n          workflowTemplateId,\n          dependencies_requires: [templateA._id]\n        }\n      }\n    )\n    expect(templateBResponse.ok()).toBeTruthy()\n    const templateB = await templateBResponse.json()\n\n    // Create template C that also depends on template A\n    const templateCResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Template C ${uniqueId}`,\n          description: 'This template also depends on Template A',\n          type: 'approval',\n          workflowTemplateId,\n          dependencies_requires: [templateA._id]\n        }\n      }\n    )\n    expect(templateCResponse.ok()).toBeTruthy()\n    const templateC = await templateCResponse.json()\n\n    // Delete template A\n    const deleteResponse = await request.delete(\n      `/api/v1/checklist-item-templates/${templateA._id}`\n    )\n    expect(deleteResponse.ok()).toBeTruthy()\n\n    // Verify template B no longer has template A in its dependencies\n    const templateBAfterResponse = await request.get(\n      `/api/v1/checklist-item-templates/${templateB._id}`\n    )\n    expect(templateBAfterResponse.ok()).toBeTruthy()\n    const templateBAfter = await templateBAfterResponse.json()\n    expect(templateBAfter.dependencies_requires).toHaveLength(0)\n\n    // Verify template C no longer has template A in its dependencies\n    const templateCAfterResponse = await request.get(\n      `/api/v1/checklist-item-templates/${templateC._id}`\n    )\n    expect(templateCAfterResponse.ok()).toBeTruthy()\n    const templateCAfter = await templateCAfterResponse.json()\n    expect(templateCAfter.dependencies_requires).toHaveLength(0)\n\n    // Clean up\n    await request.delete(`/api/v1/checklist-item-templates/${templateB._id}`)\n    await request.delete(`/api/v1/checklist-item-templates/${templateC._id}`)\n  })\n\n  test('should filter checklist item templates by workflowTemplateId', async ({\n    request\n  }) => {\n    // Create another workflow template for testing filtering\n    const anotherWorkflowResponse = await request.post(\n      '/api/v1/workflow-templates',\n      {\n        data: {\n          name: `Another Workflow Template ${uniqueId}`,\n          description: 'Another workflow template for filter tests',\n          governanceTemplateId,\n          metadata: { test: true }\n        }\n      }\n    )\n    expect(anotherWorkflowResponse.ok()).toBeTruthy()\n    const anotherWorkflowId = (await anotherWorkflowResponse.json())._id\n\n    // Create a checklist item for the new workflow\n    const anotherChecklistResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Another Checklist Template ${uniqueId}`,\n          description: 'Another checklist template for filter tests',\n          type: 'approval',\n          workflowTemplateId: anotherWorkflowId,\n          dependencies_requires: []\n        }\n      }\n    )\n    expect(anotherChecklistResponse.ok()).toBeTruthy()\n    const anotherChecklistId = (await anotherChecklistResponse.json())._id\n\n    // Test filtering by original workflowTemplateId\n    const filterResponse = await request.get(\n      `/api/v1/checklist-item-templates?workflowTemplateId=${workflowTemplateId}`\n    )\n    expect(filterResponse.ok()).toBeTruthy()\n    const filteredData = await filterResponse.json()\n\n    // Verify filtered results\n    expect(Array.isArray(filteredData)).toBeTruthy()\n    expect(filteredData.length).toBeGreaterThan(0)\n    expect(\n      filteredData.every(\n        (template) => template.workflowTemplateId === workflowTemplateId\n      )\n    ).toBeTruthy()\n    expect(\n      filteredData.some(\n        (template) => template.workflowTemplateId === anotherWorkflowId\n      )\n    ).toBeFalsy()\n\n    // Clean up\n    await request.delete(\n      `/api/v1/checklist-item-templates/${anotherChecklistId}`\n    )\n    await request.delete(`/api/v1/workflow-templates/${anotherWorkflowId}`)\n  })\n\n  test('should filter checklist item templates by governanceTemplateId', async ({\n    request\n  }) => {\n    // Create another workflow template under the same governance template\n    const anotherWorkflowResponse = await request.post(\n      '/api/v1/workflow-templates',\n      {\n        data: {\n          name: `Another Workflow Template ${uniqueId}`,\n          description: 'Another workflow template for filter tests',\n          governanceTemplateId,\n          metadata: { test: true }\n        }\n      }\n    )\n    expect(anotherWorkflowResponse.ok()).toBeTruthy()\n    const anotherWorkflowId = (await anotherWorkflowResponse.json())._id\n\n    // Create a checklist item for the new workflow\n    const anotherChecklistResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Another Checklist Template ${uniqueId}`,\n          description: 'Another checklist template for filter tests',\n          type: 'approval',\n          workflowTemplateId: anotherWorkflowId,\n          dependencies_requires: []\n        }\n      }\n    )\n    expect(anotherChecklistResponse.ok()).toBeTruthy()\n    const anotherChecklistId = (await anotherChecklistResponse.json())._id\n\n    // Create a different governance template and associated workflow/checklist\n    const differentGovResponse = await request.post(\n      '/api/v1/governance-templates',\n      {\n        data: {\n          name: `Different Governance Template ${uniqueId}`,\n          version: '1.0.0',\n          description: 'Different governance template for filter tests'\n        }\n      }\n    )\n    expect(differentGovResponse.ok()).toBeTruthy()\n    const differentGovId = (await differentGovResponse.json())._id\n\n    const differentWorkflowResponse = await request.post(\n      '/api/v1/workflow-templates',\n      {\n        data: {\n          name: `Different Workflow Template ${uniqueId}`,\n          description: 'Different workflow template for filter tests',\n          governanceTemplateId: differentGovId,\n          metadata: { test: true }\n        }\n      }\n    )\n    expect(differentWorkflowResponse.ok()).toBeTruthy()\n    const differentWorkflowId = (await differentWorkflowResponse.json())._id\n\n    const differentChecklistResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Different Checklist Template ${uniqueId}`,\n          description: 'Different checklist template for filter tests',\n          type: 'approval',\n          workflowTemplateId: differentWorkflowId,\n          dependencies_requires: []\n        }\n      }\n    )\n    expect(differentChecklistResponse.ok()).toBeTruthy()\n    const differentChecklistId = (await differentChecklistResponse.json())._id\n\n    // Test filtering by original governanceTemplateId\n    const filterResponse = await request.get(\n      `/api/v1/checklist-item-templates?governanceTemplateId=${governanceTemplateId}`\n    )\n    expect(filterResponse.ok()).toBeTruthy()\n    const filteredData = await filterResponse.json()\n\n    // Verify filtered results\n    expect(Array.isArray(filteredData)).toBeTruthy()\n    expect(filteredData.length).toBeGreaterThanOrEqual(2) // Should have at least 2 items (one from each workflow)\n\n    // All items should be from workflows in the original governance template\n    const workflowIds = [workflowTemplateId, anotherWorkflowId]\n    expect(\n      filteredData.every((template) =>\n        workflowIds.includes(template.workflowTemplateId)\n      )\n    ).toBeTruthy()\n\n    // Should not include items from the different governance template\n    expect(\n      filteredData.some(\n        (template) => template.workflowTemplateId === differentWorkflowId\n      )\n    ).toBeFalsy()\n\n    // Clean up\n    await request.delete(\n      `/api/v1/checklist-item-templates/${anotherChecklistId}`\n    )\n    await request.delete(\n      `/api/v1/checklist-item-templates/${differentChecklistId}`\n    )\n    await request.delete(`/api/v1/workflow-templates/${anotherWorkflowId}`)\n    await request.delete(`/api/v1/workflow-templates/${differentWorkflowId}`)\n    await request.delete(`/api/v1/governance-templates/${differentGovId}`)\n  })\n\n  test('should filter out self-dependency when updating dependencies_requires', async ({\n    request\n  }) => {\n    // Create a template that will try to depend on itself\n    const templateResponse = await request.post(\n      '/api/v1/checklist-item-templates',\n      {\n        data: {\n          name: `Self Dependency Test Template ${uniqueId}`,\n          description: 'Template that will try to depend on itself',\n          type: 'approval',\n          workflowTemplateId,\n          dependencies_requires: []\n        }\n      }\n    )\n    expect(templateResponse.ok()).toBeTruthy()\n    const template = await templateResponse.json()\n\n    // Try to update the template to depend on itself\n    const updateResponse = await request.put(\n      `/api/v1/checklist-item-templates/${template._id}`,\n      {\n        data: {\n          dependencies_requires: [template._id]\n        }\n      }\n    )\n    expect(updateResponse.ok()).toBeTruthy()\n    const updatedTemplate = await updateResponse.json()\n\n    // Verify dependencies_requires is empty since self-dependency was filtered out\n    expect(updatedTemplate.dependencies_requires).toHaveLength(0)\n\n    // Clean up\n    await request.delete(`/api/v1/checklist-item-templates/${template._id}`)\n  })\n\n  test('should reorder checklist item templates after deletion', async ({\n    request\n  }) => {\n    // Create three more checklist item templates with sequential order\n    const checklistData1 = {\n      name: `Test Checklist Item Template 1 ${uniqueId}`,\n      description: 'Test checklist item template 1',\n      type: 'approval',\n      workflowTemplateId\n    }\n    const checklistData2 = {\n      name: `Test Checklist Item Template 2 ${uniqueId}`,\n      description: 'Test checklist item template 2',\n      type: 'approval',\n      workflowTemplateId\n    }\n    const checklistData3 = {\n      name: `Test Checklist Item Template 3 ${uniqueId}`,\n      description: 'Test checklist item template 3',\n      type: 'approval',\n      workflowTemplateId\n    }\n\n    // Create the checklist item templates\n    const response1 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData1\n    })\n    const data1 = await response1.json()\n    const checklistId1 = data1._id\n    const order1 = data1.order\n\n    const response2 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData2\n    })\n    const data2 = await response2.json()\n    const checklistId2 = data2._id\n    const order2 = data2.order\n\n    const response3 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData3\n    })\n    const data3 = await response3.json()\n    const checklistId3 = data3._id\n    const order3 = data3.order\n\n    // Verify the initial orders are sequential\n    expect(order2).toBe(order1 + 1)\n    expect(order3).toBe(order2 + 1)\n\n    // Delete the middle checklist item template\n    const deleteResponse = await request.delete(\n      `/api/v1/checklist-item-templates/${checklistId2}`\n    )\n    expect(deleteResponse.ok()).toBeTruthy()\n\n    // Verify the first checklist item template's order remains unchanged\n    const getResponse1 = await request.get(\n      `/api/v1/checklist-item-templates/${checklistId1}`\n    )\n    const updatedData1 = await getResponse1.json()\n    expect(updatedData1.order).toBe(order1)\n\n    // Verify the third checklist item template's order has been decremented\n    const getResponse3 = await request.get(\n      `/api/v1/checklist-item-templates/${checklistId3}`\n    )\n    const updatedData3 = await getResponse3.json()\n    expect(updatedData3.order).toBe(order3 - 1)\n\n    // Clean up\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId1}`)\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId3}`)\n  })\n\n  test('should reorder checklist item templates when updating order', async ({\n    request\n  }) => {\n    // Create three checklist item templates with sequential order\n    const checklistData1 = {\n      name: `Test Checklist Item Template 1 ${uniqueId}`,\n      description: 'Test checklist item template 1',\n      type: 'approval',\n      workflowTemplateId\n    }\n    const checklistData2 = {\n      name: `Test Checklist Item Template 2 ${uniqueId}`,\n      description: 'Test checklist item template 2',\n      type: 'approval',\n      workflowTemplateId\n    }\n    const checklistData3 = {\n      name: `Test Checklist Item Template 3 ${uniqueId}`,\n      description: 'Test checklist item template 3',\n      type: 'approval',\n      workflowTemplateId\n    }\n\n    // Create the checklist item templates\n    const response1 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData1\n    })\n    const data1 = await response1.json()\n    const checklistId1 = data1._id\n    const order1 = data1.order\n\n    const response2 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData2\n    })\n    const data2 = await response2.json()\n    const checklistId2 = data2._id\n    const order2 = data2.order\n\n    const response3 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData3\n    })\n    const data3 = await response3.json()\n    const checklistId3 = data3._id\n    const order3 = data3.order\n\n    // Verify the initial orders are sequential\n    expect(order2).toBe(order1 + 1)\n    expect(order3).toBe(order2 + 1)\n\n    // Move the first checklist item template to the end (order 2)\n    const updateResponse = await request.put(\n      `/api/v1/checklist-item-templates/${checklistId1}`,\n      {\n        data: { order: order3 }\n      }\n    )\n    expect(updateResponse.ok()).toBeTruthy()\n\n    // Verify the updated order of the first checklist item template\n    const getResponse1 = await request.get(\n      `/api/v1/checklist-item-templates/${checklistId1}`\n    )\n    const updatedData1 = await getResponse1.json()\n    expect(updatedData1.order).toBe(order3)\n\n    // Verify the second checklist item template's order has been decremented\n    const getResponse2 = await request.get(\n      `/api/v1/checklist-item-templates/${checklistId2}`\n    )\n    const updatedData2 = await getResponse2.json()\n    expect(updatedData2.order).toBe(order2 - 1)\n\n    // Verify the third checklist item template's order has been decremented\n    const getResponse3 = await request.get(\n      `/api/v1/checklist-item-templates/${checklistId3}`\n    )\n    const updatedData3 = await getResponse3.json()\n    expect(updatedData3.order).toBe(order3 - 1)\n\n    // Clean up\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId1}`)\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId2}`)\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId3}`)\n  })\n\n  test('should return checklist item templates in order when filtering by workflowTemplateId', async ({\n    request\n  }) => {\n    // Create three checklist item templates with different orders\n    const orderTestUniqueId = getUniqueId()\n\n    // Create checklist item templates with specific orders\n    const checklistData1 = {\n      name: `Order Test Checklist 1 ${orderTestUniqueId}`,\n      description: 'First checklist for order test',\n      type: 'approval',\n      workflowTemplateId\n    }\n    const checklistData2 = {\n      name: `Order Test Checklist 2 ${orderTestUniqueId}`,\n      description: 'Second checklist for order test',\n      type: 'approval',\n      workflowTemplateId\n    }\n    const checklistData3 = {\n      name: `Order Test Checklist 3 ${orderTestUniqueId}`,\n      description: 'Third checklist for order test',\n      type: 'approval',\n      workflowTemplateId\n    }\n\n    // Create the checklist item templates\n    const response1 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData1\n    })\n    const data1 = await response1.json()\n    const checklistId1 = data1._id\n    const order1 = data1.order\n\n    const response2 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData2\n    })\n    const data2 = await response2.json()\n    const checklistId2 = data2._id\n    const order2 = data2.order\n\n    const response3 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData3\n    })\n    const data3 = await response3.json()\n    const checklistId3 = data3._id\n    const order3 = data3.order\n\n    // Verify the initial orders are sequential\n    expect(order2).toBe(order1 + 1)\n    expect(order3).toBe(order2 + 1)\n\n    // Reorder the templates: move the third template to the beginning\n    await request.put(`/api/v1/checklist-item-templates/${checklistId3}`, {\n      data: { order: 0 }\n    })\n\n    // Get all checklist item templates filtered by workflowTemplateId\n    const filterResponse = await request.get(\n      `/api/v1/checklist-item-templates?workflowTemplateId=${workflowTemplateId}`\n    )\n    expect(filterResponse.ok()).toBeTruthy()\n    const filteredData = await filterResponse.json()\n\n    // Find our test templates in the filtered results\n    const testTemplates = filteredData.filter(\n      (template) =>\n        template._id === checklistId1 ||\n        template._id === checklistId2 ||\n        template._id === checklistId3\n    )\n\n    // Verify they are sorted by order\n    for (let i = 1; i < testTemplates.length; i++) {\n      expect(testTemplates[i - 1].order).toBeLessThanOrEqual(\n        testTemplates[i].order\n      )\n    }\n\n    // Verify the third template is now first in our test templates\n    const sortedIds = testTemplates.map((t) => t._id)\n    expect(sortedIds.indexOf(checklistId3)).toBeLessThan(\n      sortedIds.indexOf(checklistId1)\n    )\n    expect(sortedIds.indexOf(checklistId3)).toBeLessThan(\n      sortedIds.indexOf(checklistId2)\n    )\n\n    // Clean up the test checklist item templates\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId1}`)\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId2}`)\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId3}`)\n  })\n\n  test('should prevent duplicate order numbers', async ({ request }) => {\n    // Create first checklist item template\n    const checklistData1 = {\n      name: `Test Checklist Item Template 1 ${uniqueId}`,\n      description: 'Test checklist item template 1',\n      type: 'approval',\n      workflowTemplateId\n    }\n\n    const response1 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData1\n    })\n    expect(response1.ok()).toBeTruthy()\n    const data1 = await response1.json()\n    const checklistId1 = data1._id\n    const order1 = data1.order\n\n    // Try to update another template to have the same order\n    const checklistData2 = {\n      name: `Test Checklist Item Template 2 ${uniqueId}`,\n      description: 'Test checklist item template 2',\n      type: 'approval',\n      workflowTemplateId\n    }\n\n    const response2 = await request.post('/api/v1/checklist-item-templates', {\n      data: checklistData2\n    })\n    expect(response2.ok()).toBeTruthy()\n    const data2 = await response2.json()\n    const checklistId2 = data2._id\n\n    // Try to update second template to have same order as first\n    const updateResponse = await request.put(\n      `/api/v1/checklist-item-templates/${checklistId2}`,\n      {\n        data: { order: order1 }\n      }\n    )\n    expect(updateResponse.ok()).toBeFalsy()\n    expect(updateResponse.status()).toBe(400)\n\n    const errorData = await updateResponse.json()\n    expect(errorData.message).toBe('Duplicate order number detected')\n\n    // Clean up\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId1}`)\n    await request.delete(`/api/v1/checklist-item-templates/${checklistId2}`)\n  })\n})\n"
    },
    {
      "chunk_id": "project_management",
      "description": "Functionality for creating and managing projects based on governance templates",
      "files": [
        "src/api/projects/controller.js",
        "src/api/projects/index.js",
        "src/api/projects/model.js",
        "src/api/projects/validation.js",
        "tests/api/project-crud.spec.js"
      ],
      "content": "\n\n--- src/api/projects/controller.js ---\nimport { createProject } from './model.js'\nimport Boom from '@hapi/boom'\nimport { ObjectId } from 'mongodb'\n\n/**\n * Creates checklist item instances for all workflow instances\n * @param {import('mongodb').Db} db - MongoDB database instance\n * @param {import('mongodb').ObjectId[]} workflowInstanceIds - Array of workflow instance IDs\n * @param {Map<string, import('mongodb').ObjectId>} workflowTemplateToInstanceMap - Map of workflow template IDs to instance IDs\n * @param {Set<string>} selectedWorkflowIds - Set of selected workflow template IDs\n * @returns {Promise<Map<string, import('mongodb').ObjectId>>} Map of template IDs to instance IDs\n */\nasync function createAllChecklistItemInstances(\n  db,\n  workflowInstanceIds,\n  workflowTemplateToInstanceMap,\n  selectedWorkflowIds\n) {\n  // Create a map to store template ID to instance ID mappings\n  const templateToInstanceMap = new Map()\n\n  // Get all templates for all selected workflows\n  const templates = await db\n    .collection('checklistItemTemplates')\n    .find({\n      workflowTemplateId: {\n        $in: Array.from(selectedWorkflowIds).map((id) => new ObjectId(id))\n      }\n    })\n    .toArray()\n\n  // Create instances for each template\n  for (const template of templates) {\n    const workflowInstanceId = workflowTemplateToInstanceMap.get(\n      template.workflowTemplateId.toString()\n    )\n    const instance = {\n      workflowInstanceId,\n      checklistItemTemplateId: template._id,\n      name: template.name,\n      description: template.description || '',\n      type: template.type,\n      status: 'incomplete',\n      dependencies_requires: [], // Will be populated in second phase\n      metadata: template.metadata || {},\n      order: template.order || 0,\n      createdAt: new Date(),\n      updatedAt: new Date()\n    }\n\n    const result = await db\n      .collection('checklistItemInstances')\n      .insertOne(instance)\n    templateToInstanceMap.set(template._id.toString(), result.insertedId)\n  }\n\n  return templateToInstanceMap\n}\n\n/**\n * Updates dependencies for all checklist item instances\n * @param {import('mongodb').Db} db - MongoDB database instance\n * @param {Map<string, import('mongodb').ObjectId>} templateToInstanceMap - Map of template IDs to instance IDs\n * @param {Set<string>} selectedWorkflowIds - Set of selected workflow template IDs\n * @returns {Promise<void>}\n */\nasync function updateAllInstanceDependencies(\n  db,\n  templateToInstanceMap,\n  selectedWorkflowIds\n) {\n  // Get all templates with their dependencies\n  const templates = await db\n    .collection('checklistItemTemplates')\n    .find({\n      workflowTemplateId: {\n        $in: Array.from(selectedWorkflowIds).map((id) => new ObjectId(id))\n      }\n    })\n    .toArray()\n\n  // Update dependencies for each template's instance\n  for (const template of templates) {\n    if (\n      template.dependencies_requires &&\n      template.dependencies_requires.length > 0\n    ) {\n      const validDependencies = []\n\n      for (const depId of template.dependencies_requires) {\n        // Find the template this dependency refers to\n        const depTemplate = await db\n          .collection('checklistItemTemplates')\n          .findOne({ _id: depId })\n\n        // Only include if its workflow was selected\n        if (\n          depTemplate &&\n          selectedWorkflowIds.has(depTemplate.workflowTemplateId.toString())\n        ) {\n          const instanceId = templateToInstanceMap.get(depId.toString())\n          if (instanceId) {\n            validDependencies.push(instanceId)\n          }\n        }\n      }\n\n      // Update the instance with valid dependencies\n      const instanceId = templateToInstanceMap.get(template._id.toString())\n      if (instanceId) {\n        await db.collection('checklistItemInstances').updateOne(\n          { _id: instanceId },\n          {\n            $set: {\n              dependencies_requires: validDependencies,\n              updatedAt: new Date()\n            }\n          }\n        )\n      }\n    }\n  }\n}\n\nexport const createProjectHandler = async (request, h) => {\n  try {\n    // Debug logging for incoming request\n    request.log(['debug', 'projects'], {\n      msg: 'Creating project with payload',\n      payload: request.payload\n    })\n\n    // Verify governanceTemplateId exists\n    const governanceTemplate = await request.db\n      .collection('governanceTemplates')\n      .findOne({ _id: new ObjectId(request.payload.governanceTemplateId) })\n\n    if (!governanceTemplate) {\n      request.log(['error', 'projects'], {\n        msg: 'Governance template not found',\n        governanceTemplateId: request.payload.governanceTemplateId\n      })\n      throw Boom.badRequest('Governance template not found')\n    }\n\n    // Verify all workflow template IDs exist and belong to the governance template\n    const workflowTemplates = await request.db\n      .collection('workflowTemplates')\n      .find({\n        _id: {\n          $in: request.payload.selectedWorkflowTemplateIds.map(\n            (id) => new ObjectId(id)\n          )\n        },\n        governanceTemplateId: new ObjectId(request.payload.governanceTemplateId)\n      })\n      .toArray()\n\n    if (\n      workflowTemplates.length !==\n      request.payload.selectedWorkflowTemplateIds.length\n    ) {\n      request.log(['error', 'projects'], {\n        msg: 'Invalid workflow templates',\n        selectedWorkflowTemplateIds:\n          request.payload.selectedWorkflowTemplateIds,\n        foundWorkflowTemplates: workflowTemplates.map((wt) => wt._id)\n      })\n      throw Boom.badRequest(\n        'One or more workflow templates are invalid or do not belong to the specified governance template'\n      )\n    }\n\n    // Create the project\n    const project = createProject(request.payload)\n\n    // Insert the project\n    let projectId\n    try {\n      const result = await request.db.collection('projects').insertOne(project)\n      projectId = result.insertedId\n    } catch (error) {\n      request.log(['error', 'projects'], {\n        msg: 'Failed to insert project',\n        error: error.message,\n        code: error.code,\n        codeName: error.codeName,\n        errInfo: error.errInfo\n      })\n      throw Boom.badRequest('Failed to create project')\n    }\n\n    // Create workflow instances\n    const workflowInstances = []\n    const selectedWorkflowIds = new Set(\n      request.payload.selectedWorkflowTemplateIds.map((id) => id.toString())\n    )\n    const workflowTemplateToInstanceMap = new Map()\n\n    try {\n      for (const template of workflowTemplates) {\n        const workflowInstance = {\n          projectId,\n          workflowTemplateId: template._id,\n          name: template.name,\n          description: template.description || '',\n          metadata: template.metadata || {},\n          order: template.order || 0,\n          status: 'active',\n          createdAt: new Date(),\n          updatedAt: new Date()\n        }\n\n        const workflowResult = await request.db\n          .collection('workflowInstances')\n          .insertOne(workflowInstance)\n\n        workflowInstances.push({\n          ...workflowInstance,\n          _id: workflowResult.insertedId\n        })\n\n        workflowTemplateToInstanceMap.set(\n          template._id.toString(),\n          workflowResult.insertedId\n        )\n      }\n\n      // Phase 1: Create all checklist item instances\n      const templateToInstanceMap = await createAllChecklistItemInstances(\n        request.db,\n        workflowInstances.map((wi) => wi._id),\n        workflowTemplateToInstanceMap,\n        selectedWorkflowIds\n      )\n\n      // Phase 2: Update all dependencies\n      await updateAllInstanceDependencies(\n        request.db,\n        templateToInstanceMap,\n        selectedWorkflowIds\n      )\n\n      return h\n        .response({ ...project, _id: projectId, workflowInstances })\n        .code(201)\n    } catch (error) {\n      request.log(['error', 'projects', 'workflows'], {\n        msg: 'Failed to create workflow instances',\n        error: error.message,\n        code: error.code,\n        codeName: error.codeName,\n        errInfo: error.errInfo\n      })\n      throw error\n    }\n  } catch (error) {\n    request.log(['error', 'projects'], {\n      msg: 'Failed to create project',\n      error: error.message,\n      stack: error.stack,\n      payload: request.payload\n    })\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getProjectHandler = async (request, h) => {\n  try {\n    const project = await request.db\n      .collection('projects')\n      .findOne({ _id: new ObjectId(request.params.id) })\n\n    if (!project) {\n      throw Boom.notFound('Project not found')\n    }\n\n    return h.response(project).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const updateProjectHandler = async (request, h) => {\n  try {\n    const result = await request.db\n      .collection('projects')\n      .findOneAndUpdate(\n        { _id: new ObjectId(request.params.id) },\n        { $set: { ...request.payload, updatedAt: new Date() } },\n        { returnDocument: 'after' }\n      )\n\n    if (!result) {\n      throw Boom.notFound('Project not found')\n    }\n\n    return h.response(result).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const deleteProjectHandler = async (request, h) => {\n  try {\n    const result = await request.db\n      .collection('projects')\n      .deleteOne({ _id: new ObjectId(request.params.id) })\n\n    if (result.deletedCount === 0) {\n      throw Boom.notFound('Project not found')\n    }\n\n    return h.response().code(204)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getAllProjectsHandler = async (request, h) => {\n  try {\n    const projects = await request.db.collection('projects').find().toArray()\n    return h.response(projects).code(200)\n  } catch (error) {\n    throw Boom.badRequest(error.message)\n  }\n}\n\n\n--- src/api/projects/index.js ---\nimport {\n  createProjectHandler,\n  getProjectHandler,\n  updateProjectHandler,\n  deleteProjectHandler,\n  getAllProjectsHandler\n} from './controller.js'\nimport {\n  createProjectSchema,\n  updateProjectSchema,\n  idSchema\n} from './validation.js'\nimport Joi from 'joi'\n\nconst projectResponseSchema = Joi.object({\n  _id: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .description('MongoDB ObjectId')\n    .example('60d21bbfe3d5d533d9fc1e4c'),\n  name: Joi.string().example('AI Model Development Project'),\n  description: Joi.string().example('Project for developing a new AI model'),\n  governanceTemplateId: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .example('60d21bbfe3d5d533d9fc1e4d'),\n  selectedWorkflowTemplateIds: Joi.array().items(\n    Joi.string()\n      .pattern(/^[0-9a-fA-F]{24}$/)\n      .example('60d21bbfe3d5d533d9fc1e4e')\n  ),\n  metadata: Joi.object().example({\n    priority: 'high',\n    department: 'AI Research'\n  }),\n  createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n  updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n})\n\n/**\n * @type { import('@hapi/hapi').Plugin<void> }\n */\nexport default {\n  name: 'project-routes',\n  register: (server) => {\n    server.route([\n      {\n        method: 'POST',\n        path: '/api/v1/projects',\n        handler: createProjectHandler,\n        options: {\n          tags: ['api', 'project'],\n          description: 'Create a new project',\n          validate: {\n            payload: createProjectSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                201: {\n                  description: 'Successfully created project',\n                  schema: projectResponseSchema\n                },\n                400: { description: 'Bad request' },\n                404: {\n                  description:\n                    'Governance template or workflow template not found'\n                }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/projects/{id}',\n        handler: getProjectHandler,\n        options: {\n          tags: ['api', 'project'],\n          description: 'Get a project by ID',\n          validate: {\n            params: idSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully retrieved project',\n                  schema: projectResponseSchema\n                },\n                404: { description: 'Project not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'PUT',\n        path: '/api/v1/projects/{id}',\n        handler: updateProjectHandler,\n        options: {\n          tags: ['api', 'project'],\n          description: 'Update a project',\n          validate: {\n            params: idSchema,\n            payload: updateProjectSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully updated project',\n                  schema: projectResponseSchema\n                },\n                404: { description: 'Project not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'DELETE',\n        path: '/api/v1/projects/{id}',\n        handler: deleteProjectHandler,\n        options: {\n          tags: ['api', 'project'],\n          description: 'Delete a project',\n          validate: {\n            params: idSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                204: { description: 'Successfully deleted project' },\n                404: { description: 'Project not found' },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'GET',\n        path: '/api/v1/projects',\n        handler: getAllProjectsHandler,\n        options: {\n          tags: ['api', 'project'],\n          description: 'Get all projects',\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully retrieved projects',\n                  schema: Joi.array().items(projectResponseSchema)\n                },\n                400: { description: 'Bad request' }\n              }\n            }\n          }\n        }\n      }\n    ])\n  }\n}\n\n\n--- src/api/projects/model.js ---\nimport { ObjectId } from 'mongodb'\n\n/**\n * @typedef {object} Project\n * @property {import('mongodb').ObjectId} _id - The unique identifier\n * @property {string} name - The name of the project (required)\n * @property {string} [description] - The description of the project\n * @property {import('mongodb').ObjectId} governanceTemplateId - Reference to the governance template (required)\n * @property {import('mongodb').ObjectId[]} selectedWorkflowTemplateIds - References to selected workflow templates (required)\n * @property {object} [metadata] - Additional project configuration\n * @property {Date} createdAt - When the project was created (required)\n * @property {Date} updatedAt - When the project was last updated (required)\n */\n\n/**\n * Creates a new project\n * @param {object} data - The project data\n * @param {string} data.name - The name of the project\n * @param {string} [data.description] - The description of the project\n * @param {string|import('mongodb').ObjectId} data.governanceTemplateId - Reference to the governance template\n * @param {(string|import('mongodb').ObjectId)[]} data.selectedWorkflowTemplateIds - References to selected workflow templates\n * @param {object} [data.metadata] - Additional project configuration\n * @returns {Omit<Project, '_id'>}\n */\nexport function createProject(data) {\n  const now = new Date()\n  const project = {\n    name: data.name,\n    description: data.description ?? '',\n    governanceTemplateId:\n      typeof data.governanceTemplateId === 'string'\n        ? new ObjectId(data.governanceTemplateId)\n        : data.governanceTemplateId,\n    selectedWorkflowTemplateIds: (data.selectedWorkflowTemplateIds ?? []).map(\n      (id) => (typeof id === 'string' ? new ObjectId(id) : id)\n    ),\n    metadata: data.metadata ?? {},\n    createdAt: now,\n    updatedAt: now\n  }\n\n  // Ensure all required fields are present and of correct type\n  if (!project.name || typeof project.name !== 'string') {\n    throw new Error('Invalid name')\n  }\n  if (!(project.governanceTemplateId instanceof ObjectId)) {\n    throw new Error('Invalid governanceTemplateId')\n  }\n  if (\n    !Array.isArray(project.selectedWorkflowTemplateIds) ||\n    !project.selectedWorkflowTemplateIds.every((id) => id instanceof ObjectId)\n  ) {\n    throw new Error('Invalid selectedWorkflowTemplateIds')\n  }\n  if (\n    !(project.createdAt instanceof Date) ||\n    !(project.updatedAt instanceof Date)\n  ) {\n    throw new Error('Invalid dates')\n  }\n\n  return project\n}\n\n\n--- src/api/projects/validation.js ---\nimport Joi from 'joi'\nimport { ObjectId } from 'mongodb'\nimport { logger } from '~/src/api/common/helpers/logging/logger.js'\n\n// Custom Joi extension for MongoDB ObjectId validation\nconst objectIdSchema = Joi.string().custom((value, helpers) => {\n  if (!ObjectId.isValid(value)) {\n    logger.error({ value }, 'Invalid ObjectId')\n    return helpers.error('any.invalid')\n  }\n  return value\n}, 'MongoDB ObjectId validation')\n\nexport const createProjectSchema = Joi.object({\n  name: Joi.string().required(),\n  description: Joi.string().empty('').default(''),\n  governanceTemplateId: objectIdSchema.required(),\n  selectedWorkflowTemplateIds: Joi.array().items(objectIdSchema).required(),\n  metadata: Joi.object().default({})\n}).error((errors) => {\n  logger.error({ errors }, 'Project validation errors')\n  return errors\n})\n\nexport const updateProjectSchema = Joi.object({\n  name: Joi.string(),\n  description: Joi.string().allow(''),\n  metadata: Joi.object()\n}).min(1)\n\nexport const idSchema = Joi.object({\n  id: objectIdSchema.required().description('MongoDB ObjectId')\n})\n\n\n--- tests/api/project-crud.spec.js ---\n/* eslint-disable */\nimport { test, expect } from '@playwright/test'\n\nconst getUniqueId = () =>\n  `test_${Date.now()}_${Math.random().toString(36).substring(2, 7)}`\n\nconst createProject = (uniqueId) => ({\n  name: `Test Project ${uniqueId}`,\n  description: 'Test project for E2E testing'\n})\n\n// E2E tests for Project CRUD operations\n// Base URL is set to /api/v1 via request fixture configuration\n// Test setup: create a GovernanceTemplate and two WorkflowTemplates\n\ntest.describe('Project API', () => {\n  let governanceTemplateId\n  let workflowTemplateIdA\n  let workflowTemplateIdB\n  let projectId\n  const uniqueId = getUniqueId()\n  const project = createProject(uniqueId)\n\n  test.beforeAll(async ({ request }) => {\n    // Create test dependencies\n    const gtResponse = await request.post('/api/v1/governance-templates', {\n      data: {\n        name: `Test Governance Template ${uniqueId}`,\n        version: '1.0',\n        description: 'Test governance template description.'\n      }\n    })\n\n    if (!gtResponse.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create governance template: ${await gtResponse.text()}`\n      })\n    }\n    expect(gtResponse.ok()).toBeTruthy()\n    governanceTemplateId = (await gtResponse.json())._id\n\n    // Create test workflow templates\n    const wtResponseA = await request.post('/api/v1/workflow-templates', {\n      data: {\n        governanceTemplateId,\n        name: `Test Workflow Template A ${uniqueId}`,\n        description: 'Workflow Template A description',\n        metadata: {}\n      }\n    })\n\n    if (!wtResponseA.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create workflow template A: ${await wtResponseA.text()}`\n      })\n    }\n    expect(wtResponseA.ok()).toBeTruthy()\n    workflowTemplateIdA = (await wtResponseA.json())._id\n\n    const wtResponseB = await request.post('/api/v1/workflow-templates', {\n      data: {\n        governanceTemplateId,\n        name: `Test Workflow Template B ${uniqueId}`,\n        description: 'Workflow Template B description',\n        metadata: {}\n      }\n    })\n\n    if (!wtResponseB.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create workflow template B: ${await wtResponseB.text()}`\n      })\n    }\n    expect(wtResponseB.ok()).toBeTruthy()\n    workflowTemplateIdB = (await wtResponseB.json())._id\n  })\n\n  test('should create a new project', async ({ request }) => {\n    const projectData = {\n      ...project,\n      governanceTemplateId,\n      selectedWorkflowTemplateIds: [workflowTemplateIdA, workflowTemplateIdB]\n    }\n\n    const response = await request.post('/api/v1/projects', {\n      data: projectData\n    })\n\n    if (!response.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to create project: ${await response.text()}`\n      })\n    }\n    expect(response.ok()).toBeTruthy()\n    const data = await response.json()\n    projectId = data._id\n\n    expect(data.name).toBe(projectData.name)\n    expect(data.governanceTemplateId).toBe(governanceTemplateId)\n    expect(data.selectedWorkflowTemplateIds).toContain(workflowTemplateIdA)\n    expect(data.selectedWorkflowTemplateIds).toContain(workflowTemplateIdB)\n  })\n\n  test('should get a project by id', async ({ request }) => {\n    const response = await request.get(`/api/v1/projects/${projectId}`)\n\n    if (!response.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to get project: ${await response.text()}`\n      })\n    }\n    expect(response.ok()).toBeTruthy()\n\n    const data = await response.json()\n    expect(data._id).toBe(projectId)\n    expect(data.name).toBe(project.name)\n  })\n\n  test('should update a project', async ({ request }) => {\n    const updatedProject = {\n      name: `Updated ${project.name}`,\n      description: 'Updated Description',\n      metadata: { status: 'in-progress' }\n    }\n\n    const response = await request.put(`/api/v1/projects/${projectId}`, {\n      data: updatedProject\n    })\n\n    if (!response.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to update project: ${await response.text()}`\n      })\n    }\n    expect(response.ok()).toBeTruthy()\n\n    const data = await response.json()\n    expect(data.name).toBe(updatedProject.name)\n    expect(data.description).toBe(updatedProject.description)\n    expect(data.metadata).toEqual(updatedProject.metadata)\n  })\n\n  test('should delete a project', async ({ request }) => {\n    const response = await request.delete(`/api/v1/projects/${projectId}`)\n\n    if (!response.ok()) {\n      test.info().annotations.push({\n        type: 'error',\n        description: `Failed to delete project: ${await response.text()}`\n      })\n    }\n    expect(response.ok()).toBeTruthy()\n\n    // Verify deletion\n    const getResponse = await request.get(`/api/v1/projects/${projectId}`)\n    expect(getResponse.status()).toBe(404)\n  })\n\n  test.afterAll(async ({ request }) => {\n    // Cleanup test dependencies in reverse order of creation\n    if (projectId) {\n      await request.delete(`/api/v1/projects/${projectId}`)\n    }\n\n    const templatesForDeletion = [\n      workflowTemplateIdA,\n      workflowTemplateIdB\n    ].filter(Boolean)\n\n    for (const id of templatesForDeletion) {\n      await request.delete(`/api/v1/workflow-templates/${id}`)\n    }\n\n    if (governanceTemplateId) {\n      await request.delete(\n        `/api/v1/governance-templates/${governanceTemplateId}`\n      )\n    }\n  })\n})\n"
    },
    {
      "chunk_id": "workflow_instance_management",
      "description": "Functionality for managing workflow instances within projects",
      "files": [
        "src/api/workflow-instances/controller.js",
        "src/api/workflow-instances/index.js",
        "src/api/workflow-instances/model.js",
        "src/api/workflow-instances/validation.js"
      ],
      "content": "\n\n--- src/api/workflow-instances/controller.js ---\nimport Boom from '@hapi/boom'\nimport { ObjectId } from 'mongodb'\n\n/**\n * Compares two workflows based on their checklist items\n * @param {Array} itemsA Checklist items for workflow A\n * @param {Array} itemsB Checklist items for workflow B\n * @returns {number} Comparison result (-1, 0, 1)\n */\nfunction compareWorkflowsByItems(itemsA, itemsB) {\n  // Handle empty cases - empty workflows go to the bottom\n  if (!itemsA?.length && !itemsB?.length) return 0\n  if (!itemsA?.length) return 1\n  if (!itemsB?.length) return -1\n\n  // Compare based on number of completed items\n  const completedA = itemsA.filter((item) => item.status === 'complete').length\n  const completedB = itemsB.filter((item) => item.status === 'complete').length\n\n  if (completedA !== completedB) {\n    return completedB - completedA // More completed items first\n  }\n\n  // If same number of completed items, compare total items\n  return itemsB.length - itemsA.length // More total items first\n}\n\nexport const getWorkflowInstancesHandler = async (request, h) => {\n  try {\n    const projectId = new ObjectId(request.query.projectId)\n\n    // Verify project exists\n    const project = await request.db\n      .collection('projects')\n      .findOne({ _id: projectId })\n\n    if (!project) {\n      throw Boom.notFound('Project not found')\n    }\n\n    // Get workflow instances for the project\n    const workflowInstances = await request.db\n      .collection('workflowInstances')\n      .find({ projectId })\n      .toArray()\n\n    // Get all checklist items for these workflows\n    const workflowIds = workflowInstances.map((wf) => wf._id)\n    const checklistItems = await request.db\n      .collection('checklistItemInstances')\n      .find({ workflowInstanceId: { $in: workflowIds } })\n      .toArray()\n\n    // Group checklist items by workflow\n    const itemsByWorkflow = new Map()\n    checklistItems.forEach((item) => {\n      const wfId = item.workflowInstanceId.toString()\n      if (!itemsByWorkflow.has(wfId)) {\n        itemsByWorkflow.set(wfId, [])\n      }\n      itemsByWorkflow.get(wfId).push(item)\n    })\n\n    // Sort workflow instances based on their order field\n    workflowInstances.sort((a, b) => {\n      // First sort by order field\n      if (a.order !== undefined && b.order !== undefined) {\n        return a.order - b.order\n      }\n\n      // Fall back to the old sorting method if order is not available\n      const itemsA = itemsByWorkflow.get(a._id.toString()) || []\n      const itemsB = itemsByWorkflow.get(b._id.toString()) || []\n      return compareWorkflowsByItems(itemsA, itemsB)\n    })\n\n    // Convert ObjectIds to strings\n    const formattedInstances = workflowInstances.map((instance) => ({\n      ...instance,\n      _id: instance._id.toString(),\n      projectId: instance.projectId.toString(),\n      workflowTemplateId: instance.workflowTemplateId.toString()\n    }))\n\n    return h.response(formattedInstances).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\n\n--- src/api/workflow-instances/index.js ---\nimport { getWorkflowInstancesHandler } from './controller.js'\nimport Joi from 'joi'\n\nconst workflowInstanceResponseSchema = Joi.object({\n  _id: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .description('MongoDB ObjectId')\n    .example('60d21bbfe3d5d533d9fc1e4c'),\n  projectId: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .example('60d21bbfe3d5d533d9fc1e4d'),\n  workflowTemplateId: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .example('60d21bbfe3d5d533d9fc1e4e'),\n  name: Joi.string().example('Model Validation Workflow'),\n  description: Joi.string()\n    .allow('')\n    .example('Workflow for validating AI models'),\n  metadata: Joi.object().example({\n    priority: 'high',\n    category: 'validation'\n  }),\n  order: Joi.number()\n    .integer()\n    .min(0)\n    .example(1)\n    .description('Manual ordering position for the workflow'),\n  status: Joi.string().valid('active', 'completed').example('active'),\n  createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n  updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n})\n\n/**\n * @type { import('@hapi/hapi').Plugin<void> }\n */\nexport default {\n  name: 'workflow-instance-routes',\n  register: (server) => {\n    server.route([\n      {\n        method: 'GET',\n        path: '/api/v1/workflow-instances',\n        handler: getWorkflowInstancesHandler,\n        options: {\n          tags: ['api', 'workflow-instance'],\n          description: 'Get workflow instances for a project',\n          validate: {\n            query: Joi.object({\n              projectId: Joi.string()\n                .pattern(/^[0-9a-fA-F]{24}$/)\n                .required()\n                .description('MongoDB ObjectId of the project')\n            })\n          },\n          response: {\n            schema: Joi.array().items(workflowInstanceResponseSchema)\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'List of workflow instances for the project',\n                  schema: Joi.array().items(workflowInstanceResponseSchema)\n                },\n                400: { description: 'Bad request or validation error' },\n                404: { description: 'Project not found' }\n              }\n            }\n          }\n        }\n      }\n    ])\n  }\n}\n\n\n--- src/api/workflow-instances/model.js ---\nimport { ObjectId } from 'mongodb'\n\n/**\n * @typedef {object} WorkflowInstance\n * @property {import('mongodb').ObjectId} _id - The unique identifier\n * @property {import('mongodb').ObjectId} projectId - Reference to parent Project (required)\n * @property {import('mongodb').ObjectId} workflowTemplateId - Reference to source WorkflowTemplate (required)\n * @property {string} name - The name of the workflow (required)\n * @property {string} [description] - The description of the workflow\n * @property {object} [metadata] - Additional workflow configuration\n * @property {number} [order] - Manual ordering position for the workflow\n * @property {string} status - Current status of the workflow (e.g., 'active', 'completed') (required)\n * @property {Date} createdAt - When the instance was created (required)\n * @property {Date} updatedAt - When the instance was last updated (required)\n */\n\n/**\n * Creates a new workflow instance from a template\n * @param {object} data - The instance data\n * @param {string|import('mongodb').ObjectId} data.projectId - Reference to parent Project\n * @param {string|import('mongodb').ObjectId} data.workflowTemplateId - Reference to source WorkflowTemplate\n * @param {string} data.name - The name of the workflow\n * @param {string} [data.description] - The description of the workflow\n * @param {object} [data.metadata] - Additional workflow configuration\n * @param {number} [data.order] - Manual ordering position for the workflow\n * @returns {Omit<WorkflowInstance, '_id'>}\n */\nexport function createWorkflowInstance(data) {\n  const now = new Date()\n  return {\n    projectId:\n      typeof data.projectId === 'string'\n        ? new ObjectId(data.projectId)\n        : data.projectId,\n    workflowTemplateId:\n      typeof data.workflowTemplateId === 'string'\n        ? new ObjectId(data.workflowTemplateId)\n        : data.workflowTemplateId,\n    name: data.name,\n    description: data.description,\n    metadata: data.metadata ?? {},\n    order: data.order ?? 0,\n    status: 'active',\n    createdAt: now,\n    updatedAt: now\n  }\n}\n\n\n--- src/api/workflow-instances/validation.js ---\nimport Joi from 'joi'\nimport { ObjectId } from 'mongodb'\n\n// Custom Joi extension for MongoDB ObjectId validation\nconst objectIdSchema = Joi.string().custom((value, helpers) => {\n  if (!ObjectId.isValid(value)) {\n    return helpers.error('any.invalid')\n  }\n  return value\n}, 'MongoDB ObjectId validation')\n\nexport const createWorkflowInstanceSchema = Joi.object({\n  projectId: objectIdSchema.required(),\n  workflowTemplateId: objectIdSchema.required(),\n  name: Joi.string().required(),\n  description: Joi.string().allow(''),\n  metadata: Joi.object().default({}),\n  order: Joi.number().integer().min(0).default(0),\n  status: Joi.string().valid('active', 'completed').default('active')\n})\n\nexport const updateWorkflowInstanceSchema = Joi.object({\n  name: Joi.string(),\n  description: Joi.string().allow(''),\n  metadata: Joi.object(),\n  order: Joi.number().integer().min(0),\n  status: Joi.string().valid('active', 'completed')\n}).min(1)\n\nexport const idSchema = Joi.object({\n  id: objectIdSchema.required().description('MongoDB ObjectId')\n})\n"
    },
    {
      "chunk_id": "checklist_item_instance_management",
      "description": "Functionality for managing checklist item instances within workflow instances",
      "files": [
        "src/api/checklist-item-instances/controller.js",
        "src/api/checklist-item-instances/index.js",
        "src/api/checklist-item-instances/model.js",
        "src/api/checklist-item-instances/validation.js"
      ],
      "content": "\n\n--- src/api/checklist-item-instances/controller.js ---\nimport { ObjectId } from 'mongodb'\nimport Boom from '@hapi/boom'\nimport { createLogger } from '../common/helpers/logging/logger.js'\n\nconst logger = createLogger()\n\n/**\n * Validates that all dependencies are complete before allowing status change\n * @param {import('mongodb').Collection} collection\n * @param {import('mongodb').ObjectId} instanceId\n * @param {string} newStatus\n * @returns {Promise<boolean>}\n */\nasync function validateDependencies(collection, instanceId, newStatus) {\n  if (newStatus !== 'complete') {\n    return true // Only validate dependencies when marking as complete\n  }\n\n  const instance = await collection.findOne({ _id: instanceId })\n  if (!instance || !instance.dependencies_requires?.length) {\n    return true\n  }\n\n  const dependencyIds = instance.dependencies_requires.map((id) =>\n    typeof id === 'string' ? new ObjectId(id) : id\n  )\n\n  const dependencies = await collection\n    .find({ _id: { $in: dependencyIds } })\n    .toArray()\n\n  return dependencies.every((dep) => dep.status === 'complete')\n}\n\n/**\n * Records an audit log entry for status change\n * @param {import('@hapi/hapi').Request} request\n * @param {string} instanceId\n * @param {string} oldStatus\n * @param {string} newStatus\n */\nasync function recordAuditLog(request, instanceId, oldStatus, newStatus) {\n  try {\n    await request.db.collection('auditLogs').insertOne({\n      eventType: 'checklist_item_status_change',\n      objectType: 'checklist_item_instance',\n      objectId: new ObjectId(instanceId),\n      changes: {\n        status: {\n          from: oldStatus,\n          to: newStatus\n        }\n      },\n      changedAt: new Date(),\n      changedBy: request.auth?.credentials?.user?.id || 'system'\n    })\n  } catch (error) {\n    logger.error(error, 'Failed to record audit log')\n  }\n}\n\n/**\n * Sorts checklist items based on their order field\n * @param {Array} items Array of checklist items to sort\n * @returns {Array} Sorted array of checklist items\n */\nfunction topologicalSort(items) {\n  // Handle empty case\n  if (!items || items.length === 0) {\n    return []\n  }\n\n  // Sort items by order field\n  return [...items].sort((a, b) => {\n    // Sort by order if both items have it\n    if (typeof a.order === 'number' && typeof b.order === 'number') {\n      return a.order - b.order\n    }\n    // Items with order come before items without\n    if (typeof a.order === 'number') return -1\n    if (typeof b.order === 'number') return 1\n    return 0\n  })\n}\n\n/**\n * Compares two workflows based on their checklist items\n * @param {Array} itemsA Checklist items for workflow A\n * @param {Array} itemsB Checklist items for workflow B\n * @returns {number} Comparison result (-1, 0, 1)\n */\nfunction compareWorkflowsByItems(itemsA, itemsB) {\n  // Handle empty cases - empty workflows go to the bottom\n  if (!itemsA?.length && !itemsB?.length) return 0\n  if (!itemsA?.length) return 1\n  if (!itemsB?.length) return -1\n\n  // Compare based on number of completed items\n  const completedA = itemsA.filter((item) => item.status === 'complete').length\n  const completedB = itemsB.filter((item) => item.status === 'complete').length\n\n  if (completedA !== completedB) {\n    return completedB - completedA // More completed items first\n  }\n\n  // If same number of completed items, compare total items\n  return itemsB.length - itemsA.length // More total items first\n}\n\nexport const updateChecklistItemInstanceStatusHandler = async (request, h) => {\n  try {\n    const instanceId = new ObjectId(request.params.id)\n    const newStatus = request.payload.status\n\n    const collection = request.db.collection('checklistItemInstances')\n\n    // Get current instance\n    const currentInstance = await collection.findOne({ _id: instanceId })\n    if (!currentInstance) {\n      throw Boom.notFound('Checklist item instance not found')\n    }\n\n    // Validate dependencies if marking as complete\n    const dependenciesValid = await validateDependencies(\n      collection,\n      instanceId,\n      newStatus\n    )\n    if (!dependenciesValid) {\n      throw Boom.preconditionFailed(\n        'Cannot mark as complete - dependencies are not complete'\n      )\n    }\n\n    // Update the status\n    const result = await collection.findOneAndUpdate(\n      { _id: instanceId },\n      {\n        $set: {\n          status: newStatus,\n          updatedAt: new Date()\n        }\n      },\n      { returnDocument: 'after' }\n    )\n\n    if (!result) {\n      throw Boom.notFound('Checklist item instance not found')\n    }\n\n    // Convert ObjectIds to strings for response\n    result._id = result._id.toString()\n    result.workflowInstanceId = result.workflowInstanceId.toString()\n    result.checklistItemTemplateId = result.checklistItemTemplateId.toString()\n\n    // Record audit log\n    await recordAuditLog(\n      request,\n      request.params.id,\n      currentInstance.status,\n      newStatus\n    )\n\n    return h.response(result).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const updateChecklistItemInstanceHandler = async (request, h) => {\n  try {\n    const instanceId = new ObjectId(request.params.id)\n    const updates = request.payload\n    const collection = request.db.collection('checklistItemInstances')\n\n    // Get current instance\n    const currentInstance = await collection.findOne({ _id: instanceId })\n    if (!currentInstance) {\n      throw Boom.notFound('Checklist item instance not found')\n    }\n\n    // If status is being updated, validate dependencies\n    if (updates.status && updates.status !== currentInstance.status) {\n      const dependenciesValid = await validateDependencies(\n        collection,\n        instanceId,\n        updates.status\n      )\n      if (!dependenciesValid) {\n        throw Boom.preconditionFailed(\n          'Cannot mark as complete - dependencies are not complete'\n        )\n      }\n    }\n\n    // Validate metadata based on type\n    if (updates.metadata) {\n      switch (currentInstance.type) {\n        case 'approval':\n          if (!updates.metadata.approver) {\n            throw Boom.badRequest('Approver is required for approval items')\n          }\n          if (!updates.metadata.approvalDate && updates.status === 'complete') {\n            updates.metadata.approvalDate = new Date()\n          }\n          break\n        case 'document':\n          if (!updates.metadata.documentUrl && updates.status === 'complete') {\n            throw Boom.badRequest('Document URL is required for document items')\n          }\n          break\n        case 'task':\n          if (!updates.metadata.completedBy && updates.status === 'complete') {\n            updates.metadata.completedBy =\n              request.auth?.credentials?.user?.id || 'system'\n          }\n          if (\n            !updates.metadata.completedDate &&\n            updates.status === 'complete'\n          ) {\n            updates.metadata.completedDate = new Date()\n          }\n          break\n      }\n    }\n\n    // Update the instance\n    const updateData = {\n      ...updates,\n      updatedAt: new Date()\n    }\n\n    // Convert dependencies_requires to strings for validation\n    if (currentInstance.dependencies_requires) {\n      currentInstance.dependencies_requires =\n        currentInstance.dependencies_requires.map((id) =>\n          id instanceof ObjectId ? id.toString() : id\n        )\n    }\n\n    // Prevent updating dependencies\n    if (updateData.dependencies_requires) {\n      throw Boom.badRequest(\n        '\\n        Cannot update dependencies - they are managed by the system\\n      '\n      )\n    }\n\n    const result = await collection.findOneAndUpdate(\n      { _id: instanceId },\n      { $set: updateData },\n      { returnDocument: 'after' }\n    )\n\n    if (!result) {\n      throw Boom.notFound('Checklist item instance not found')\n    }\n\n    // Convert ObjectIds to strings for response\n    result._id = result._id.toString()\n    result.workflowInstanceId = result.workflowInstanceId.toString()\n    result.checklistItemTemplateId = result.checklistItemTemplateId.toString()\n    if (result.dependencies_requires) {\n      result.dependencies_requires = result.dependencies_requires.map((id) =>\n        id instanceof ObjectId ? id.toString() : id\n      )\n    }\n\n    // Record audit log if status changed\n    if (updates.status && updates.status !== currentInstance.status) {\n      await recordAuditLog(\n        request,\n        request.params.id,\n        currentInstance.status,\n        updates.status\n      )\n    }\n\n    return h.response(result).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\nexport const getChecklistItemInstancesHandler = async (request, h) => {\n  try {\n    const workflowInstanceId = new ObjectId(request.query.workflowInstanceId)\n\n    // Get all workflow instances to compare\n    const workflowInstances = await request.db\n      .collection('workflowInstances')\n      .find({})\n      .toArray()\n\n    if (!workflowInstances?.length) {\n      throw Boom.notFound('No workflow instances found')\n    }\n\n    // Get checklist items for all workflows\n    const allChecklistItems = await request.db\n      .collection('checklistItemInstances')\n      .find({})\n      .toArray()\n\n    // Group checklist items by workflow\n    const itemsByWorkflow = new Map()\n    allChecklistItems.forEach((item) => {\n      const wfId = item.workflowInstanceId.toString()\n      if (!itemsByWorkflow.has(wfId)) {\n        itemsByWorkflow.set(wfId, [])\n      }\n      itemsByWorkflow.get(wfId).push(item)\n    })\n\n    // Sort workflows based on their checklist items\n    workflowInstances.sort((a, b) => {\n      // First sort by order field\n      if (a.order !== undefined && b.order !== undefined) {\n        return a.order - b.order\n      }\n\n      // Fall back to the old sorting method if order is not available\n      const itemsA = itemsByWorkflow.get(a._id.toString()) || []\n      const itemsB = itemsByWorkflow.get(b._id.toString()) || []\n      return compareWorkflowsByItems(itemsA, itemsB)\n    })\n\n    // Get checklist items for the requested workflow\n    const checklistItemInstances = allChecklistItems.filter(\n      (item) =>\n        item.workflowInstanceId.toString() === workflowInstanceId.toString()\n    )\n\n    // If no checklist items found, return empty array\n    if (!checklistItemInstances?.length) {\n      return h.response([]).code(200)\n    }\n\n    // Convert ObjectIds and populate dependencies\n    for (const instance of checklistItemInstances) {\n      instance._id = instance._id.toString()\n      instance.workflowInstanceId = instance.workflowInstanceId.toString()\n      instance.checklistItemTemplateId =\n        instance.checklistItemTemplateId.toString()\n\n      if (instance.dependencies_requires?.length > 0) {\n        if (\n          instance.dependencies_requires[0] instanceof ObjectId ||\n          typeof instance.dependencies_requires[0] === 'string'\n        ) {\n          const dependencyIds = instance.dependencies_requires.map((id) =>\n            typeof id === 'string' ? new ObjectId(id) : id\n          )\n          const dependencies = await request.db\n            .collection('checklistItemInstances')\n            .find({ _id: { $in: dependencyIds } })\n            .toArray()\n\n          instance.dependencies_requires = dependencies.map((dep) => ({\n            ...dep,\n            _id: dep._id.toString(),\n            workflowInstanceId: dep.workflowInstanceId.toString(),\n            checklistItemTemplateId: dep.checklistItemTemplateId.toString(),\n            dependencies_requires: Array.isArray(dep.dependencies_requires)\n              ? dep.dependencies_requires.map((id) => id.toString())\n              : dep.dependencies_requires\n          }))\n        }\n      }\n    }\n\n    // Sort items topologically based on dependencies\n    const sortedItems = topologicalSort(checklistItemInstances)\n\n    return h.response(sortedItems).code(200)\n  } catch (error) {\n    if (error.isBoom) throw error\n    throw Boom.badRequest(error.message)\n  }\n}\n\n\n--- src/api/checklist-item-instances/index.js ---\nimport {\n  updateChecklistItemInstanceHandler,\n  getChecklistItemInstancesHandler\n} from './controller.js'\nimport Joi from 'joi'\n\n// First define a base schema without the recursive dependencies\nconst baseChecklistItemSchema = Joi.object({\n  _id: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .description('MongoDB ObjectId')\n    .example('60d21bbfe3d5d533d9fc1e4c'),\n  workflowInstanceId: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .example('60d21bbfe3d5d533d9fc1e4d'),\n  checklistItemTemplateId: Joi.string()\n    .pattern(/^[0-9a-fA-F]{24}$/)\n    .example('60d21bbfe3d5d533d9fc1e4e'),\n  name: Joi.string().example('Model Validation'),\n  description: Joi.string()\n    .allow('')\n    .example('Validate the AI model performance and fairness'),\n  type: Joi.string().example('task'),\n  status: Joi.string()\n    .valid('incomplete', 'complete', 'not_required')\n    .example('complete'),\n  metadata: Joi.object()\n    .example({\n      priority: 'high',\n      category: 'validation',\n      approver: 'john.doe@example.com',\n      approvalDate: '2024-03-20T10:00:00.000Z',\n      documentUrl: 'https://example.com/doc.pdf',\n      completedBy: 'jane.smith@example.com',\n      completedDate: '2024-03-20T10:00:00.000Z'\n    })\n    .description('Additional configuration based on checklist item type'),\n  order: Joi.number()\n    .integer()\n    .min(0)\n    .example(1)\n    .description('Manual ordering position for the checklist item'),\n  createdAt: Joi.date().example('2024-03-20T10:00:00.000Z'),\n  updatedAt: Joi.date().example('2024-03-20T10:00:00.000Z')\n}).id('ChecklistItemInstance')\n\n// Then create the full schema that includes the recursive dependencies\nconst checklistItemInstanceResponseSchema = baseChecklistItemSchema.keys({\n  dependencies_requires: Joi.array()\n    .items(\n      Joi.alternatives().try(\n        Joi.string().pattern(/^[0-9a-fA-F]{24}$/),\n        Joi.link('#ChecklistItemInstance')\n      )\n    )\n    .description(\n      'Array of checklist item instance IDs that this item depends on'\n    )\n})\n\nconst updateChecklistItemInstanceSchema = Joi.object({\n  name: Joi.string(),\n  description: Joi.string().allow(''),\n  type: Joi.string().valid('approval', 'document', 'task'),\n  status: Joi.string()\n    .valid('incomplete', 'complete', 'not_required')\n    .description('New status for the checklist item'),\n  metadata: Joi.object({\n    // Approval type metadata\n    approver: Joi.string().email().description('Email of the approver'),\n    approvalDate: Joi.date().description('Date of approval'),\n    // Document type metadata\n    documentUrl: Joi.string().uri().description('URL of the uploaded document'),\n    // Task type metadata\n    completedBy: Joi.string().description('User who completed the task'),\n    completedDate: Joi.date().description('Date when task was completed'),\n    // Common metadata\n    priority: Joi.string().valid('low', 'medium', 'high'),\n    notes: Joi.string().description('Additional notes'),\n    category: Joi.string().description('Category of the checklist item')\n  }).description('Additional configuration based on checklist item type')\n}).min(1)\n\n/**\n * @type { import('@hapi/hapi').Plugin<void> }\n */\nexport default {\n  name: 'checklist-item-instance-routes',\n  register: (server) => {\n    server.route([\n      {\n        method: 'GET',\n        path: '/api/v1/checklist-item-instances',\n        handler: getChecklistItemInstancesHandler,\n        options: {\n          tags: ['api', 'checklist-item-instance'],\n          description: 'Get checklist item instances for a workflow instance',\n          validate: {\n            query: Joi.object({\n              workflowInstanceId: Joi.string()\n                .pattern(/^[0-9a-fA-F]{24}$/)\n                .required()\n                .description('MongoDB ObjectId of the workflow instance')\n            })\n          },\n          response: {\n            schema: Joi.array().items(checklistItemInstanceResponseSchema)\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description:\n                    'List of checklist item instances for the workflow',\n                  schema: Joi.array().items(checklistItemInstanceResponseSchema)\n                },\n                400: { description: 'Bad request or validation error' },\n                404: { description: 'Workflow instance not found' }\n              }\n            }\n          }\n        }\n      },\n      {\n        method: 'PUT',\n        path: '/api/v1/checklist-item-instances/{id}',\n        handler: updateChecklistItemInstanceHandler,\n        options: {\n          tags: ['api', 'checklist-item-instance'],\n          description: 'Update a checklist item instance',\n          validate: {\n            params: Joi.object({\n              id: Joi.string()\n                .pattern(/^[0-9a-fA-F]{24}$/)\n                .required()\n                .description('MongoDB ObjectId')\n            }),\n            payload: updateChecklistItemInstanceSchema\n          },\n          response: {\n            schema: checklistItemInstanceResponseSchema\n          },\n          plugins: {\n            'hapi-swagger': {\n              responses: {\n                200: {\n                  description: 'Successfully updated checklist item instance',\n                  schema: checklistItemInstanceResponseSchema\n                },\n                400: { description: 'Bad request or validation error' },\n                404: { description: 'Checklist item instance not found' },\n                412: {\n                  description: 'Dependencies not met for status change'\n                }\n              }\n            }\n          }\n        }\n      }\n    ])\n  }\n}\n\n\n--- src/api/checklist-item-instances/model.js ---\nimport { ObjectId } from 'mongodb'\n\n/**\n * @typedef {object} ChecklistItemInstance\n * @property {import('mongodb').ObjectId} _id - The unique identifier\n * @property {import('mongodb').ObjectId} workflowInstanceId - Reference to parent WorkflowInstance (required)\n * @property {import('mongodb').ObjectId} checklistItemTemplateId - Reference to the template this instance is based on (required)\n * @property {string} name - Display name of the checklist item (required)\n * @property {string} [description] - Detailed description\n * @property {string} type - Type of checklist item (e.g. 'approval', 'document', 'task') (required)\n * @property {string} status - Current status (e.g. 'incomplete', 'complete', 'not_required') (required)\n * @property {import('mongodb').ObjectId[]} dependencies_requires - Array of checklist item instance IDs that this item depends on\n * @property {object} [metadata] - Additional configuration\n * @property {number} [order] - Manual ordering position for the checklist item\n * @property {Date} createdAt - When the instance was created (required)\n * @property {Date} updatedAt - When the instance was last updated (required)\n */\n\n/**\n * Creates a new checklist item instance from a template\n * @param {object} data - The instance data\n * @param {string|import('mongodb').ObjectId} data.workflowInstanceId - Reference to parent WorkflowInstance\n * @param {string|import('mongodb').ObjectId} data.checklistItemTemplateId - Reference to the template\n * @param {string} data.name - Display name of the checklist item\n * @param {string} [data.description] - Detailed description\n * @param {string} data.type - Type of checklist item\n * @param {string[]} [data.dependencies_requires] - Array of checklist item instance IDs that this item depends on\n * @param {object} [data.metadata] - Additional configuration\n * @param {number} [data.order] - Manual ordering position for the checklist item\n * @returns {Omit<ChecklistItemInstance, '_id'>}\n */\nexport function createChecklistItemInstance(data) {\n  const now = new Date()\n  return {\n    workflowInstanceId:\n      typeof data.workflowInstanceId === 'string'\n        ? new ObjectId(data.workflowInstanceId)\n        : data.workflowInstanceId,\n    checklistItemTemplateId:\n      typeof data.checklistItemTemplateId === 'string'\n        ? new ObjectId(data.checklistItemTemplateId)\n        : data.checklistItemTemplateId,\n    name: data.name,\n    description: data.description,\n    type: data.type,\n    status: 'incomplete',\n    dependencies_requires: (data.dependencies_requires ?? []).map((id) =>\n      typeof id === 'string' ? new ObjectId(id) : id\n    ),\n    metadata: data.metadata ?? {},\n    order: data.order ?? 0,\n    createdAt: now,\n    updatedAt: now\n  }\n}\n\n\n--- src/api/checklist-item-instances/validation.js ---\nimport Joi from 'joi'\nimport { ObjectId } from 'mongodb'\n\n// Custom Joi extension for MongoDB ObjectId validation\nconst objectIdSchema = Joi.string().custom((value, helpers) => {\n  if (!ObjectId.isValid(value)) {\n    return helpers.error('any.invalid')\n  }\n  return value\n}, 'MongoDB ObjectId validation')\n\nexport const createChecklistItemInstanceSchema = Joi.object({\n  workflowInstanceId: objectIdSchema.required(),\n  checklistItemTemplateId: objectIdSchema.required(),\n  name: Joi.string().required(),\n  description: Joi.string().allow(''),\n  type: Joi.string().required().valid('approval', 'document', 'task'),\n  status: Joi.string()\n    .required()\n    .valid('incomplete', 'complete', 'not_required')\n    .default('incomplete'),\n  dependencies_requires: Joi.array().items(objectIdSchema).default([]),\n  metadata: Joi.object().default({})\n})\n\nexport const updateChecklistItemInstanceSchema = Joi.object({\n  name: Joi.string(),\n  description: Joi.string().allow(''),\n  type: Joi.string().valid('approval', 'document', 'task'),\n  status: Joi.string().valid('incomplete', 'complete', 'not_required'),\n  metadata: Joi.object(),\n  dependencies_requires: Joi.array().items(objectIdSchema),\n  order: Joi.number().integer().min(0)\n}).min(1)\n\nexport const idSchema = Joi.object({\n  id: objectIdSchema.required().description('MongoDB ObjectId')\n})\n"
    },
    {
      "chunk_id": "api_routing",
      "description": "API routing and server setup",
      "files": [
        "src/api/index.js",
        "src/api/router.js",
        "src/index.js"
      ],
      "content": "\n\n--- src/api/index.js ---\nimport path from 'path'\nimport hapi from '@hapi/hapi'\n\nimport { config } from '~/src/config/index.js'\nimport { router } from '~/src/api/router.js'\nimport { requestLogger } from '~/src/api/common/helpers/logging/request-logger.js'\nimport { mongoDb } from '~/src/api/common/helpers/mongodb.js'\nimport { failAction } from '~/src/api/common/helpers/fail-action.js'\nimport { secureContext } from '~/src/api/common/helpers/secure-context/index.js'\nimport { pulse } from '~/src/api/common/helpers/pulse.js'\nimport { requestTracing } from '~/src/api/common/helpers/request-tracing.js'\nimport { setupProxy } from '~/src/api/common/helpers/proxy/setup-proxy.js'\n\nasync function createServer() {\n  setupProxy()\n  const server = hapi.server({\n    port: config.get('port'),\n    routes: {\n      validate: {\n        options: {\n          abortEarly: false\n        },\n        failAction\n      },\n      files: {\n        relativeTo: path.resolve(config.get('root'), '.public')\n      },\n      security: {\n        hsts: {\n          maxAge: 31536000,\n          includeSubDomains: true,\n          preload: false\n        },\n        xss: 'enabled',\n        noSniff: true,\n        xframe: true\n      }\n    },\n    router: {\n      stripTrailingSlash: true\n    }\n  })\n\n  // Hapi Plugins:\n  // requestLogger  - automatically logs incoming requests\n  // requestTracing - trace header logging and propagation\n  // secureContext  - loads CA certificates from environment config\n  // pulse          - provides shutdown handlers\n  // mongoDb        - sets up mongo connection pool and attaches to `server` and `request` objects\n  // router         - routes used in the app\n  await server.register([\n    requestLogger,\n    requestTracing,\n    secureContext,\n    pulse,\n    mongoDb,\n    router\n  ])\n\n  return server\n}\n\nexport { createServer }\n\n\n--- src/api/router.js ---\nimport { health } from '~/src/api/health/index.js'\nimport { example } from '~/src/api/example/index.js'\nimport governanceTemplateRoutes from '~/src/api/governance-templates/index.js'\nimport workflowTemplateRoutes from '~/src/api/workflow-templates/index.js'\nimport checklistItemTemplateRoutes from '~/src/api/checklist-item-templates/index.js'\nimport projectRoutes from '~/src/api/projects/index.js'\nimport checklistItemInstanceRoutes from './checklist-item-instances/index.js'\nimport workflowInstanceRoutes from './workflow-instances/index.js'\nimport Inert from '@hapi/inert'\nimport Vision from '@hapi/vision'\nimport HapiSwagger from 'hapi-swagger'\nimport { readFileSync } from 'fs'\nimport { fileURLToPath } from 'url'\nimport { dirname, join } from 'path'\n\nlet packageJson\ntry {\n  const __filename = fileURLToPath(import.meta.url)\n  const __dirname = dirname(__filename)\n  packageJson = JSON.parse(\n    readFileSync(join(__dirname, '../../package.json'), 'utf8')\n  )\n} catch (error) {\n  // Fallback for test environment\n  const __dirname = process.cwd()\n  packageJson = JSON.parse(\n    readFileSync(join(__dirname, 'package.json'), 'utf8')\n  )\n}\n\n/**\n * @satisfies { import('@hapi/hapi').ServerRegisterPluginObject<*> }\n */\nconst router = {\n  plugin: {\n    name: 'Router',\n    register: async (server) => {\n      const swaggerOptions = {\n        info: {\n          title: 'AI SDLC Governance API Documentation',\n          version: packageJson.version,\n          description: 'API documentation for the AI SDLC Governance service'\n        },\n        securityDefinitions: {\n          jwt: {\n            type: 'apiKey',\n            name: 'Authorization',\n            in: 'header'\n          }\n        },\n        security: [{ jwt: [] }],\n        documentationPath: '/docs',\n        swaggerUIPath: '/docs/swagger',\n        jsonPath: '/docs/swagger.json',\n        basePath: '/api/v1',\n        pathPrefixSize: 2,\n        grouping: 'tags',\n        expanded: 'list',\n        uiOptions: { defaultModelsExpandDepth: -1 },\n        tags: [\n          {\n            name: 'api',\n            description: 'API Endpoints'\n          },\n          {\n            name: 'project',\n            description:\n              '📊 Projects - Project instances created from governance templates'\n          },\n          {\n            name: 'governance-template',\n            description:\n              '🔷 Governance Templates - Top level templates that define governance processes'\n          },\n          {\n            name: 'workflow-template',\n            description:\n              '🔶 Workflow Templates - Templates that define workflow steps within a governance template'\n          },\n          {\n            name: 'checklist-item-template',\n            description:\n              '📋 Checklist Item Templates - Individual checklist items within workflow templates'\n          },\n          {\n            name: 'workflow-instance',\n            description:\n              '🔸 Workflow Instances - Active workflow instances within projects'\n          },\n          {\n            name: 'checklist-item-instance',\n            description:\n              '✓ Checklist Item Instances - Active checklist items within workflow instances'\n          }\n        ]\n      }\n\n      // Register swagger plugins first\n      await server.register([\n        Inert,\n        Vision,\n        {\n          plugin: HapiSwagger,\n          options: swaggerOptions\n        }\n      ])\n\n      // Health-check route. Used by platform to check if service is running, do not remove!\n      await server.register([health])\n\n      // Application specific routes, add your own routes here.\n      await server.register([\n        example,\n        governanceTemplateRoutes,\n        workflowTemplateRoutes,\n        checklistItemTemplateRoutes,\n        projectRoutes,\n        checklistItemInstanceRoutes,\n        workflowInstanceRoutes\n      ])\n    }\n  }\n}\n\nexport { router }\n\n\n--- src/index.js ---\nimport process from 'node:process'\n\nimport { createLogger } from '~/src/api/common/helpers/logging/logger.js'\nimport { startServer } from '~/src/api/common/helpers/start-server.js'\n\nawait startServer()\n\nprocess.on('unhandledRejection', (error) => {\n  const logger = createLogger()\n  logger.info('Unhandled rejection')\n  logger.error(error)\n  process.exitCode = 1\n})\n"
    },
    {
      "chunk_id": "database_management",
      "description": "Database connection and management",
      "files": [
        "src/api/common/helpers/mongodb.js",
        "src/api/common/helpers/mongodb.test.js",
        "src/api/common/helpers/mongo-lock.js",
        "src/api/common/helpers/mongo-lock.test.js",
        "scripts/manage-mongodb.js"
      ],
      "content": "\n\n--- src/api/common/helpers/mongodb.js ---\nimport { MongoClient } from 'mongodb'\nimport { LockManager } from 'mongo-locks'\n\nimport { config } from '~/src/config/index.js'\nimport { runMigrations } from '~/src/api/common/helpers/migrations/index.js'\n\n/**\n * @satisfies { import('@hapi/hapi').ServerRegisterPluginObject<*> }\n */\nexport const mongoDb = {\n  plugin: {\n    name: 'mongodb',\n    version: '1.0.0',\n    /**\n     *\n     * @param { import('@hapi/hapi').Server } server\n     * @param {{mongoUrl: string, databaseName: string, retryWrites: boolean, readPreference: string}} options\n     * @returns {Promise<void>}\n     */\n    register: async function (server, options) {\n      server.logger.info('Setting up MongoDb')\n\n      const client = await MongoClient.connect(options.mongoUrl, {\n        retryWrites: options.retryWrites,\n        readPreference: options.readPreference,\n        ...(server.secureContext && { secureContext: server.secureContext })\n      })\n\n      const databaseName = options.databaseName\n      const db = client.db(databaseName)\n      const locker = new LockManager(db.collection('mongo-locks'))\n\n      await createIndexes(db)\n      await createSchemaValidations(db)\n\n      // Run migrations after schema validations\n      try {\n        await runMigrations(db, server.logger)\n      } catch (error) {\n        server.logger.error('Failed to run migrations', error)\n        throw error\n      }\n\n      server.logger.info(`MongoDb connected to ${databaseName}`)\n\n      server.decorate('server', 'mongoClient', client)\n      server.decorate('server', 'db', db)\n      server.decorate('server', 'locker', locker)\n      server.decorate('request', 'db', () => db, { apply: true })\n      server.decorate('request', 'locker', () => locker, { apply: true })\n\n      // eslint-disable-next-line @typescript-eslint/no-misused-promises\n      server.events.on('stop', async () => {\n        server.logger.info('Closing Mongo client')\n        await client.close(true)\n      })\n    }\n  },\n  options: {\n    mongoUrl: config.get('mongoUri'),\n    databaseName: config.get('mongoDatabase'),\n    retryWrites: false,\n    readPreference: 'secondary'\n  }\n}\n\n/**\n * @param {import('mongodb').Db} db\n * @returns {Promise<void>}\n */\nasync function createIndexes(db) {\n  await db.collection('mongo-locks').createIndex({ id: 1 })\n\n  // Create indexes for governance templates\n  await db.collection('governanceTemplates').createIndex({ name: 1 })\n  await db.collection('governanceTemplates').createIndex({ version: 1 })\n  await db\n    .collection('governanceTemplates')\n    .createIndex({ name: 1, version: 1 }, { unique: true })\n\n  // Create indexes for workflow templates\n  await db\n    .collection('workflowTemplates')\n    .createIndex({ governanceTemplateId: 1 })\n  await db.collection('workflowTemplates').createIndex({ name: 1 })\n  await db\n    .collection('workflowTemplates')\n    .createIndex({ governanceTemplateId: 1, name: 1 }, { unique: true })\n\n  // Create indexes for checklist item templates\n  await db\n    .collection('checklistItemTemplates')\n    .createIndex({ workflowTemplateId: 1 })\n}\n\nasync function createSchemaValidations(db) {\n  const validations = [\n    {\n      collection: 'governanceTemplates',\n      schema: {\n        bsonType: 'object',\n        required: ['name', 'version', 'createdAt', 'updatedAt'],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          version: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'projects',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'name',\n          'governanceTemplateId',\n          'selectedWorkflowTemplateIds',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string' },\n          governanceTemplateId: { bsonType: 'objectId' },\n          selectedWorkflowTemplateIds: {\n            bsonType: 'array',\n            items: { bsonType: 'objectId' }\n          },\n          metadata: { bsonType: 'object' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'workflowTemplates',\n      schema: {\n        bsonType: 'object',\n        required: ['governanceTemplateId', 'name', 'createdAt', 'updatedAt'],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          governanceTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'workflowInstances',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'projectId',\n          'workflowTemplateId',\n          'name',\n          'status',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          projectId: { bsonType: 'objectId' },\n          workflowTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          status: { bsonType: 'string', enum: ['active', 'completed'] },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'checklistItemTemplates',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'workflowTemplateId',\n          'name',\n          'type',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          workflowTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          type: { bsonType: 'string' },\n          dependencies_requires: {\n            bsonType: 'array',\n            items: { bsonType: 'objectId' }\n          },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'checklistItemInstances',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'workflowInstanceId',\n          'checklistItemTemplateId',\n          'name',\n          'type',\n          'status',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          workflowInstanceId: { bsonType: 'objectId' },\n          checklistItemTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          type: { bsonType: 'string' },\n          status: {\n            bsonType: 'string',\n            enum: ['incomplete', 'complete', 'not_required']\n          },\n          dependencies_requires: {\n            bsonType: 'array',\n            items: { bsonType: 'objectId' }\n          },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    }\n  ]\n\n  for (const { collection, schema } of validations) {\n    try {\n      await db.command({\n        collMod: collection,\n        validator: { $jsonSchema: schema },\n        validationLevel: 'strict',\n        validationAction: 'error'\n      })\n    } catch (error) {\n      if (error.codeName === 'NamespaceNotFound') {\n        await db.createCollection(collection, {\n          validator: { $jsonSchema: schema },\n          validationLevel: 'strict',\n          validationAction: 'error'\n        })\n      } else {\n        throw error\n      }\n    }\n  }\n}\n\n/**\n * To be mixed in with Request|Server to provide the db decorator\n * @typedef {{db: import('mongodb').Db, locker: import('mongo-locks').LockManager }} MongoDBPlugin\n */\n\n\n--- src/api/common/helpers/mongodb.test.js ---\nimport { Db, MongoClient } from 'mongodb'\nimport { LockManager } from 'mongo-locks'\n\nimport { createServer } from '~/src/api/index.js'\n\ndescribe('#mongoDb', () => {\n  /** @type {Server} */\n  let server\n\n  describe('Set up', () => {\n    beforeAll(async () => {\n      server = await createServer()\n      await server.initialize()\n    })\n\n    afterAll(async () => {\n      await server.stop({ timeout: 0 })\n    })\n\n    test('Server should have expected MongoDb decorators', () => {\n      expect(server.db).toBeInstanceOf(Db)\n      expect(server.mongoClient).toBeInstanceOf(MongoClient)\n      expect(server.locker).toBeInstanceOf(LockManager)\n    })\n\n    test('MongoDb should have expected database name', () => {\n      expect(server.db.databaseName).toBe('ai-sdlc-governance-api')\n    })\n\n    test('MongoDb should have expected namespace', () => {\n      expect(server.db.namespace).toBe('ai-sdlc-governance-api')\n    })\n  })\n\n  describe('Shut down', () => {\n    beforeAll(async () => {\n      server = await createServer()\n      await server.initialize()\n    })\n\n    test('Should close Mongo client on server stop', async () => {\n      const closeSpy = jest.spyOn(server.mongoClient, 'close')\n      await server.stop({ timeout: 0 })\n\n      expect(closeSpy).toHaveBeenCalledWith(true)\n    })\n  })\n})\n\n/**\n * @import { Server } from '@hapi/hapi'\n */\n\n\n--- src/api/common/helpers/mongo-lock.js ---\n/**\n *\n * @param {LockManager} locker\n * @param {string} resource\n * @param {Logger|undefined} logger\n * @returns {Promise<*>}\n */\nasync function acquireLock(locker, resource, logger) {\n  const lock = await locker.lock(resource)\n  if (!lock) {\n    if (logger) {\n      logger.error(`Failed to acquire lock for ${resource}`)\n    }\n    return null\n  }\n  return lock\n}\n\n/**\n *\n * @param {LockManager} locker\n * @param {string} resource\n * @returns {Promise<*>}\n */\nasync function requireLock(locker, resource) {\n  const lock = await locker.lock(resource)\n  if (!lock) {\n    throw new Error(`Failed to acquire lock for ${resource}`)\n  }\n  return lock\n}\n\nexport { acquireLock, requireLock }\n/**\n * @import { LockManager } from 'mongo-locks'\n * @import { Logger } from 'pino'\n */\n\n\n--- src/api/common/helpers/mongo-lock.test.js ---\nimport {\n  acquireLock,\n  requireLock\n} from '~/src/api/common/helpers/mongo-lock.js'\n\ndescribe('Lock Functions', () => {\n  let locker\n  let logger\n\n  beforeEach(() => {\n    locker = {\n      lock: jest.fn()\n    }\n    logger = {\n      error: jest.fn()\n    }\n  })\n\n  describe('acquireLock', () => {\n    test('should acquire lock and return it', async () => {\n      const resource = 'testResource'\n      const mockLock = { id: 'lockId' }\n\n      locker.lock.mockResolvedValue(mockLock) // Mocking lock method to resolve a lock\n\n      const result = await acquireLock(locker, resource, logger)\n\n      expect(result).toEqual(mockLock)\n      expect(logger.error).not.toHaveBeenCalled()\n      expect(locker.lock).toHaveBeenCalledWith(resource)\n    })\n\n    test('should log error and return null if lock cannot be acquired', async () => {\n      const resource = 'testResource'\n\n      locker.lock.mockResolvedValue(null) // Mocking lock method to resolve to null\n\n      const result = await acquireLock(locker, resource, logger)\n\n      expect(result).toBeNull()\n      expect(logger.error).toHaveBeenCalledWith(\n        `Failed to acquire lock for ${resource}`\n      )\n      expect(locker.lock).toHaveBeenCalledWith(resource)\n    })\n  })\n\n  describe('requireLock', () => {\n    test('should acquire lock and return it', async () => {\n      const resource = 'testResource'\n      const mockLock = { id: 'lockId' }\n\n      locker.lock.mockResolvedValue(mockLock) // Mocking lock method to resolve a lock\n\n      const result = await requireLock(locker, resource)\n\n      expect(result).toEqual(mockLock)\n      expect(locker.lock).toHaveBeenCalledWith(resource)\n    })\n\n    test('should throw error if lock cannot be acquired', async () => {\n      const resource = 'testResource'\n\n      locker.lock.mockResolvedValue(null) // Mocking lock method to resolve to null\n\n      await expect(requireLock(locker, resource)).rejects.toThrow(\n        `Failed to acquire lock for ${resource}`\n      )\n      expect(locker.lock).toHaveBeenCalledWith(resource)\n    })\n  })\n})\n\n\n--- scripts/manage-mongodb.js ---\nimport { MongoClient, ObjectId } from 'mongodb'\nimport { promises as fs } from 'fs'\nimport path from 'path'\nimport yargs from 'yargs/yargs'\nimport { hideBin } from 'yargs/helpers'\nimport { fileURLToPath } from 'url'\nimport { config } from '../src/config/index.js'\n\n// Use __filename for potential future path resolution needs\nfileURLToPath(import.meta.url)\n\nclass MongoHandler {\n  constructor() {\n    this.client = null\n    this.db = null\n  }\n\n  async connect() {\n    try {\n      const uri = config.get('mongoUri')\n      if (!uri) {\n        throw new Error('MongoDB URI not configured')\n      }\n\n      this.client = await MongoClient.connect(uri)\n      this.db = this.client.db(config.get('mongoDatabase'))\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error'\n      throw new Error('Failed to connect to MongoDB: ' + errorMessage)\n    }\n  }\n\n  async close() {\n    if (this.client) {\n      await this.client.close()\n    }\n  }\n\n  async deleteAll() {\n    const collections = await this.db.listCollections().toArray()\n    for (const collection of collections) {\n      await this.db.collection(collection.name).deleteMany({})\n    }\n  }\n\n  async dumpDatabase(testDataDir = 'test_data') {\n    const dumpsDir = path.join(testDataDir, 'mongodb_dumps')\n    await fs.mkdir(dumpsDir, { recursive: true })\n\n    const timestamp = new Date().toISOString().replace(/[:.]/g, '')\n    const outputFile = path.join(\n      dumpsDir,\n      'mongodb_dump_' + timestamp + '.json'\n    )\n\n    const dumpData = {}\n    const collections = await this.db.listCollections().toArray()\n\n    for (const collection of collections) {\n      const documents = await this.db\n        .collection(collection.name)\n        .find({})\n        .toArray()\n      // Convert ObjectIds and Dates to a serializable format\n      const processedDocs = documents.map((doc) =>\n        JSON.parse(\n          JSON.stringify(doc, (key, value) => {\n            if (value instanceof ObjectId) {\n              return value.toString()\n            }\n            if (value instanceof Date) {\n              return value.toISOString()\n            }\n            return value\n          })\n        )\n      )\n      dumpData[collection.name] = processedDocs\n    }\n\n    await fs.writeFile(outputFile, JSON.stringify(dumpData, null, 2))\n    return outputFile\n  }\n\n  async restoreDatabase(dumpFile = null) {\n    let finalDumpFile = dumpFile\n    if (!finalDumpFile) {\n      const dumpsDir = path.join('test_data', 'mongodb_dumps')\n      try {\n        const files = await fs.readdir(dumpsDir)\n        const jsonFiles = files.filter((f) => f.endsWith('.json'))\n        if (jsonFiles.length === 0) {\n          return null\n        }\n\n        // Get the most recent dump file\n        const mostRecent = jsonFiles.sort().reverse()[0]\n        finalDumpFile = path.join(dumpsDir, mostRecent)\n      } catch (error) {\n        return null\n      }\n    }\n\n    const dumpData = JSON.parse(await fs.readFile(finalDumpFile, 'utf-8'))\n\n    for (const [collectionName, documents] of Object.entries(dumpData)) {\n      // Clear existing data\n      await this.db.collection(collectionName).deleteMany({})\n\n      if (documents.length === 0) continue\n\n      // Convert string IDs back to ObjectIds and handle special fields\n      const processedDocs = documents.map((doc) => {\n        const processedDoc = { ...doc }\n\n        // Process _id\n        if (processedDoc._id) {\n          processedDoc._id = new ObjectId(processedDoc._id)\n        }\n\n        // Process other fields\n        Object.keys(processedDoc).forEach((key) => {\n          // Handle ObjectId fields\n          if (key.endsWith('_id') && typeof processedDoc[key] === 'string') {\n            try {\n              processedDoc[key] = new ObjectId(processedDoc[key])\n            } catch {\n              // Keep as string if not a valid ObjectId\n            }\n          } else if (key.endsWith('_ids') && Array.isArray(processedDoc[key])) {\n            processedDoc[key] = processedDoc[key]\n              .filter((id) => typeof id === 'string')\n              .map((id) => {\n                try {\n                  return new ObjectId(id)\n                } catch {\n                  return id\n                }\n              })\n          }\n        })\n\n        // Convert date strings to Date objects\n        if (processedDoc.createdAt) {\n          processedDoc.createdAt = new Date(processedDoc.createdAt)\n        }\n        if (processedDoc.updatedAt) {\n          processedDoc.updatedAt = new Date(processedDoc.updatedAt)\n        }\n\n        // Handle dependencies_requires array\n        if (processedDoc.dependencies_requires) {\n          if (\n            Array.isArray(processedDoc.dependencies_requires) &&\n            processedDoc.dependencies_requires.length > 0\n          ) {\n            processedDoc.dependencies_requires =\n              processedDoc.dependencies_requires.map((id) => new ObjectId(id))\n          } else {\n            delete processedDoc.dependencies_requires\n          }\n        }\n\n        // Handle optional fields\n        if (\n          processedDoc.metadata &&\n          Object.keys(processedDoc.metadata).length === 0\n        ) {\n          delete processedDoc.metadata\n        }\n\n        if (processedDoc.description === '') {\n          delete processedDoc.description\n        }\n\n        // Handle status fields with correct enums\n        if (collectionName === 'workflowInstances' && !processedDoc.status) {\n          processedDoc.status = 'active'\n        }\n        if (\n          collectionName === 'checklistItemInstances' &&\n          !processedDoc.status\n        ) {\n          processedDoc.status = 'incomplete'\n        }\n\n        // Ensure specific fields are ObjectIds\n        if (\n          processedDoc.workflowTemplateId &&\n          typeof processedDoc.workflowTemplateId === 'string'\n        ) {\n          processedDoc.workflowTemplateId = new ObjectId(\n            processedDoc.workflowTemplateId\n          )\n        }\n        if (\n          processedDoc.governanceTemplateId &&\n          typeof processedDoc.governanceTemplateId === 'string'\n        ) {\n          processedDoc.governanceTemplateId = new ObjectId(\n            processedDoc.governanceTemplateId\n          )\n        }\n\n        // Log the processed document for debugging\n        // eslint-disable-next-line no-console\n        console.log(`Processed document for ${collectionName}:`, {\n          ...processedDoc,\n          createdAt:\n            processedDoc.createdAt instanceof Date\n              ? processedDoc.createdAt.toISOString()\n              : processedDoc.createdAt,\n          updatedAt:\n            processedDoc.updatedAt instanceof Date\n              ? processedDoc.updatedAt.toISOString()\n              : processedDoc.updatedAt\n        })\n\n        return processedDoc\n      })\n\n      if (processedDocs.length > 0) {\n        try {\n          await this.db.collection(collectionName).insertMany(processedDocs)\n        } catch (error) {\n          // eslint-disable-next-line no-console\n          console.error(\n            `Error inserting into ${collectionName}:`,\n            error.message\n          )\n          // eslint-disable-next-line no-console\n          console.error('First document:', {\n            ...processedDocs[0],\n            createdAt:\n              processedDocs[0].createdAt instanceof Date\n                ? processedDocs[0].createdAt.toISOString()\n                : processedDocs[0].createdAt,\n            updatedAt:\n              processedDocs[0].updatedAt instanceof Date\n                ? processedDocs[0].updatedAt.toISOString()\n                : processedDocs[0].updatedAt\n          })\n          throw error\n        }\n      }\n    }\n\n    return finalDumpFile\n  }\n}\n\nasync function main() {\n  const argv = yargs(hideBin(process.argv))\n    .command('dump', 'Dump the current state of MongoDB')\n    .command('restore', 'Restore database from a dump file')\n    .command('deleteAll', 'Delete all data from all collections')\n    .command('reset-schema', 'Reset schema validations')\n    .option('file', {\n      alias: 'f',\n      describe: 'Specific dump file to restore from',\n      type: 'string'\n    })\n    .demandCommand(\n      1,\n      'You must specify an action: dump, restore, deleteAll, or reset-schema'\n    )\n    .help().argv\n\n  const mongo = new MongoHandler()\n\n  try {\n    await mongo.connect()\n\n    if (argv._[0] === 'dump') {\n      const outputFile = await mongo.dumpDatabase()\n      // eslint-disable-next-line no-console\n      console.log('Database dumped to:', outputFile)\n    } else if (argv._[0] === 'restore') {\n      const restoredFile = await mongo.restoreDatabase(argv.file)\n      if (restoredFile) {\n        // eslint-disable-next-line no-console\n        console.log('Database restored from:', restoredFile)\n      } else {\n        // eslint-disable-next-line no-console\n        console.log('No dump files found to restore')\n      }\n    } else if (argv._[0] === 'deleteAll') {\n      await mongo.deleteAll()\n      // eslint-disable-next-line no-console\n      console.log('All collections have been emptied')\n    } else if (argv._[0] === 'reset-schema') {\n      await resetSchemaValidations()\n      // eslint-disable-next-line no-console\n      console.log('Schema validations have been reset')\n    }\n  } catch (error) {\n    // eslint-disable-next-line no-console\n    console.error(\n      'Fatal error occurred:',\n      error instanceof Error ? error.message : 'Unknown error'\n    )\n    process.exitCode = 1\n  } finally {\n    await mongo.close()\n  }\n}\n\nasync function resetSchemaValidations() {\n  const uri = config.get('mongoUri')\n  const dbName = config.get('mongoDatabase')\n  const client = await MongoClient.connect(uri)\n  const db = client.db(dbName)\n\n  // Drop existing schema validations for all collections\n  const collections = [\n    'projects',\n    'governanceTemplates',\n    'workflowTemplates',\n    'checklistItemTemplates',\n    'workflowInstances',\n    'checklistItemInstances',\n    'auditLogs'\n  ]\n\n  // Create collections if they don't exist\n  for (const collection of collections) {\n    try {\n      await db.createCollection(collection)\n    } catch (error) {\n      // Collection might already exist, which is fine\n      if (!error.message.includes('already exists')) {\n        throw error\n      }\n    }\n  }\n\n  // Drop existing schema validations\n  for (const collection of collections) {\n    await db.command({ collMod: collection, validator: {} })\n  }\n\n  // Re-create schema validations\n  const validations = [\n    {\n      collection: 'governanceTemplates',\n      schema: {\n        bsonType: 'object',\n        required: ['name', 'version', 'createdAt', 'updatedAt'],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          version: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'projects',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'name',\n          'governanceTemplateId',\n          'selectedWorkflowTemplateIds',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string' },\n          governanceTemplateId: { bsonType: 'objectId' },\n          selectedWorkflowTemplateIds: {\n            bsonType: 'array',\n            items: { bsonType: 'objectId' }\n          },\n          metadata: { bsonType: 'object' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'workflowTemplates',\n      schema: {\n        bsonType: 'object',\n        required: ['governanceTemplateId', 'name', 'createdAt', 'updatedAt'],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          governanceTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'workflowInstances',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'projectId',\n          'workflowTemplateId',\n          'name',\n          'status',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          projectId: { bsonType: 'objectId' },\n          workflowTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          status: { bsonType: 'string', enum: ['active', 'completed'] },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'checklistItemTemplates',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'workflowTemplateId',\n          'name',\n          'type',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          workflowTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          type: { bsonType: 'string' },\n          dependencies_requires: {\n            bsonType: 'array',\n            items: { bsonType: 'objectId' }\n          },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    },\n    {\n      collection: 'checklistItemInstances',\n      schema: {\n        bsonType: 'object',\n        required: [\n          'workflowInstanceId',\n          'checklistItemTemplateId',\n          'name',\n          'type',\n          'status',\n          'createdAt',\n          'updatedAt'\n        ],\n        additionalProperties: false,\n        properties: {\n          _id: { bsonType: 'objectId' },\n          workflowInstanceId: { bsonType: 'objectId' },\n          checklistItemTemplateId: { bsonType: 'objectId' },\n          name: { bsonType: 'string' },\n          description: { bsonType: 'string', pattern: '^.*$' },\n          type: { bsonType: 'string' },\n          status: {\n            bsonType: 'string',\n            enum: ['incomplete', 'complete', 'not_required']\n          },\n          dependencies_requires: {\n            bsonType: 'array',\n            items: { bsonType: 'objectId' }\n          },\n          metadata: { bsonType: 'object' },\n          order: { bsonType: 'int' },\n          createdAt: { bsonType: 'date' },\n          updatedAt: { bsonType: 'date' }\n        }\n      }\n    }\n  ]\n\n  for (const { collection, schema } of validations) {\n    await db.command({\n      collMod: collection,\n      validator: { $jsonSchema: schema },\n      validationLevel: 'strict',\n      validationAction: 'error'\n    })\n  }\n\n  // eslint-disable-next-line no-console\n  console.log('Schema validations reset successfully')\n  await client.close()\n}\n\nmain().catch((error) => {\n  // eslint-disable-next-line no-console\n  console.error(\n    { error: error instanceof Error ? error.message : 'Unknown error' },\n    'Fatal error occurred'\n  )\n  process.exitCode = 1\n})\n"
    },
    {
      "chunk_id": "logging_and_metrics",
      "description": "Logging and metrics functionality",
      "files": [
        "src/api/common/helpers/logging/logger.js",
        "src/api/common/helpers/logging/logger-options.js",
        "src/api/common/helpers/logging/request-logger.js",
        "src/api/common/helpers/metrics.js",
        "src/api/common/helpers/metrics.test.js"
      ],
      "content": "\n\n--- src/api/common/helpers/logging/logger.js ---\nimport { pino } from 'pino'\n\nimport { loggerOptions } from '~/src/api/common/helpers/logging/logger-options.js'\n\nfunction createLogger() {\n  return pino(loggerOptions)\n}\n\nconst logger = createLogger()\n\nexport { createLogger, logger }\n\n\n--- src/api/common/helpers/logging/logger-options.js ---\nimport { ecsFormat } from '@elastic/ecs-pino-format'\nimport { config } from '~/src/config/index.js'\nimport { getTraceId } from '@defra/hapi-tracing'\nimport { mkdir } from 'node:fs/promises'\nimport { join } from 'node:path'\nimport { writeFileSync } from 'node:fs'\n\nconst logConfig = config.get('log')\nconst serviceName = config.get('serviceName')\nconst serviceVersion = config.get('serviceVersion')\nconst isDevelopment = config.get('isDevelopment')\n\n// Override log level to debug in development mode\nif (isDevelopment && !process.env.LOG_LEVEL) {\n  config.set('log.level', 'debug')\n}\n\n// Ensure logs directory exists and clear log file in development mode\nif (isDevelopment) {\n  const logDir = join(process.cwd(), 'logs')\n  const logFile = join(logDir, 'app.log')\n  await mkdir(logDir, { recursive: true })\n  writeFileSync(logFile, '', { flag: 'w' }) // Clear/create the log file\n}\n\n/**\n * @type {{ecs: Omit<LoggerOptions, \"mixin\"|\"transport\">, \"pino-pretty\": {transport: {target: string}}}}\n */\nconst formatters = {\n  ecs: {\n    ...ecsFormat({\n      serviceVersion,\n      serviceName\n    })\n  },\n  'pino-pretty': {\n    transport: {\n      targets: [\n        { target: 'pino-pretty' },\n        ...(isDevelopment\n          ? [\n              {\n                target: 'pino/file',\n                options: { destination: './logs/app.log', append: true }\n              }\n            ]\n          : [])\n      ]\n    }\n  }\n}\n\n/**\n * @satisfies {Options}\n */\nexport const loggerOptions = {\n  enabled: logConfig.enabled,\n  ignorePaths: ['/health'],\n  redact: {\n    paths: logConfig.redact,\n    remove: true\n  },\n  level: logConfig.level,\n  ...formatters[logConfig.format],\n  nesting: true,\n  mixin() {\n    const mixinValues = {}\n    const traceId = getTraceId()\n    if (traceId) {\n      mixinValues.trace = { id: traceId }\n    }\n    return mixinValues\n  }\n}\n\n/**\n * @import { Options } from 'hapi-pino'\n * @import { LoggerOptions } from 'pino'\n */\n\n\n--- src/api/common/helpers/logging/request-logger.js ---\nimport hapiPino from 'hapi-pino'\n\nimport { loggerOptions } from '~/src/api/common/helpers/logging/logger-options.js'\n\n/**\n * @satisfies {ServerRegisterPluginObject<Options>}\n */\nconst requestLogger = {\n  plugin: hapiPino,\n  options: loggerOptions\n}\n\nexport { requestLogger }\n\n/**\n * @import { ServerRegisterPluginObject } from '@hapi/hapi'\n * @import { Options } from 'hapi-pino'\n */\n\n\n--- src/api/common/helpers/metrics.js ---\nimport {\n  createMetricsLogger,\n  Unit,\n  StorageResolution\n} from 'aws-embedded-metrics'\nimport { config } from '~/src/config/index.js'\nimport { createLogger } from '~/src/api/common/helpers/logging/logger.js'\n\n/**\n * @param {string} metricName\n * @param {number} value\n */\nconst metricsCounter = async (metricName, value = 1) => {\n  const isMetricsEnabled = config.get('isMetricsEnabled')\n\n  if (!isMetricsEnabled) {\n    return\n  }\n\n  try {\n    const metricsLogger = createMetricsLogger()\n    metricsLogger.putMetric(\n      metricName,\n      value,\n      Unit.Count,\n      StorageResolution.Standard\n    )\n    await metricsLogger.flush()\n  } catch (error) {\n    createLogger().error(error, error.message)\n  }\n}\n\nexport { metricsCounter }\n\n\n--- src/api/common/helpers/metrics.test.js ---\nimport { StorageResolution, Unit } from 'aws-embedded-metrics'\n\nimport { config } from '~/src/config/index.js'\nimport { metricsCounter } from '~/src/api/common/helpers/metrics.js'\n\nconst mockPutMetric = jest.fn()\nconst mockFlush = jest.fn()\nconst mockLoggerError = jest.fn()\n\njest.mock('aws-embedded-metrics', () => ({\n  ...jest.requireActual('aws-embedded-metrics'),\n  createMetricsLogger: () => ({\n    putMetric: mockPutMetric,\n    flush: mockFlush\n  })\n}))\njest.mock('~/src/api/common/helpers/logging/logger.js', () => ({\n  createLogger: () => ({ error: (...args) => mockLoggerError(...args) })\n}))\n\nconst mockMetricsName = 'mock-metrics-name'\nconst defaultMetricsValue = 1\nconst mockValue = 200\n\ndescribe('#metrics', () => {\n  describe('When metrics is not enabled', () => {\n    beforeEach(async () => {\n      config.set('isMetricsEnabled', false)\n      await metricsCounter(mockMetricsName, mockValue)\n    })\n\n    test('Should not call metric', () => {\n      expect(mockPutMetric).not.toHaveBeenCalled()\n    })\n\n    test('Should not call flush', () => {\n      expect(mockFlush).not.toHaveBeenCalled()\n    })\n  })\n\n  describe('When metrics is enabled', () => {\n    beforeEach(() => {\n      config.set('isMetricsEnabled', true)\n    })\n\n    test('Should send metric with default value', async () => {\n      await metricsCounter(mockMetricsName)\n\n      expect(mockPutMetric).toHaveBeenCalledWith(\n        mockMetricsName,\n        defaultMetricsValue,\n        Unit.Count,\n        StorageResolution.Standard\n      )\n    })\n\n    test('Should send metric', async () => {\n      await metricsCounter(mockMetricsName, mockValue)\n\n      expect(mockPutMetric).toHaveBeenCalledWith(\n        mockMetricsName,\n        mockValue,\n        Unit.Count,\n        StorageResolution.Standard\n      )\n    })\n\n    test('Should not call flush', async () => {\n      await metricsCounter(mockMetricsName, mockValue)\n      expect(mockFlush).toHaveBeenCalled()\n    })\n  })\n\n  describe('When metrics throws', () => {\n    const mockError = 'mock-metrics-put-error'\n\n    beforeEach(async () => {\n      config.set('isMetricsEnabled', true)\n      mockFlush.mockRejectedValue(new Error(mockError))\n\n      await metricsCounter(mockMetricsName, mockValue)\n    })\n\n    test('Should log expected error', () => {\n      expect(mockLoggerError).toHaveBeenCalledWith(Error(mockError), mockError)\n    })\n  })\n})\n\n/**\n * @import { Server } from '@hapi/hapi'\n */\n"
    },
    {
      "chunk_id": "server_health_and_security",
      "description": "Server health checks and security features",
      "files": [
        "src/api/health/controller.js",
        "src/api/health/controller.test.js",
        "src/api/health/index.js",
        "src/api/common/helpers/secure-context/get-trust-store-certs.js",
        "src/api/common/helpers/secure-context/get-trust-store-certs.test.js",
        "src/api/common/helpers/secure-context/index.js",
        "src/api/common/helpers/secure-context/secure-context.js",
        "src/api/common/helpers/secure-context/secure-context.test.js"
      ],
      "content": "\n\n--- src/api/health/controller.js ---\nimport { statusCodes } from '~/src/api/common/constants/status-codes.js'\n\n/**\n * A generic health-check endpoint. Used by the platform to check if the service is up and handling requests.\n * @satisfies {Partial<ServerRoute>}\n */\nconst healthController = {\n  handler: (_request, h) =>\n    h.response({ message: 'success' }).code(statusCodes.ok)\n}\n\nexport { healthController }\n\n/**\n * @import { ServerRoute } from '@hapi/hapi'\n */\n\n\n--- src/api/health/controller.test.js ---\nimport { createServer } from '~/src/api/index.js'\nimport { statusCodes } from '~/src/api/common/constants/status-codes.js'\n\ndescribe('#healthController', () => {\n  /** @type {Server} */\n  let server\n\n  beforeAll(async () => {\n    server = await createServer()\n    await server.initialize()\n  })\n\n  afterAll(async () => {\n    await server.stop({ timeout: 0 })\n  })\n\n  test('Should provide expected response', async () => {\n    const { result, statusCode } = await server.inject({\n      method: 'GET',\n      url: '/health'\n    })\n\n    expect(result).toEqual({ message: 'success' })\n    expect(statusCode).toBe(statusCodes.ok)\n  })\n})\n\n/**\n * @import { Server } from '@hapi/hapi'\n */\n\n\n--- src/api/health/index.js ---\nimport { healthController } from '~/src/api/health/controller.js'\n\n/**\n * @satisfies {ServerRegisterPluginObject<void>}\n */\nconst health = {\n  plugin: {\n    name: 'health',\n    register: (server) => {\n      server.route({\n        method: 'GET',\n        path: '/health',\n        ...healthController\n      })\n    }\n  }\n}\n\nexport { health }\n\n/**\n * @import { ServerRegisterPluginObject } from '@hapi/hapi'\n */\n\n\n--- src/api/common/helpers/secure-context/get-trust-store-certs.js ---\n/**\n * Get base64 certs from all environment variables starting with TRUSTSTORE_\n * @param {NodeJS.ProcessEnv} envs\n * @returns {string[]}\n */\nfunction getTrustStoreCerts(envs) {\n  return Object.entries(envs)\n    .map(([key, value]) => key.startsWith('TRUSTSTORE_') && value)\n    .filter(\n      /** @returns {envValue is string} */\n      (envValue) => Boolean(envValue)\n    )\n    .map((envValue) => Buffer.from(envValue, 'base64').toString().trim())\n}\n\nexport { getTrustStoreCerts }\n\n\n--- src/api/common/helpers/secure-context/get-trust-store-certs.test.js ---\nimport { getTrustStoreCerts } from '~/src/api/common/helpers/secure-context/get-trust-store-certs.js'\n\ndescribe('#getTrustStoreCerts', () => {\n  const mockProcessEnvWithCerts = {\n    TRUSTSTORE_CA_ONE:\n      'LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCm1vY2stY2VydC1kb3JpcwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==',\n    UNRELATED_ENV: 'not-a-cert'\n  }\n\n  test('Should provide expected result with \"certs\"', () => {\n    expect(getTrustStoreCerts(mockProcessEnvWithCerts)).toEqual([\n      '-----BEGIN CERTIFICATE-----\\nmock-cert-doris\\n-----END CERTIFICATE-----'\n    ])\n  })\n\n  test('Should provide expected empty array', () => {\n    expect(getTrustStoreCerts({})).toEqual([])\n  })\n})\n\n\n--- src/api/common/helpers/secure-context/index.js ---\nimport { secureContext } from '~/src/api/common/helpers/secure-context/secure-context.js'\nexport { secureContext }\n\n\n--- src/api/common/helpers/secure-context/secure-context.js ---\nimport tls from 'node:tls'\nimport { config } from '~/src/config/index.js'\n\nimport { getTrustStoreCerts } from '~/src/api/common/helpers/secure-context/get-trust-store-certs.js'\n\n/**\n * Creates a new secure context loaded from Base64 encoded certs\n * @satisfies {ServerRegisterPluginObject<void>}\n */\nexport const secureContext = {\n  plugin: {\n    name: 'secure-context',\n    register(server) {\n      if (config.get('isSecureContextEnabled')) {\n        const originalTlsCreateSecureContext = tls.createSecureContext\n\n        tls.createSecureContext = function (options = {}) {\n          const trustStoreCerts = getTrustStoreCerts(process.env)\n\n          if (!trustStoreCerts.length) {\n            server.logger.info('Could not find any TRUSTSTORE_ certificates')\n          }\n\n          const tlsSecureContext = originalTlsCreateSecureContext(options)\n\n          trustStoreCerts.forEach((cert) => {\n            tlsSecureContext.context.addCACert(cert)\n          })\n\n          return tlsSecureContext\n        }\n\n        server.decorate('server', 'secureContext', tls.createSecureContext())\n      } else {\n        server.logger.info('Custom secure context is disabled')\n      }\n    }\n  }\n}\n\n/**\n * @import { ServerRegisterPluginObject } from '@hapi/hapi'\n */\n\n\n--- src/api/common/helpers/secure-context/secure-context.test.js ---\nimport hapi from '@hapi/hapi'\n\nimport { secureContext } from '~/src/api/common/helpers/secure-context/index.js'\nimport { requestLogger } from '~/src/api/common/helpers/logging/request-logger.js'\nimport { config } from '~/src/config/index.js'\n\nconst mockAddCACert = jest.fn()\nconst mockTlsCreateSecureContext = jest\n  .fn()\n  .mockReturnValue({ context: { addCACert: mockAddCACert } })\n\njest.mock('hapi-pino', () => ({\n  register: (server) => {\n    server.decorate('server', 'logger', {\n      info: jest.fn(),\n      error: jest.fn()\n    })\n  },\n  name: 'mock-hapi-pino'\n}))\njest.mock('node:tls', () => ({\n  ...jest.requireActual('node:tls'),\n  createSecureContext: (...args) => mockTlsCreateSecureContext(...args)\n}))\n\ndescribe('#secureContext', () => {\n  let server\n\n  describe('When secure context is disabled', () => {\n    beforeEach(async () => {\n      config.set('isSecureContextEnabled', false)\n      server = hapi.server()\n      await server.register([requestLogger, secureContext])\n    })\n\n    afterEach(async () => {\n      config.set('isSecureContextEnabled', false)\n      await server.stop({ timeout: 0 })\n    })\n\n    test('secureContext decorator should not be available', () => {\n      expect(server.logger.info).toHaveBeenCalledWith(\n        'Custom secure context is disabled'\n      )\n    })\n\n    test('Logger should give us disabled message', () => {\n      expect(server.secureContext).toBeUndefined()\n    })\n  })\n\n  describe('When secure context is enabled', () => {\n    const PROCESS_ENV = process.env\n\n    beforeAll(() => {\n      process.env = { ...PROCESS_ENV }\n      process.env.TRUSTSTORE_ONE = 'mock-trust-store-cert-one'\n    })\n\n    beforeEach(async () => {\n      config.set('isSecureContextEnabled', true)\n      server = hapi.server()\n      await server.register([requestLogger, secureContext])\n    })\n\n    afterEach(async () => {\n      config.set('isSecureContextEnabled', false)\n      await server.stop({ timeout: 0 })\n    })\n\n    afterAll(() => {\n      process.env = PROCESS_ENV\n    })\n\n    test('Original tls.createSecureContext should have been called', () => {\n      expect(mockTlsCreateSecureContext).toHaveBeenCalledWith({})\n    })\n\n    test('addCACert should have been called', () => {\n      expect(mockAddCACert).toHaveBeenCalled()\n    })\n\n    test('secureContext decorator should be available', () => {\n      expect(server.secureContext).toEqual({\n        context: { addCACert: expect.any(Function) }\n      })\n    })\n  })\n\n  describe('When secure context is enabled without TRUSTSTORE_ certs', () => {\n    beforeEach(async () => {\n      config.set('isSecureContextEnabled', true)\n      server = hapi.server()\n      await server.register([requestLogger, secureContext])\n    })\n\n    afterEach(async () => {\n      config.set('isSecureContextEnabled', false)\n      await server.stop({ timeout: 0 })\n    })\n\n    test('Should log about not finding any TRUSTSTORE_ certs', () => {\n      expect(server.logger.info).toHaveBeenCalledWith(\n        'Could not find any TRUSTSTORE_ certificates'\n      )\n    })\n  })\n})\n"
    },
    {
      "chunk_id": "server_utilities",
      "description": "Various server utilities and helpers",
      "files": [
        "src/api/common/helpers/fail-action.js",
        "src/api/common/helpers/fail-action.test.js",
        "src/api/common/helpers/pulse.js",
        "src/api/common/helpers/request-tracing.js",
        "src/api/common/helpers/start-server.js",
        "src/api/common/helpers/start-server.test.js",
        "src/api/common/helpers/proxy/setup-proxy.js",
        "src/api/common/helpers/proxy/setup-proxy.test.js"
      ],
      "content": "\n\n--- src/api/common/helpers/fail-action.js ---\nimport { createLogger } from '~/src/api/common/helpers/logging/logger.js'\n\nconst logger = createLogger()\n\n/**\n *\n * @param { import('@hapi/hapi').Request } _request\n * @param { import('@hapi/hapi').ResponseToolkit } _h\n * @param { Error|undefined } error\n * @returns { never }\n */\nexport function failAction(_request, _h, error) {\n  logger.warn(error, error?.message)\n  throw error\n}\n\n\n--- src/api/common/helpers/fail-action.test.js ---\nimport { failAction } from '~/src/api/common/helpers/fail-action.js'\n\ndescribe('#fail-action', () => {\n  test('Should throw expected error', () => {\n    const mockRequest = {}\n    const mockToolkit = {}\n    const mockError = Error('Something terrible has happened!')\n\n    expect(() => failAction(mockRequest, mockToolkit, mockError)).toThrow(\n      'Something terrible has happened!'\n    )\n  })\n})\n\n\n--- src/api/common/helpers/pulse.js ---\nimport hapiPulse from 'hapi-pulse'\nimport { createLogger } from '~/src/api/common/helpers/logging/logger.js'\n\nconst tenSeconds = 10 * 1000\n\n/**\n * Plug-in to handle cleanly shutting down the service.\n * @satisfies { import('@hapi/hapi').ServerRegisterPluginObject<*> }\n */\nconst pulse = {\n  plugin: hapiPulse,\n  options: {\n    logger: createLogger(),\n    timeout: tenSeconds\n  }\n}\n\nexport { pulse }\n\n\n--- src/api/common/helpers/request-tracing.js ---\nimport { tracing } from '@defra/hapi-tracing'\nimport { config } from '~/src/config/index.js'\n\nexport const requestTracing = {\n  plugin: tracing.plugin,\n  options: {\n    tracingHeader: config.get('tracing.header')\n  }\n}\n\n\n--- src/api/common/helpers/start-server.js ---\nimport { config } from '~/src/config/index.js'\n\nimport { createServer } from '~/src/api/index.js'\nimport { createLogger } from '~/src/api/common/helpers/logging/logger.js'\n\nasync function startServer() {\n  let server\n\n  try {\n    server = await createServer()\n    await server.start()\n\n    server.logger.info('Server started successfully')\n    server.logger.info(\n      `Access your backend on http://localhost:${config.get('port')}`\n    )\n  } catch (error) {\n    const logger = createLogger()\n    logger.info('Server failed to start :(')\n    logger.error(error)\n    throw error\n  }\n\n  return server\n}\n\nexport { startServer }\n\n\n--- src/api/common/helpers/start-server.test.js ---\nconst mockLoggerInfo = jest.fn()\nconst mockLoggerError = jest.fn()\n\nconst mockHapiLoggerInfo = jest.fn()\nconst mockHapiLoggerError = jest.fn()\n\nconst mockServer = {\n  start: jest.fn().mockResolvedValue(undefined),\n  stop: jest.fn().mockResolvedValue(undefined),\n  logger: {\n    info: mockHapiLoggerInfo,\n    error: mockHapiLoggerError\n  }\n}\n\njest.mock('@hapi/hapi', () => ({\n  server: jest.fn().mockReturnValue(mockServer)\n}))\n\njest.mock('hapi-pino', () => ({\n  register: (server) => {\n    server.decorate('server', 'logger', {\n      info: mockHapiLoggerInfo,\n      error: mockHapiLoggerError\n    })\n  },\n  name: 'mock-hapi-pino'\n}))\n\njest.mock('~/src/api/common/helpers/logging/logger.js', () => ({\n  createLogger: () => ({\n    info: (...args) => mockLoggerInfo(...args),\n    error: (...args) => mockLoggerError(...args)\n  })\n}))\n\nconst mockCreateServer = jest.fn().mockResolvedValue(mockServer)\njest.mock('~/src/api/index.js', () => ({\n  createServer: mockCreateServer\n}))\n\ndescribe('#startServer', () => {\n  const PROCESS_ENV = process.env\n  let server\n\n  beforeAll(() => {\n    process.env = { ...PROCESS_ENV }\n    process.env.PORT = '3098' // Set to obscure port to avoid conflicts\n  })\n\n  afterAll(() => {\n    process.env = PROCESS_ENV\n    jest.resetAllMocks()\n  })\n\n  describe('When server starts', () => {\n    beforeEach(async () => {\n      mockCreateServer.mockResolvedValueOnce(mockServer)\n      const { startServer } = await import('./start-server.js')\n      server = await startServer()\n    })\n\n    afterEach(async () => {\n      await server?.stop({ timeout: 0 })\n      jest.clearAllMocks()\n    })\n\n    test('Should start up server as expected', () => {\n      expect(mockCreateServer).toHaveBeenCalled()\n      expect(server.start).toHaveBeenCalled()\n      expect(mockHapiLoggerInfo).toHaveBeenCalledWith(\n        'Server started successfully'\n      )\n      expect(mockHapiLoggerInfo).toHaveBeenCalledWith(\n        'Access your backend on http://localhost:3098'\n      )\n    })\n  })\n\n  describe('When server start fails', () => {\n    beforeEach(() => {\n      const error = new Error('Server failed to start')\n      mockCreateServer.mockRejectedValueOnce(error)\n    })\n\n    test('Should log failed startup message', async () => {\n      const { startServer } = await import('./start-server.js')\n      await expect(startServer()).rejects.toThrow('Server failed to start')\n      expect(mockLoggerInfo).toHaveBeenCalledWith('Server failed to start :(')\n      expect(mockLoggerError).toHaveBeenCalledWith(expect.any(Error))\n    })\n  })\n})\n\n\n--- src/api/common/helpers/proxy/setup-proxy.js ---\nimport { ProxyAgent, setGlobalDispatcher } from 'undici'\nimport { bootstrap } from 'global-agent'\n\nimport { createLogger } from '~/src/api/common/helpers/logging/logger.js'\nimport { config } from '~/src/config/index.js'\n\nconst logger = createLogger()\n\n/**\n * If HTTP_PROXY is set setupProxy() will enable it globally\n * for a number of http clients.\n * Node Fetch will still need to pass a ProxyAgent in on each call.\n */\nexport function setupProxy() {\n  const proxyUrl = config.get('httpProxy')\n\n  if (proxyUrl) {\n    logger.info('setting up global proxies')\n\n    // Undici proxy\n    setGlobalDispatcher(new ProxyAgent(proxyUrl))\n\n    // global-agent (axios/request/and others)\n    bootstrap()\n    global.GLOBAL_AGENT.HTTP_PROXY = proxyUrl\n  }\n}\n\n\n--- src/api/common/helpers/proxy/setup-proxy.test.js ---\nimport { config } from '~/src/config/index.js'\nimport { getGlobalDispatcher, ProxyAgent } from 'undici'\nimport { setupProxy } from '~/src/api/common/helpers/proxy/setup-proxy.js'\n\ndescribe('setupProxy', () => {\n  afterEach(() => {\n    config.set('httpProxy', null)\n  })\n\n  test('Should not setup proxy if the environment variable is not set', () => {\n    config.set('httpProxy', null)\n    setupProxy()\n\n    expect(global?.GLOBAL_AGENT?.HTTP_PROXY).toBeUndefined()\n\n    const undiciDispatcher = getGlobalDispatcher()\n\n    expect(undiciDispatcher).not.toBeInstanceOf(ProxyAgent)\n  })\n\n  test('Should setup proxy if the environment variable is set', () => {\n    config.set('httpProxy', 'http://localhost:8080')\n    setupProxy()\n    expect(global?.GLOBAL_AGENT?.HTTP_PROXY).toBe('http://localhost:8080')\n    const undiciDispatcher = getGlobalDispatcher()\n    expect(undiciDispatcher).toBeInstanceOf(ProxyAgent)\n  })\n})\n"
    },
    {
      "chunk_id": "migrations",
      "description": "Database migration scripts",
      "files": [
        "src/api/common/helpers/migrations/index.js",
        "scripts/migrations/add-checklist-item-order.js",
        "scripts/migrations/add-workflow-order.js"
      ],
      "content": "\n\n--- src/api/common/helpers/migrations/index.js ---\nimport fs from 'fs/promises'\nimport path from 'path'\nimport { fileURLToPath } from 'url'\n\nconst __dirname = path.dirname(fileURLToPath(import.meta.url))\nconst MIGRATIONS_DIR = path.resolve(\n  __dirname,\n  '../../../../../scripts/migrations'\n)\n\n/**\n * Runs all migrations that haven't been run yet\n * @param {import('mongodb').Db} db - MongoDB database instance\n * @param {object} logger - Logger instance\n * @returns {Promise<void>}\n */\nexport async function runMigrations(db, logger) {\n  logger.info('Checking for migrations to run...')\n\n  // Create migrations collection if it doesn't exist\n  if (!(await collectionExists(db, 'migrations'))) {\n    await db.createCollection('migrations')\n    logger.info('Created migrations collection')\n  }\n\n  // Get list of completed migrations\n  const completedMigrations = await db\n    .collection('migrations')\n    .find({})\n    .project({ name: 1, _id: 0 })\n    .map((doc) => doc.name)\n    .toArray()\n\n  // Get list of migration files\n  const migrationFiles = await getMigrationFiles()\n\n  // Filter out completed migrations\n  const pendingMigrations = migrationFiles.filter(\n    (file) => !completedMigrations.includes(path.basename(file, '.js'))\n  )\n\n  if (pendingMigrations.length === 0) {\n    logger.info('No pending migrations found')\n    return\n  }\n\n  logger.info(`Found ${pendingMigrations.length} pending migrations`)\n\n  // Run each migration in sequence\n  for (const migrationFile of pendingMigrations) {\n    const migrationName = path.basename(migrationFile, '.js')\n    logger.info(`Running migration: ${migrationName}`)\n\n    try {\n      // Import and run the migration\n      const migration = await import(migrationFile)\n      await migration.default(db, logger)\n\n      // Record successful migration\n      await db.collection('migrations').insertOne({\n        name: migrationName,\n        completedAt: new Date()\n      })\n\n      logger.info(`Migration completed: ${migrationName}`)\n    } catch (error) {\n      logger.error(`Migration failed: ${migrationName}`, error)\n      throw error\n    }\n  }\n\n  logger.info('All migrations completed successfully')\n}\n\n/**\n * Checks if a collection exists in the database\n * @param {import('mongodb').Db} db - MongoDB database instance\n * @param {string} collectionName - Name of the collection to check\n * @returns {Promise<boolean>}\n */\nasync function collectionExists(db, collectionName) {\n  const collections = await db\n    .listCollections({ name: collectionName })\n    .toArray()\n  return collections.length > 0\n}\n\n/**\n * Gets a list of migration files\n * @returns {Promise<string[]>}\n */\nasync function getMigrationFiles() {\n  try {\n    const files = await fs.readdir(MIGRATIONS_DIR)\n    return files\n      .filter((file) => file.endsWith('.js'))\n      .map((file) => path.join(MIGRATIONS_DIR, file))\n      .sort() // Sort to ensure migrations run in order\n  } catch (error) {\n    // If directory doesn't exist, return empty array\n    if (error.code === 'ENOENT') {\n      return []\n    }\n    throw error\n  }\n}\n\n\n--- scripts/migrations/add-checklist-item-order.js ---\n/**\n * Migration script to add order field to existing checklist item templates\n * @param {import('mongodb').Db} db - MongoDB database instance\n * @param {object} logger - Logger instance\n * @returns {Promise<void>}\n */\nexport default async function (db, logger) {\n  logger.info('Updating checklist item templates...')\n\n  // Get all workflow templates\n  const workflowTemplates = await db\n    .collection('workflowTemplates')\n    .find({})\n    .toArray()\n\n  for (const workflowTemplate of workflowTemplates) {\n    // Get all checklist item templates for this workflow template\n    const checklistItemTemplates = await db\n      .collection('checklistItemTemplates')\n      .find({ workflowTemplateId: workflowTemplate._id })\n      .sort({ name: 1 }) // Sort by name initially\n      .toArray()\n\n    // Update each checklist item template with an order field\n    for (let i = 0; i < checklistItemTemplates.length; i++) {\n      await db\n        .collection('checklistItemTemplates')\n        .updateOne(\n          { _id: checklistItemTemplates[i]._id },\n          { $set: { order: i } }\n        )\n      logger.info(\n        `Updated checklist item template ${checklistItemTemplates[i].name} with order ${i}`\n      )\n    }\n  }\n\n  // Update checklist item instances with order from their templates\n  logger.info('Updating checklist item instances...')\n\n  // Get all workflow instances\n  const workflowInstances = await db\n    .collection('workflowInstances')\n    .find({})\n    .toArray()\n\n  for (const workflowInstance of workflowInstances) {\n    // Get all checklist item instances for this workflow instance\n    const checklistItemInstances = await db\n      .collection('checklistItemInstances')\n      .find({ workflowInstanceId: workflowInstance._id })\n      .toArray()\n\n    // Create a map of checklist item template IDs to their order\n    const templateOrderMap = new Map()\n    const checklistItemTemplateIds = checklistItemInstances.map(\n      (ci) => ci.checklistItemTemplateId\n    )\n\n    if (checklistItemTemplateIds.length > 0) {\n      const checklistItemTemplates = await db\n        .collection('checklistItemTemplates')\n        .find({\n          _id: { $in: checklistItemTemplateIds }\n        })\n        .toArray()\n\n      checklistItemTemplates.forEach((template) => {\n        templateOrderMap.set(template._id.toString(), template.order || 0)\n      })\n\n      // Update each checklist item instance with the order from its template\n      for (const instance of checklistItemInstances) {\n        const templateOrder =\n          templateOrderMap.get(instance.checklistItemTemplateId.toString()) || 0\n\n        await db\n          .collection('checklistItemInstances')\n          .updateOne({ _id: instance._id }, { $set: { order: templateOrder } })\n        logger.info(\n          `Updated checklist item instance ${instance.name} with order ${templateOrder}`\n        )\n      }\n    }\n  }\n\n  logger.info('Migration completed successfully')\n}\n\n\n--- scripts/migrations/add-workflow-order.js ---\n/**\n * Migration script to add order field to existing workflow templates and instances\n * @param {import('mongodb').Db} db - MongoDB database instance\n * @param {object} logger - Logger instance\n * @returns {Promise<void>}\n */\nexport default async function (db, logger) {\n  // Step 1: Update workflow templates\n  logger.info('Updating workflow templates...')\n\n  // Get all governance templates\n  const governanceTemplates = await db\n    .collection('governanceTemplates')\n    .find({})\n    .toArray()\n\n  for (const govTemplate of governanceTemplates) {\n    // Get all workflow templates for this governance template\n    const workflowTemplates = await db\n      .collection('workflowTemplates')\n      .find({ governanceTemplateId: govTemplate._id })\n      .sort({ name: 1 }) // Sort by name initially\n      .toArray()\n\n    // Update each workflow template with an order field\n    for (let i = 0; i < workflowTemplates.length; i++) {\n      await db\n        .collection('workflowTemplates')\n        .updateOne({ _id: workflowTemplates[i]._id }, { $set: { order: i } })\n      logger.info(\n        `Updated workflow template ${workflowTemplates[i].name} with order ${i}`\n      )\n    }\n  }\n\n  // Step 2: Update workflow instances\n  logger.info('Updating workflow instances...')\n\n  // Get all projects\n  const projects = await db.collection('projects').find({}).toArray()\n\n  for (const project of projects) {\n    // Get all workflow instances for this project\n    const workflowInstances = await db\n      .collection('workflowInstances')\n      .find({ projectId: project._id })\n      .toArray()\n\n    // Create a map of workflow template IDs to their order\n    const templateOrderMap = new Map()\n    const workflowTemplates = await db\n      .collection('workflowTemplates')\n      .find({\n        _id: {\n          $in: workflowInstances.map((wi) => wi.workflowTemplateId)\n        }\n      })\n      .toArray()\n\n    workflowTemplates.forEach((template) => {\n      templateOrderMap.set(template._id.toString(), template.order || 0)\n    })\n\n    // Update each workflow instance with the order from its template\n    for (const instance of workflowInstances) {\n      const templateOrder =\n        templateOrderMap.get(instance.workflowTemplateId.toString()) || 0\n\n      await db\n        .collection('workflowInstances')\n        .updateOne({ _id: instance._id }, { $set: { order: templateOrder } })\n      logger.info(\n        `Updated workflow instance ${instance.name} with order ${templateOrder}`\n      )\n    }\n  }\n\n  logger.info('Migration completed successfully')\n}\n"
    },
    {
      "chunk_id": "configuration",
      "description": "Application configuration files",
      "files": [
        "src/config/index.js",
        "compose/aws.env",
        "compose/start-localstack.sh",
        "compose.yml",
        "Dockerfile",
        "nodemon.json",
        "package.json",
        "tsconfig.json",
        "tsconfig.test.json"
      ],
      "content": "\n\n--- src/config/index.js ---\nimport convict from 'convict'\nimport path from 'node:path'\nimport { fileURLToPath } from 'node:url'\n\nconst dirname = path.dirname(fileURLToPath(import.meta.url))\n\nconst isProduction = process.env.NODE_ENV === 'production'\nconst isDev = process.env.NODE_ENV === 'development'\nconst isTest = process.env.NODE_ENV === 'test'\nconst config = convict({\n  serviceVersion: {\n    doc: 'The service version, this variable is injected into your docker container in CDP environments',\n    format: String,\n    nullable: true,\n    default: null,\n    env: 'SERVICE_VERSION'\n  },\n  env: {\n    doc: 'The application environment.',\n    format: ['production', 'development', 'test'],\n    default: 'development',\n    env: 'NODE_ENV'\n  },\n  port: {\n    doc: 'The port to bind.',\n    format: 'port',\n    default: 3001,\n    env: 'PORT'\n  },\n  serviceName: {\n    doc: 'Api Service Name',\n    format: String,\n    default: 'ai-sdlc-governance-api'\n  },\n  root: {\n    doc: 'Project root',\n    format: String,\n    default: path.resolve(dirname, '../..')\n  },\n  isProduction: {\n    doc: 'If this application running in the production environment',\n    format: Boolean,\n    default: isProduction\n  },\n  isDevelopment: {\n    doc: 'If this application running in the development environment',\n    format: Boolean,\n    default: isDev\n  },\n  isTest: {\n    doc: 'If this application running in the test environment',\n    format: Boolean,\n    default: isTest\n  },\n  log: {\n    enabled: {\n      doc: 'Is logging enabled',\n      format: Boolean,\n      default: !isTest,\n      env: 'LOG_ENABLED'\n    },\n    level: {\n      doc: 'Logging level',\n      format: ['fatal', 'error', 'warn', 'info', 'debug', 'trace', 'silent'],\n      default: 'info',\n      env: 'LOG_LEVEL'\n    },\n    format: {\n      doc: 'Format to output logs in.',\n      format: ['ecs', 'pino-pretty'],\n      default: isProduction ? 'ecs' : 'pino-pretty',\n      env: 'LOG_FORMAT'\n    },\n    redact: {\n      doc: 'Log paths to redact',\n      format: Array,\n      default: isProduction\n        ? ['req.headers.authorization', 'req.headers.cookie', 'res.headers']\n        : []\n    }\n  },\n  mongoUri: {\n    doc: 'URI for mongodb',\n    format: String,\n    default: 'mongodb://127.0.0.1:27017/',\n    env: 'MONGO_URI'\n  },\n  mongoDatabase: {\n    doc: 'database for mongodb',\n    format: String,\n    default: 'ai-sdlc-governance-api',\n    env: 'MONGO_DATABASE'\n  },\n  httpProxy: {\n    doc: 'HTTP Proxy',\n    format: String,\n    nullable: true,\n    default: null,\n    env: 'HTTP_PROXY'\n  },\n  isSecureContextEnabled: {\n    doc: 'Enable Secure Context',\n    format: Boolean,\n    default: isProduction,\n    env: 'ENABLE_SECURE_CONTEXT'\n  },\n  isMetricsEnabled: {\n    doc: 'Enable metrics reporting',\n    format: Boolean,\n    default: isProduction,\n    env: 'ENABLE_METRICS'\n  },\n  tracing: {\n    header: {\n      doc: 'Which header to track',\n      format: String,\n      default: 'x-cdp-request-id',\n      env: 'TRACING_HEADER'\n    }\n  }\n})\n\nconfig.validate({ allowed: 'strict' })\n\nexport { config }\n\n\n--- compose/aws.env ---\nAWS_REGION=eu-west-2\nAWS_DEFAULT_REGION=eu-west-2\nAWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\n\n\n--- compose/start-localstack.sh ---\n#!/bin/bash\nexport AWS_REGION=eu-west-2\nexport AWS_DEFAULT_REGION=eu-west-2\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\n\n# S3 buckets\n# aws --endpoint-url=http://localhost:4566 s3 mb s3://my-bucket\n\n# SQS queues\n# aws --endpoint-url=http://localhost:4566 sqs create-queue --queue-name my-queue\n\n\n--- compose.yml ---\nservices:\n  localstack:\n    image: localstack/localstack:3.0.2\n    ports:\n      - '4566:4566' # LocalStack Gateway\n      - '4510-4559:4510-4559' # external services port range\n    env_file:\n      - 'compose/aws.env'\n    environment:\n      DEBUG: ${DEBUG:-1}\n      LS_LOG: WARN # Localstack DEBUG Level\n      SERVICES: s3,sqs,sns,firehose\n      LOCALSTACK_HOST: 127.0.0.1\n    volumes:\n      - '${TMPDIR:-/tmp}/localstack:/var/lib/localstack'\n      - ./compose/start-localstack.sh:/etc/localstack/init/ready.d/start-localstack.sh\n    healthcheck:\n      test: ['CMD', 'curl', 'localhost:4566']\n      interval: 5s\n      start_period: 5s\n      retries: 3\n    networks:\n      - cdp-tenant\n\n  redis:\n    image: redis:7.2.3-alpine3.18\n    ports:\n      - '6379:6379'\n    restart: always\n    networks:\n      - cdp-tenant\n\n  mongodb:\n    image: mongo:6.0.13\n    networks:\n      - cdp-tenant\n    ports:\n      - '27017:27017'\n    volumes:\n      - mongodb-data:/data\n    restart: always\n\n  ################################################################################\n\n  # your-frontend:\n  #   image: defradigital/your-frontend:${YOUR_FRONTEND_VERSION:-latest}\n  #   ports:\n  #     - '3000:3000'\n  #   links:\n  #     - 'localstack:localstack'\n  #     - 'redis:redis'\n  #   depends_on:\n  #     localstack:\n  #       condition: service_healthy\n  #     redis:\n  #       condition: service_started\n  #   env_file:\n  #     - 'compose/aws.env'\n  #   environment:\n  #     PORT: 3000\n  #     NODE_ENV: development\n  #     REDIS_HOST: redis\n  #     LOCALSTACK_ENDPOINT: http://localstack:4566\n  #     USE_SINGLE_INSTANCE_CACHE: true\n  #   networks:\n  #     - cdp-tenant\n\n  your-backend:\n    build: ./\n    ports:\n      - '3555:3555'\n    links:\n      - 'localstack:localstack'\n      - 'mongodb:mongodb'\n    depends_on:\n      localstack:\n        condition: service_healthy\n      mongodb:\n        condition: service_started\n    env_file:\n      - 'compose/aws.env'\n    environment:\n      PORT: 3555\n      NODE_ENV: development\n      LOCALSTACK_ENDPOINT: http://localstack:4566\n      MONGO_URI: mongodb://mongodb:27017/\n    networks:\n      - cdp-tenant\n\n################################################################################\n\nvolumes:\n  mongodb-data:\n\nnetworks:\n  cdp-tenant:\n    driver: bridge\n\n\n--- Dockerfile ---\nARG PARENT_VERSION=latest-22\nARG PORT=3000\nARG PORT_DEBUG=9229\n\nFROM defradigital/node-development:${PARENT_VERSION} AS development\nARG PARENT_VERSION\nLABEL uk.gov.defra.ffc.parent-image=defradigital/node-development:${PARENT_VERSION}\n\nARG PORT\nARG PORT_DEBUG\nENV PORT=${PORT}\nEXPOSE ${PORT} ${PORT_DEBUG}\n\nCOPY --chown=node:node package*.json ./\nRUN npm install\nCOPY --chown=node:node . .\nRUN npm run build\n\nCMD [ \"npm\", \"run\", \"docker:dev\" ]\n\nFROM defradigital/node:${PARENT_VERSION} AS production\nARG PARENT_VERSION\nLABEL uk.gov.defra.ffc.parent-image=defradigital/node:${PARENT_VERSION}\n\n# Add curl to template.\n# CDP PLATFORM HEALTHCHECK REQUIREMENT\nUSER root\nRUN apk update && \\\n    apk add curl\nUSER node\n\nCOPY --from=development /home/node/package*.json ./\nCOPY --from=development /home/node/.server ./.server/\n\nRUN npm ci --omit=dev\n\nARG PORT\nENV PORT=${PORT}\nEXPOSE ${PORT}\n\nCMD [ \"node\", \".\" ]\n\n\n--- nodemon.json ---\n{\n  \"watch\": [\".public\", \"./src\", \"./mock-api\"],\n  \"ignore\": [\"**/*.test.*\", \"./test-helpers\", \"./src/common/assets\"],\n  \"ext\": \"js,json,njk,scss\",\n  \"signal\": \"SIGINT\"\n}\n\n\n--- package.json ---\n{\n  \"name\": \"ai-sdlc-governance-api\",\n  \"version\": \"0.0.0\",\n  \"description\": \"CDP Backend Template\",\n  \"main\": \".server/index.js\",\n  \"type\": \"module\",\n  \"engines\": {\n    \"node\": \">=22\"\n  },\n  \"scripts\": {\n    \"build\": \"npm run build:server\",\n    \"build:server\": \"NODE_ENV=production babel --delete-dir-on-start --ignore \\\"**/*.test.js\\\" --ignore \\\"**/__fixtures__\\\" --ignore \\\"**/test-helpers\\\" --copy-files --no-copy-ignored --out-dir ./.server ./src\",\n    \"docker:dev\": \"NODE_ENV=development npm run server:watch\",\n    \"dev\": \"npm run server:watch\",\n    \"dev:debug\": \"npm run server:debug\",\n    \"format\": \"prettier --write \\\"src/**/*.js\\\" \\\"**/*.{js,cjs,md,json,config.js,test.js,graphql.js}\\\"\",\n    \"format:check\": \"prettier --check \\\"src/**/*.js\\\" \\\"**/*.{js,cjs,md,json,config.js,test.js,graphql.js}\\\"\",\n    \"git:pre-commit-hook\": \"npm run format:check && npm run lint && npm test\",\n    \"postinstall\": \"npm run setup:husky\",\n    \"lint\": \"run-s lint:js lint:types\",\n    \"lint:fix\": \"eslint --cache . --fix\",\n    \"lint:js\": \"eslint --cache .\",\n    \"lint:types\": \"tsc --build tsconfig.json\",\n    \"postversion\": \"git add package.json package-lock.json && git commit -m $npm_package_version\",\n    \"test\": \"jest --coverage --verbose --runInBand\",\n    \"test:watch\": \"jest --watch\",\n    \"server:watch\": \"nodemon --exec tsx --enable-source-maps ./src\",\n    \"server:debug\": \"nodemon --exec tsx --enable-source-maps --inspect ./src\",\n    \"prestart\": \"npm run build\",\n    \"start\": \"NODE_ENV=production node --use-strict .\",\n    \"setup:husky\": \"node -e \\\"try { (await import('husky')).default() } catch (e) { if (e.code !== 'ERR_MODULE_NOT_FOUND') throw e }\\\" --input-type module\",\n    \"db:dump\": \"node scripts/manage-mongodb.js dump\",\n    \"db:restore\": \"node scripts/manage-mongodb.js restore\",\n    \"db:deleteAll\": \"node scripts/manage-mongodb.js deleteAll\",\n    \"test:e2e\": \"playwright test\",\n    \"test:e2e:ui\": \"playwright test --ui\",\n    \"test:e2e:api\": \"playwright test --project=api\"\n  },\n  \"author\": \"Defra DDTS\",\n  \"license\": \"OGL-UK-3.0\",\n  \"dependencies\": {\n    \"@babel/runtime\": \"^7.26.0\",\n    \"@defra/hapi-tracing\": \"^1.0.0\",\n    \"@elastic/ecs-pino-format\": \"^1.5.0\",\n    \"@hapi/boom\": \"^10.0.1\",\n    \"@hapi/hapi\": \"^21.3.12\",\n    \"@hapi/inert\": \"^7.1.0\",\n    \"@hapi/vision\": \"^7.0.3\",\n    \"aws-embedded-metrics\": \"^4.2.0\",\n    \"aws4\": \"^1.13.2\",\n    \"babel-plugin-module-resolver\": \"^5.0.2\",\n    \"convict\": \"^6.2.4\",\n    \"dotenv\": \"^16.4.5\",\n    \"global-agent\": \"^3.0.0\",\n    \"hapi-pino\": \"^12.1.0\",\n    \"hapi-pulse\": \"^3.0.1\",\n    \"hapi-swagger\": \"^17.3.2\",\n    \"https-proxy-agent\": \"^7.0.5\",\n    \"lodash\": \"^4.17.21\",\n    \"mongo-locks\": \"^3.0.2\",\n    \"mongodb\": \"^6.10.0\",\n    \"node-fetch\": \"^3.3.2\",\n    \"pino\": \"^9.5.0\",\n    \"pino-pretty\": \"^13.0.0\",\n    \"undici\": \"^6.20.1\",\n    \"yargs\": \"^17.7.2\"\n  },\n  \"devDependencies\": {\n    \"@babel/cli\": \"^7.25.9\",\n    \"@babel/core\": \"^7.26.0\",\n    \"@babel/preset-env\": \"^7.26.0\",\n    \"@playwright/test\": \"^1.50.1\",\n    \"@shelf/jest-mongodb\": \"4.3.2\",\n    \"@types/convict\": \"^6.1.6\",\n    \"@types/jest\": \"^29.5.14\",\n    \"@types/lodash\": \"^4.17.13\",\n    \"@types/node\": \"^22.9.0\",\n    \"@types/nunjucks\": \"^3.2.6\",\n    \"@types/webpack-assets-manifest\": \"^5.1.4\",\n    \"@typescript-eslint/eslint-plugin\": \"^7.17.0\",\n    \"@typescript-eslint/parser\": \"^7.17.0\",\n    \"autoprefixer\": \"^10.4.20\",\n    \"babel-jest\": \"^29.7.0\",\n    \"babel-loader\": \"^9.2.1\",\n    \"babel-plugin-transform-import-meta\": \"^2.2.1\",\n    \"eslint\": \"^8.57.0\",\n    \"eslint-config-prettier\": \"^9.1.0\",\n    \"eslint-config-standard\": \"^17.1.0\",\n    \"eslint-import-resolver-typescript\": \"^3.6.3\",\n    \"eslint-plugin-import\": \"^2.30.0\",\n    \"eslint-plugin-jest\": \"^28.8.3\",\n    \"eslint-plugin-jest-formatting\": \"^3.1.0\",\n    \"eslint-plugin-jsdoc\": \"^48.8.3\",\n    \"eslint-plugin-n\": \"^16.6.2\",\n    \"eslint-plugin-prettier\": \"^5.2.1\",\n    \"eslint-plugin-promise\": \"^6.4.0\",\n    \"husky\": \"^9.1.6\",\n    \"jest\": \"^29.7.0\",\n    \"jest-fetch-mock\": \"3.0.3\",\n    \"nodemon\": \"^3.1.7\",\n    \"npm-run-all\": \"^4.1.5\",\n    \"prettier\": \"^3.3.3\",\n    \"tsx\": \"^4.19.2\",\n    \"typescript\": \"^5.6.3\"\n  }\n}\n\n\n--- tsconfig.json ---\n{\n  \"compilerOptions\": {\n    \"allowJs\": true,\n    \"checkJs\": false,\n    \"module\": \"NodeNext\",\n    \"noEmit\": true,\n    \"paths\": {\n      \"~/*\": [\"./*\"]\n    },\n    \"resolveJsonModule\": true,\n    \"skipLibCheck\": true,\n    \"strictFunctionTypes\": true,\n    \"strictNullChecks\": true,\n    \"types\": [\"jest\"]\n  },\n  \"exclude\": [\n    \"node_modules\",\n    \"coverage\",\n    \"tests/**/*\",\n    \"playwright-report/**/*\",\n    \".server/**/*\",\n    \".cache/**/*\"\n  ],\n  \"include\": [\"**/*.cjs\", \"**/*.js\", \".eslintrc.*\", \".prettierrc.*\"]\n}\n\n\n--- tsconfig.test.json ---\n{\n  \"extends\": \"./tsconfig.json\",\n  \"compilerOptions\": {\n    \"types\": [\"jest\", \"@playwright/test\"]\n  },\n  \"include\": [\"tests/**/*\"],\n  \"exclude\": [\"node_modules\", \"coverage\"]\n}\n"
    },
    {
      "chunk_id": "testing_setup",
      "description": "Test configuration and setup files",
      "files": [
        "babel.config.cjs",
        "jest-mongodb-config.cjs",
        "jest.config.js",
        "playwright.config.js"
      ],
      "content": "\n\n--- babel.config.cjs ---\nconst { NODE_ENV } = process.env\n\n/**\n * @type {TransformOptions}\n */\nmodule.exports = {\n  presets: [\n    [\n      '@babel/preset-env',\n      {\n        modules: NODE_ENV === 'test' ? 'auto' : false\n      }\n    ]\n  ],\n  plugins: [\n    [\n      'module-resolver',\n      {\n        root: ['./'],\n        alias: {\n          '~': '.'\n        }\n      }\n    ]\n  ],\n  env: {\n    test: {\n      plugins: ['babel-plugin-transform-import-meta']\n    }\n  }\n}\n\n/**\n * @import { TransformOptions } from '@babel/core'\n */\n\n\n--- jest-mongodb-config.cjs ---\nmodule.exports = {\n  mongodbMemoryServerOptions: {\n    binary: {\n      version: '4.0.3',\n      skipMD5: true\n    },\n    instance: {\n      dbName: 'ai-sdlc-governance-api',\n      replSet: {\n        name: 'testset'\n      }\n    }\n  }\n}\n\n\n--- jest.config.js ---\n/**\n * @type {Config}\n */\nexport default {\n  rootDir: '.',\n  verbose: true,\n  resetModules: true,\n  clearMocks: true,\n  silent: false,\n  preset: '@shelf/jest-mongodb',\n  watchPathIgnorePatterns: ['globalConfig'],\n  testMatch: ['**/src/**/*.test.js'],\n  reporters: ['default', ['github-actions', { silent: false }], 'summary'],\n  setupFiles: ['<rootDir>/.jest/setup.js'],\n  setupFilesAfterEnv: ['<rootDir>/.jest/setup-after-env.js'],\n  collectCoverageFrom: ['src/**/*.js'],\n  coveragePathIgnorePatterns: [\n    '<rootDir>/node_modules/',\n    '<rootDir>/.server',\n    'index.js'\n  ],\n  coverageDirectory: '<rootDir>/coverage',\n  transform: {\n    '^.+\\\\.js$': 'babel-jest'\n  },\n  transformIgnorePatterns: [\n    `node_modules/(?!${[\n      '@defra/hapi-tracing', // Supports ESM only\n      'node-fetch' // Supports ESM only\n    ].join('|')}/)`\n  ]\n}\n\n/**\n * @import { Config } from 'jest'\n */\n\n\n--- playwright.config.js ---\n// @ts-check\nimport { defineConfig } from '@playwright/test'\n\nexport default defineConfig({\n  testDir: './tests',\n  timeout: 30000,\n  expect: {\n    timeout: 5000\n  },\n  use: {\n    baseURL: process.env.BASE_URL ?? 'http://localhost:3001',\n    extraHTTPHeaders: {\n      Accept: 'application/json'\n    }\n  },\n  reporter: [['list']],\n  projects: [\n    {\n      name: 'api-tests',\n      testMatch: /.*\\.spec\\.js/\n    }\n  ]\n})\n"
    },
    {
      "chunk_id": "documentation",
      "description": "Project documentation and README files",
      "files": [
        "README.md",
        "LICENCE",
        "docs/checklist-item-ordering.md",
        "docs/workflow-ordering.md",
        "src/api/example/README.md"
      ],
      "content": "\n\n--- README.md ---\n# ai-sdlc-governance-api\n\nCore delivery platform Node.js Backend Template.\n\n- [Requirements](#requirements)\n  - [Node.js](#nodejs)\n- [Local development](#local-development)\n  - [Setup](#setup)\n  - [Development](#development)\n  - [Testing](#testing)\n  - [Production](#production)\n  - [Npm scripts](#npm-scripts)\n  - [Update dependencies](#update-dependencies)\n  - [Formatting](#formatting)\n    - [Windows prettier issue](#windows-prettier-issue)\n- [API endpoints](#api-endpoints)\n- [Development helpers](#development-helpers)\n  - [MongoDB Locks](#mongodb-locks)\n- [Docker](#docker)\n  - [Development image](#development-image)\n  - [Production image](#production-image)\n  - [Docker Compose](#docker-compose)\n  - [Dependabot](#dependabot)\n  - [SonarCloud](#sonarcloud)\n- [Licence](#licence)\n  - [About the licence](#about-the-licence)\n\n## Requirements\n\n### Node.js\n\nPlease install [Node.js](http://nodejs.org/) `>= v18` and [npm](https://nodejs.org/) `>= v9`. You will find it\neasier to use the Node Version Manager [nvm](https://github.com/creationix/nvm)\n\nTo use the correct version of Node.js for this application, via nvm:\n\n```bash\ncd ai-sdlc-governance-api\nnvm use\n```\n\n## Local development\n\n### Setup\n\nInstall application dependencies:\n\n```bash\nnpm install\n```\n\n### Development\n\nTo run the application in `development` mode run:\n\n```bash\nnpm run dev\n```\n\n### Testing\n\nTo test the application run:\n\n```bash\nnpm run test\n```\n\n### Production\n\nTo mimic the application running in `production` mode locally run:\n\n```bash\nnpm start\n```\n\n### Npm scripts\n\nAll available Npm scripts can be seen in [package.json](./package.json).\nTo view them in your command line run:\n\n```bash\nnpm run\n```\n\n### Update dependencies\n\nTo update dependencies use [npm-check-updates](https://github.com/raineorshine/npm-check-updates):\n\n> The following script is a good start. Check out all the options on\n> the [npm-check-updates](https://github.com/raineorshine/npm-check-updates)\n\n```bash\nncu --interactive --format group\n```\n\n### Formatting\n\n#### Windows prettier issue\n\nIf you are having issues with formatting of line breaks on Windows update your global git config by running:\n\n```bash\ngit config --global core.autocrlf false\n```\n\n## API endpoints\n\n| Endpoint             | Description                    |\n| :------------------- | :----------------------------- |\n| `GET: /health`       | Health                         |\n| `GET: /example    `  | Example API (remove as needed) |\n| `GET: /example/<id>` | Example API (remove as needed) |\n\n## Development helpers\n\n### MongoDB Locks\n\nIf you require a write lock for Mongo you can acquire it via `server.locker` or `request.locker`:\n\n```javascript\nasync function doStuff(server) {\n  const lock = await server.locker.lock('unique-resource-name')\n\n  if (!lock) {\n    // Lock unavailable\n    return\n  }\n\n  try {\n    // do stuff\n  } finally {\n    await lock.free()\n  }\n}\n```\n\nKeep it small and atomic.\n\nYou may use **using** for the lock resource management.\nNote test coverage reports do not like that syntax.\n\n```javascript\nasync function doStuff(server) {\n  await using lock = await server.locker.lock('unique-resource-name')\n\n  if (!lock) {\n    // Lock unavailable\n    return\n  }\n\n  // do stuff\n\n  // lock automatically released\n}\n```\n\nHelper methods are also available in `/src/helpers/mongo-lock.js`.\n\n### Proxy\n\nWe are using forward-proxy which is set up by default. To make use of this: `import { fetch } from 'undici'` then because of the `setGlobalDispatcher(new ProxyAgent(proxyUrl))` calls will use the ProxyAgent Dispatcher\n\nIf you are not using Wreck, Axios or Undici or a similar http that uses `Request`. Then you may have to provide the proxy dispatcher:\n\nTo add the dispatcher to your own client:\n\n```javascript\nimport { ProxyAgent } from 'undici'\n\nreturn await fetch(url, {\n  dispatcher: new ProxyAgent({\n    uri: proxyUrl,\n    keepAliveTimeout: 10,\n    keepAliveMaxTimeout: 10\n  })\n})\n```\n\n## Docker\n\n### Development image\n\nBuild:\n\n```bash\ndocker build --target development --no-cache --tag ai-sdlc-governance-api:development .\n```\n\nRun:\n\n```bash\ndocker run -e PORT=3001 -p 3001:3001 ai-sdlc-governance-api:development\n```\n\n### Production image\n\nBuild:\n\n```bash\ndocker build --no-cache --tag ai-sdlc-governance-api .\n```\n\nRun:\n\n```bash\ndocker run -e PORT=3001 -p 3001:3001 ai-sdlc-governance-api\n```\n\n### Docker Compose\n\nA local environment with:\n\n- Localstack for AWS services (S3, SQS)\n- Redis\n- MongoDB\n- This service.\n- A commented out frontend example.\n\n```bash\ndocker compose up --build -d\n```\n\n### Dependabot\n\nWe have added an example dependabot configuration file to the repository. You can enable it by renaming\nthe [.github/example.dependabot.yml](.github/example.dependabot.yml) to `.github/dependabot.yml`\n\n### SonarCloud\n\nInstructions for setting up SonarCloud can be found in [sonar-project.properties](./sonar-project.properties)\n\n## Licence\n\nTHIS INFORMATION IS LICENSED UNDER THE CONDITIONS OF THE OPEN GOVERNMENT LICENCE found at:\n\n<http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3>\n\nThe following attribution statement MUST be cited in your products and applications when using this information.\n\n> Contains public sector information licensed under the Open Government license v3\n\n### About the licence\n\nThe Open Government Licence (OGL) was developed by the Controller of Her Majesty's Stationery Office (HMSO) to enable\ninformation providers in the public sector to license the use and re-use of their information under a common open\nlicence.\n\nIt is designed to encourage use and re-use of information freely and flexibly, with only a few conditions.\n\n\n--- LICENCE ---\nThe Open Government Licence (OGL) Version 3\n\nCopyright (c) 2023 Defra\n\nThis source code is licensed under the Open Government Licence v3.0. To view this\nlicence, visit www.nationalarchives.gov.uk/doc/open-government-licence/version/3\nor write to the Information Policy Team, The National Archives, Kew, Richmond,\nSurrey, TW9 4DU.\n\n\n--- docs/checklist-item-ordering.md ---\n# Checklist Item Ordering Feature\n\n## Overview\n\nThe checklist item ordering feature allows for manual ordering of checklist item templates and instances. This ordering is used to determine the display order of checklist items in the UI, providing a more intuitive and customizable user experience.\n\n## Implementation Details\n\n### Checklist Item Templates\n\nChecklist item templates now include an `order` field, which is an integer that determines the display order. Lower values are displayed first. The default value is `0`.\n\n```json\n{\n  \"_id\": \"60d21bbfe3d5d533d9fc1e4c\",\n  \"workflowTemplateId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"name\": \"Upload Model Documentation\",\n  \"description\": \"Upload documentation for the AI model\",\n  \"type\": \"document\",\n  \"dependencies_requires\": [],\n  \"metadata\": {\n    \"requiredEvidence\": true,\n    \"approver\": \"manager\"\n  },\n  \"order\": 1,\n  \"createdAt\": \"2024-03-20T10:00:00.000Z\",\n  \"updatedAt\": \"2024-03-20T10:00:00.000Z\"\n}\n```\n\n### Checklist Item Instances\n\nWhen a project is created, the `order` field from each checklist item template is copied to the corresponding checklist item instance. This ensures that the ordering is preserved when checklist items are instantiated for a project.\n\n```json\n{\n  \"_id\": \"60d21bbfe3d5d533d9fc1e4c\",\n  \"workflowInstanceId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"checklistItemTemplateId\": \"60d21bbfe3d5d533d9fc1e4e\",\n  \"name\": \"Upload Model Documentation\",\n  \"description\": \"Upload documentation for the AI model\",\n  \"type\": \"document\",\n  \"status\": \"incomplete\",\n  \"dependencies_requires\": [],\n  \"metadata\": {\n    \"requiredEvidence\": true,\n    \"approver\": \"manager\"\n  },\n  \"order\": 1,\n  \"createdAt\": \"2024-03-20T10:00:00.000Z\",\n  \"updatedAt\": \"2024-03-20T10:00:00.000Z\"\n}\n```\n\n## API Usage\n\n### Creating a Checklist Item Template with Order\n\nWhen creating a checklist item template, the `order` field is automatically calculated and set to the maximum order value for all checklist item templates in the same workflow template plus 1. This ensures that new checklist item templates are always added to the end of the list.\n\n```json\n{\n  \"workflowTemplateId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"name\": \"Upload Model Documentation\",\n  \"description\": \"Upload documentation for the AI model\",\n  \"type\": \"document\",\n  \"dependencies_requires\": [],\n  \"metadata\": {\n    \"requiredEvidence\": true,\n    \"approver\": \"manager\"\n  }\n}\n```\n\nThe response will include the automatically calculated `order` value:\n\n```json\n{\n  \"_id\": \"60d21bbfe3d5d533d9fc1e4c\",\n  \"workflowTemplateId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"name\": \"Upload Model Documentation\",\n  \"description\": \"Upload documentation for the AI model\",\n  \"type\": \"document\",\n  \"dependencies_requires\": [],\n  \"metadata\": {\n    \"requiredEvidence\": true,\n    \"approver\": \"manager\"\n  },\n  \"order\": 3,\n  \"createdAt\": \"2024-03-20T10:00:00.000Z\",\n  \"updatedAt\": \"2024-03-20T10:00:00.000Z\"\n}\n```\n\n### Updating a Checklist Item Template's Order\n\nYou can update the `order` field of an existing checklist item template:\n\n```json\n{\n  \"order\": 2\n}\n```\n\n### Deleting a Checklist Item Template\n\nWhen a checklist item template is deleted, all remaining checklist item templates in the same workflow template with a higher order value will have their order decremented by 1. This ensures that the order remains sequential without gaps.\n\nFor example, if you have checklist item templates with orders 0, 1, 2, 3 and delete the template with order 1, the remaining templates will be reordered to 0, 1, 2.\n\n### Retrieving Checklist Item Templates\n\nWhen retrieving checklist item templates for a workflow template, they are automatically sorted by their `order` field:\n\n```\nGET /api/v1/checklist-item-templates?workflowTemplateId=60d21bbfe3d5d533d9fc1e4d\n```\n\n## Migration\n\nA migration script has been created to add the `order` field to existing checklist item templates and instances. The migration runs automatically when the application is deployed.\n\nFor existing checklist item templates, the `order` is initially set based on the template's name (alphabetical order). For existing checklist item instances, the `order` is copied from their corresponding templates.\n\n## UI Considerations\n\nThe UI should display checklist items in the order specified by the `order` field. This provides a consistent and predictable experience for users, regardless of when the checklist items were created or their alphabetical order.\n\n\n--- docs/workflow-ordering.md ---\n# Workflow Ordering Feature\n\n## Overview\n\nThe workflow ordering feature allows for manual ordering of workflow templates and instances. This ordering is used to determine the display order of workflows in the UI, providing a more intuitive and customizable user experience.\n\n## Implementation Details\n\n### Workflow Templates\n\nWorkflow templates now include an `order` field, which is an integer that determines the display order. Lower values are displayed first. The default value is `0`.\n\n```json\n{\n  \"_id\": \"60d21bbfe3d5d533d9fc1e4c\",\n  \"governanceTemplateId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"name\": \"Model Development Workflow\",\n  \"description\": \"Workflow for developing and validating AI models\",\n  \"metadata\": {\n    \"priority\": \"high\",\n    \"category\": \"development\"\n  },\n  \"order\": 1,\n  \"createdAt\": \"2024-03-20T10:00:00.000Z\",\n  \"updatedAt\": \"2024-03-20T10:00:00.000Z\"\n}\n```\n\n### Workflow Instances\n\nWhen a project is created, the `order` field from each workflow template is copied to the corresponding workflow instance. This ensures that the ordering is preserved when workflows are instantiated for a project.\n\n```json\n{\n  \"_id\": \"60d21bbfe3d5d533d9fc1e4c\",\n  \"projectId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"workflowTemplateId\": \"60d21bbfe3d5d533d9fc1e4e\",\n  \"name\": \"Model Validation Workflow\",\n  \"description\": \"Workflow for validating AI models\",\n  \"metadata\": {\n    \"priority\": \"high\",\n    \"category\": \"validation\"\n  },\n  \"order\": 1,\n  \"status\": \"active\",\n  \"createdAt\": \"2024-03-20T10:00:00.000Z\",\n  \"updatedAt\": \"2024-03-20T10:00:00.000Z\"\n}\n```\n\n## API Usage\n\n### Creating a Workflow Template with Order\n\nWhen creating a workflow template, the `order` field is automatically calculated and set to the maximum order value for all workflow templates in the same governance template plus 1. This ensures that new workflow templates are always added to the end of the list.\n\n```json\n{\n  \"governanceTemplateId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"name\": \"Model Development Workflow\",\n  \"description\": \"Workflow for developing and validating AI models\",\n  \"metadata\": {\n    \"priority\": \"high\",\n    \"category\": \"development\"\n  }\n}\n```\n\nThe response will include the automatically calculated `order` value:\n\n```json\n{\n  \"_id\": \"60d21bbfe3d5d533d9fc1e4c\",\n  \"governanceTemplateId\": \"60d21bbfe3d5d533d9fc1e4d\",\n  \"name\": \"Model Development Workflow\",\n  \"description\": \"Workflow for developing and validating AI models\",\n  \"metadata\": {\n    \"priority\": \"high\",\n    \"category\": \"development\"\n  },\n  \"order\": 3,\n  \"createdAt\": \"2024-03-20T10:00:00.000Z\",\n  \"updatedAt\": \"2024-03-20T10:00:00.000Z\"\n}\n```\n\n### Updating a Workflow Template's Order\n\nYou can update the `order` field of an existing workflow template:\n\n```json\n{\n  \"order\": 2\n}\n```\n\n### Deleting a Workflow Template\n\nWhen a workflow template is deleted, all remaining workflow templates in the same governance template with a higher order value will have their order decremented by 1. This ensures that the order remains sequential without gaps.\n\nFor example, if you have workflow templates with orders 0, 1, 2, 3 and delete the template with order 1, the remaining templates will be reordered to 0, 1, 2.\n\n### Retrieving Workflow Instances\n\nWhen retrieving workflow instances for a project, they are automatically sorted by their `order` field:\n\n```\nGET /api/v1/workflow-instances?projectId=60d21bbfe3d5d533d9fc1e4d\n```\n\n## Migration\n\nA migration script has been created to add the `order` field to existing workflow templates and instances. The migration runs automatically when the application is deployed.\n\nFor existing workflow templates, the `order` is initially set based on the template's name (alphabetical order). For existing workflow instances, the `order` is copied from their corresponding templates.\n\n## UI Considerations\n\nThe UI should display workflows in the order specified by the `order` field. This provides a consistent and predictable experience for users, regardless of when the workflows were created or their alphabetical order.\n\n\n--- src/api/example/README.md ---\n# Example API endpoints\n\nThis is a bare-bones example of how to create an API controller, with example tests. Modify, remove or updates as\nyou wish.\n"
    },
    {
      "chunk_id": "example_api",
      "description": "Example API implementation for reference",
      "files": [
        "src/api/example/controllers/example-find-all.js",
        "src/api/example/controllers/example-find-all.test.js",
        "src/api/example/controllers/example-find-one.js",
        "src/api/example/controllers/example-find-one.test.js",
        "src/api/example/controllers/index.js",
        "src/api/example/helpers/find-all-example-data.js",
        "src/api/example/helpers/find-example-data.js",
        "src/api/example/index.js"
      ],
      "content": "\n\n--- src/api/example/controllers/example-find-all.js ---\nimport { findAllExampleData } from '~/src/api/example/helpers/find-all-example-data.js'\nimport { statusCodes } from '~/src/api/common/constants/status-codes.js'\n\n/**\n * Example controller\n * Finds all entries in a mongodb collection\n * @satisfies {Partial<ServerRoute>}\n */\nconst exampleFindAllController = {\n  handler: async (request, h) => {\n    const entities = await findAllExampleData(request.db)\n\n    return h.response({ message: 'success', entities }).code(statusCodes.ok)\n  }\n}\n\nexport { exampleFindAllController }\n\n/**\n * @import { ServerRoute } from '@hapi/hapi'\n */\n\n\n--- src/api/example/controllers/example-find-all.test.js ---\nimport { createServer } from '~/src/api/index.js'\nimport { statusCodes } from '~/src/api/common/constants/status-codes.js'\n\ndescribe('#exampleFindAllController', () => {\n  /** @type {Server} */\n  let server\n\n  beforeAll(async () => {\n    server = await createServer()\n    await server.initialize()\n  })\n\n  beforeEach(async () => {\n    await server.db.collection('example-data').insertMany([\n      { exampleId: 'four', exampleData: 'data' },\n      { exampleId: 'five', exampleData: 'data' }\n    ])\n  })\n\n  afterEach(async () => {\n    await server.db.collection('example-data').deleteMany({})\n  })\n\n  afterAll(async () => {\n    await server.stop({ timeout: 0 })\n  })\n\n  test('Should provide expected response', async () => {\n    const { result, statusCode } = await server.inject({\n      method: 'GET',\n      url: '/example'\n    })\n\n    expect(result).toEqual({\n      message: 'success',\n      entities: [\n        { exampleId: 'four', exampleData: 'data' },\n        { exampleId: 'five', exampleData: 'data' }\n      ]\n    })\n    expect(statusCode).toBe(statusCodes.ok)\n  })\n})\n\n/**\n * @import { Server } from '@hapi/hapi'\n */\n\n\n--- src/api/example/controllers/example-find-one.js ---\nimport Boom from '@hapi/boom'\nimport isNull from 'lodash/isNull.js'\n\nimport { findExampleData } from '~/src/api/example/helpers/find-example-data.js'\nimport { statusCodes } from '~/src/api/common/constants/status-codes.js'\n\n/**\n * @satisfies {Partial<ServerRoute>}\n */\nconst exampleFindOneController = {\n  /**\n   * @param { Request & MongoDBPlugin } request\n   * @param { ResponseToolkit } h\n   * @returns { Promise<*> }\n   */\n  handler: async (request, h) => {\n    const entity = await findExampleData(request.db, request.params.exampleId)\n    if (isNull(entity)) {\n      return Boom.boomify(Boom.notFound())\n    }\n\n    return h.response({ message: 'success', entity }).code(statusCodes.ok)\n  }\n}\n\nexport { exampleFindOneController }\n\n/**\n * @import { Request, ResponseToolkit, ServerRoute} from '@hapi/hapi'\n * @import { MongoDBPlugin } from '~/src/api/common/helpers/mongodb.js'\n */\n\n\n--- src/api/example/controllers/example-find-one.test.js ---\nimport { createServer } from '~/src/api/index.js'\nimport { statusCodes } from '~/src/api/common/constants/status-codes.js'\n\ndescribe('#exampleFindAllController', () => {\n  /** @type {Server} */\n  let server\n\n  beforeAll(async () => {\n    server = await createServer()\n    await server.initialize()\n  })\n\n  afterAll(async () => {\n    await server.stop({ timeout: 0 })\n  })\n\n  describe('With results', () => {\n    beforeEach(async () => {\n      await server.db\n        .collection('example-data')\n        .insertOne({ exampleId: 'one', exampleData: 'data' })\n    })\n\n    afterEach(async () => {\n      await server.db.collection('example-data').deleteMany({})\n    })\n\n    test('Should provide expected response', async () => {\n      const { result, statusCode } = await server.inject({\n        method: 'GET',\n        url: '/example/one'\n      })\n\n      expect(result).toEqual({\n        entity: {\n          exampleData: 'data',\n          exampleId: 'one'\n        },\n        message: 'success'\n      })\n      expect(statusCode).toBe(statusCodes.ok)\n    })\n  })\n\n  test('Should provide expected 404 response', async () => {\n    const { result, statusCode } = await server.inject({\n      method: 'GET',\n      url: '/example/one'\n    })\n\n    expect(result).toEqual({\n      error: 'Not Found',\n      message: 'Not Found',\n      statusCode: 404\n    })\n    expect(statusCode).toBe(statusCodes.notFound)\n  })\n})\n\n/**\n * @import { Server } from '@hapi/hapi'\n */\n\n\n--- src/api/example/controllers/index.js ---\nimport { exampleFindOneController } from '~/src/api/example/controllers/example-find-one.js'\nimport { exampleFindAllController } from '~/src/api/example/controllers/example-find-all.js'\n\nexport { exampleFindOneController, exampleFindAllController }\n\n\n--- src/api/example/helpers/find-all-example-data.js ---\n/**\n * Database helper. Returns all objects stored in the example-data collection in mongodb.\n * See src/server/api/common/helpers/mongodb.js for an example of how the indexes are created for this collection.\n * @param { Db } db\n * @returns {Promise<WithId<Document>[]>}\n */\nfunction findAllExampleData(db) {\n  const cursor = db\n    .collection('example-data')\n    .find({}, { projection: { _id: 0 } })\n\n  return cursor.toArray()\n}\n\nexport { findAllExampleData }\n\n/**\n * @import { Db, WithId, Document } from 'mongodb'\n */\n\n\n--- src/api/example/helpers/find-example-data.js ---\n/**\n * Finds and returns a single example record from mongodb.\n * See src/server/api/common/helpers/mongodb.js for an example of how the indexes are created for this collection.\n * @param { Db } db\n * @param { string } id\n * @returns {Promise<WithId<Document> | null>}\n */\nfunction findExampleData(db, id) {\n  return db\n    .collection('example-data')\n    .findOne({ exampleId: id }, { projection: { _id: 0 } })\n}\n\nexport { findExampleData }\n\n/**\n * @import { Db, WithId, Document } from 'mongodb'\n */\n\n\n--- src/api/example/index.js ---\nimport {\n  exampleFindOneController,\n  exampleFindAllController\n} from '~/src/api/example/controllers/index.js'\n\n/**\n * @satisfies {ServerRegisterPluginObject<void>}\n */\nconst example = {\n  plugin: {\n    name: 'example',\n    register: (server) => {\n      server.route([\n        {\n          method: 'GET',\n          path: '/example',\n          ...exampleFindAllController\n        },\n        {\n          method: 'GET',\n          path: '/example/{exampleId}',\n          ...exampleFindOneController\n        }\n      ])\n    }\n  }\n}\n\nexport { example }\n\n/**\n * @import { ServerRegisterPluginObject } from '@hapi/hapi'\n */\n"
    },
    {
      "chunk_id": "scripts_and_utilities",
      "description": "Various scripts and utilities for development and deployment",
      "files": [
        "scripts/git_cleanup.sh",
        "scripts/start_dev_server.sh",
        "sonar-project.properties"
      ],
      "content": "\n\n--- scripts/git_cleanup.sh ---\n#!/bin/bash\n\n# git-sync.sh - Synchronize local Git repository with remote branches\n\n# Exit on error\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Print with color\nprint_message() {\n    local color=$1\n    local message=$2\n    echo -e \"${color}${message}${NC}\"\n}\n\n# Check if we're in a git repository\nif ! git rev-parse --git-dir > /dev/null 2>&1; then\n    print_message \"$RED\" \"Error: Not a git repository\"\n    exit 1\nfi\n\n# Check for uncommitted changes\nif ! git diff-index --quiet HEAD --; then\n    print_message \"$RED\" \"Error: You have uncommitted changes. Please commit or stash them first.\"\n    exit 1\nfi\n\n# Get current branch\nCURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)\nprint_message \"$GREEN\" \"Current branch: $CURRENT_BRANCH\"\n\n# Fetch latest from remote and prune\nprint_message \"$YELLOW\" \"Fetching from remote and pruning...\"\ngit fetch origin --prune\n\n# Switch to main branch if not already on it\nif [ \"$CURRENT_BRANCH\" != \"main\" ]; then\n    print_message \"$YELLOW\" \"Switching to main branch...\"\n    git checkout main\nfi\n\n# Delete all local branches except main\nprint_message \"$YELLOW\" \"Deleting local branches except main...\"\ngit branch | grep -v '^*' | grep -v '^  main$' | xargs git branch -D 2>/dev/null || true\n\n# Create local branches for each remote branch\nprint_message \"$YELLOW\" \"Creating local branches from remote...\"\ngit branch -r | grep -v '\\->' | sed \"s,origin/,,\" | grep -v '^main$' | while read branch; do\n    print_message \"$GREEN\" \"Creating local branch: $branch\"\n    git checkout -B \"$branch\" \"origin/$branch\"\ndone\n\n# Switch back to original branch\nprint_message \"$YELLOW\" \"Switching back to $CURRENT_BRANCH...\"\ngit checkout \"$CURRENT_BRANCH\"\n\nprint_message \"$GREEN\" \"Sync complete! Current branches:\"\ngit branch\n\n--- scripts/start_dev_server.sh ---\n#!/bin/bash\n\nexport NODE_ENV=development\nexport LOG_LEVEL=debug\nclear && npm run dev \n\n--- sonar-project.properties ---\n# To set up Sonar cloud follow https://github.com/DEFRA/cdp-documentation/blob/main/howto/sonarcloud.md\n# Update properties in this file as per the howto instructions\n# Uncomment properties in this .github/workflows/check-pull-request.yml\n# Uncomment properties in this .github/workflows/publish.yml\n# Uncomment properties in this .github/workflows/publish-hotfix.yml\n\nsonar.projectKey=DEFRA_ai-sdlc-governance-api\nsonar.organization=defra\n\nsonar.links.homepage=https://github.com/DEFRA/ai-sdlc-governance-api\nsonar.links.ci=https://github.com/DEFRA/ai-sdlc-governance-api/actions\nsonar.links.scm=https://github.com/DEFRA/ai-sdlc-governance-api\nsonar.links.issue=https://github.com/DEFRA/ai-sdlc-governance-api/issues\n\nsonar.sources=src/\nsonar.exclusions=src/**/*.test.js\nsonar.tests=src/\nsonar.test.inclusions=src/**/*.test.js\n\nsonar.javascript.lcov.reportPaths=./coverage/lcov.info\n"
    },
    {
      "chunk_id": "test_data",
      "description": "Test data for the application",
      "files": [
        "test_data/mongodb_dumps/test_governance_template.json"
      ],
      "content": "\n\n--- test_data/mongodb_dumps/test_governance_template.json ---\n{\n  \"governanceTemplates\": [\n    {\n      \"_id\": \"67b1fd2f2104d8019b09583e\",\n      \"version\": \"1.0\",\n      \"name\": \"Defra Service Governance\",\n      \"description\": \"To-be governance model\",\n      \"createdAt\": \"2025-02-16T14:58:55.332Z\",\n      \"updatedAt\": \"2025-02-16T14:58:55.332Z\"\n    }\n  ],\n  \"workflowInstances\": [],\n  \"projects\": [],\n  \"auditLogs\": [],\n  \"mongo-locks\": [],\n  \"workflowTemplates\": [\n    {\n      \"_id\": \"67b1fd672104d8019b09583f\",\n      \"governanceTemplateId\": \"67b1fd2f2104d8019b09583e\",\n      \"name\": \"GDS Service Assessments\",\n      \"description\": \"Service assessment workflow\",\n      \"createdAt\": \"2025-02-16T14:59:51.010Z\",\n      \"updatedAt\": \"2025-02-16T14:59:51.010Z\"\n    },\n    {\n      \"_id\": \"67b1fd802104d8019b095840\",\n      \"governanceTemplateId\": \"67b1fd2f2104d8019b09583e\",\n      \"name\": \"GDS Spend Control\",\n      \"description\": \"Spend control workflow\",\n      \"createdAt\": \"2025-02-16T15:00:16.180Z\",\n      \"updatedAt\": \"2025-02-16T15:00:16.180Z\"\n    },\n    {\n      \"_id\": \"67b1fd922104d8019b095841\",\n      \"governanceTemplateId\": \"67b1fd2f2104d8019b09583e\",\n      \"name\": \"Service Readiness\",\n      \"description\": \"Service Readiness workflow\",\n      \"createdAt\": \"2025-02-16T15:00:34.978Z\",\n      \"updatedAt\": \"2025-02-16T15:00:34.978Z\"\n    },\n    {\n      \"_id\": \"67b1fda42104d8019b095842\",\n      \"governanceTemplateId\": \"67b1fd2f2104d8019b09583e\",\n      \"name\": \"Change Management\",\n      \"description\": \"Change Management Workflow\",\n      \"createdAt\": \"2025-02-16T15:00:52.184Z\",\n      \"updatedAt\": \"2025-02-16T15:00:52.184Z\"\n    }\n  ],\n  \"checklistItemTemplates\": [\n    {\n      \"_id\": \"67b1fdcb2104d8019b095843\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"Project Kickoff\",\n      \"description\": \"Starting point of project\",\n      \"type\": \"task\",\n      \"createdAt\": \"2025-02-16T15:01:31.233Z\",\n      \"updatedAt\": \"2025-02-16T15:01:31.233Z\"\n    },\n    {\n      \"_id\": \"67b1fdff2104d8019b095844\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"Project Online created (PMO)\",\n      \"description\": \"PMO task to setup the project in Project Online\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\"67b1fdcb2104d8019b095843\"],\n      \"createdAt\": \"2025-02-16T15:02:23.959Z\",\n      \"updatedAt\": \"2025-02-16T15:02:23.959Z\"\n    },\n    {\n      \"_id\": \"67b1fe632104d8019b095845\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"Project Kickoff - Spend Control Form Created\",\n      \"description\": \"Creation of the initial spend control form\",\n      \"type\": \"document\",\n      \"createdAt\": \"2025-02-16T15:04:03.515Z\",\n      \"updatedAt\": \"2025-02-16T21:45:19.320Z\",\n      \"dependencies_requires\": [\"67b1fdff2104d8019b095844\"]\n    },\n    {\n      \"_id\": \"67b1ff236f1a39437f13686a\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"Project Kickoff - Portfolio Assurance Board Scheduled\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\"67b1fe632104d8019b095845\"],\n      \"createdAt\": \"2025-02-16T15:07:15.961Z\",\n      \"updatedAt\": \"2025-02-16T15:07:15.961Z\"\n    },\n    {\n      \"_id\": \"67b1ff8e6f1a39437f13686b\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"Project Kickoff - Portfolio Assurance Board (PAB) Approval\",\n      \"type\": \"approval\",\n      \"dependencies_requires\": [\n        \"67b1ff236f1a39437f13686a\",\n        \"67b1fe632104d8019b095845\"\n      ],\n      \"createdAt\": \"2025-02-16T15:09:02.788Z\",\n      \"updatedAt\": \"2025-02-16T21:45:51.707Z\"\n    },\n    {\n      \"_id\": \"67b1ffbd6f1a39437f13686c\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"Project Kickoff - Portfolio Assurance Board (PAB) - Needs service assessment decision\",\n      \"type\": \"approval\",\n      \"dependencies_requires\": [\"67b1ff8e6f1a39437f13686b\"],\n      \"createdAt\": \"2025-02-16T15:09:49.315Z\",\n      \"updatedAt\": \"2025-02-16T15:09:49.315Z\"\n    },\n    {\n      \"_id\": \"67b1ffe06f1a39437f13686d\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"Start Discovery Phase\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\n        \"67b1ffbd6f1a39437f13686c\",\n        \"67b1fdff2104d8019b095844\"\n      ],\n      \"createdAt\": \"2025-02-16T15:10:24.221Z\",\n      \"updatedAt\": \"2025-02-16T15:29:05.379Z\"\n    },\n    {\n      \"_id\": \"67b2001d6f1a39437f13686e\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"Equality Analysis\",\n      \"description\": \"Equality Analysis SharePoint Form submitted\",\n      \"type\": \"document\",\n      \"dependencies_requires\": [\"67b1ffe06f1a39437f13686d\"],\n      \"createdAt\": \"2025-02-16T15:11:25.462Z\",\n      \"updatedAt\": \"2025-02-16T15:11:25.462Z\"\n    },\n    {\n      \"_id\": \"67b2003d6f1a39437f13686f\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"Slide deck created for end of discovery workshop\",\n      \"type\": \"document\",\n      \"dependencies_requires\": [\"67b1ffe06f1a39437f13686d\"],\n      \"createdAt\": \"2025-02-16T15:11:57.769Z\",\n      \"updatedAt\": \"2025-02-16T15:11:57.769Z\"\n    },\n    {\n      \"_id\": \"67b2005f6f1a39437f136870\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"End of Discovery workshops scheduled\",\n      \"description\": \"2-3 hour meeting with service assessors (service assessment-like)\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\"67b1ffe06f1a39437f13686d\"],\n      \"createdAt\": \"2025-02-16T15:12:31.318Z\",\n      \"updatedAt\": \"2025-02-16T15:42:55.514Z\"\n    },\n    {\n      \"_id\": \"67b200786f1a39437f136871\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"End of Discovery workshops completed\",\n      \"type\": \"approval\",\n      \"dependencies_requires\": [\n        \"67b2005f6f1a39437f136870\",\n        \"67b2003d6f1a39437f13686f\"\n      ],\n      \"createdAt\": \"2025-02-16T15:12:56.545Z\",\n      \"updatedAt\": \"2025-02-16T15:43:41.012Z\"\n    },\n    {\n      \"_id\": \"67b2008a6f1a39437f136872\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"End of Discovery Phase\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\"67b200786f1a39437f136871\"],\n      \"createdAt\": \"2025-02-16T15:13:14.552Z\",\n      \"updatedAt\": \"2025-02-16T15:13:14.552Z\"\n    },\n    {\n      \"_id\": \"67b20812294678094df63d3d\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"End Discovery - Spend control form updated\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\"67b2008a6f1a39437f136872\"],\n      \"createdAt\": \"2025-02-16T15:45:22.239Z\",\n      \"updatedAt\": \"2025-02-16T15:45:22.239Z\"\n    },\n    {\n      \"_id\": \"67b20840294678094df63d3e\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"End Discovery - Portfolio Approval Board (PAB) scheduled\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\"67b2008a6f1a39437f136872\"],\n      \"createdAt\": \"2025-02-16T15:46:08.397Z\",\n      \"updatedAt\": \"2025-02-16T15:46:08.397Z\"\n    },\n    {\n      \"_id\": \"67b20865294678094df63d3f\",\n      \"workflowTemplateId\": \"67b1fd802104d8019b095840\",\n      \"name\": \"End Discovery - Portfolio Assurance Board (PAB) Approval\",\n      \"type\": \"approval\",\n      \"dependencies_requires\": [\n        \"67b20840294678094df63d3e\",\n        \"67b20812294678094df63d3d\"\n      ],\n      \"createdAt\": \"2025-02-16T15:46:45.421Z\",\n      \"updatedAt\": \"2025-02-16T15:46:45.421Z\"\n    },\n    {\n      \"_id\": \"67b2088a294678094df63d40\",\n      \"workflowTemplateId\": \"67b1fd672104d8019b09583f\",\n      \"name\": \"Start Alpha Phase\",\n      \"type\": \"task\",\n      \"dependencies_requires\": [\n        \"67b20865294678094df63d3f\",\n        \"67b2008a6f1a39437f136872\"\n      ],\n      \"createdAt\": \"2025-02-16T15:47:22.347Z\",\n      \"updatedAt\": \"2025-02-16T21:42:18.188Z\"\n    }\n  ],\n  \"checklistItemInstances\": []\n}\n"
    },
    {
      "chunk_id": "constants",
      "description": "Constant values used throughout the application",
      "files": [
        "src/api/common/constants/status-codes.js"
      ],
      "content": "\n\n--- src/api/common/constants/status-codes.js ---\n/**\n * @typedef {Record<string, number>} StatusCodes\n */\nexport const statusCodes = {\n  ok: 200,\n  noContent: 204,\n  badRequest: 400,\n  unauthorized: 401,\n  forbidden: 403,\n  notFound: 404,\n  imATeapot: 418\n}\n"
    }
  ],
  "analyzed_code_chunks": [
    {
      "chunk_id": "governance_template_management",
      "summary": "This code implements a RESTful API for managing governance templates in an AI model development and deployment context. It provides CRUD operations (Create, Read, Update, Delete) for governance templates, including associated workflow templates and checklist items. The API handles template creation, retrieval, updating, and deletion, with cascading delete functionality for related workflow templates and checklist items. It also includes data validation, error handling, and Swagger documentation for API endpoints.",
      "data_model": "The code defines the following data models:\n\n1. Governance Template:\n   - _id: MongoDB ObjectId\n   - version: string\n   - name: string\n   - description: string (optional)\n   - createdAt: Date\n   - updatedAt: Date\n   - workflowTemplates: array of Workflow Templates\n\n2. Workflow Template:\n   - _id: MongoDB ObjectId\n   - governanceTemplateId: MongoDB ObjectId (reference to Governance Template)\n   - name: string\n   - description: string\n   - metadata: object\n   - order: integer\n   - createdAt: Date\n   - updatedAt: Date\n\n3. Checklist Item Template:\n   - _id: MongoDB ObjectId\n   - workflowTemplateId: MongoDB ObjectId (reference to Workflow Template)\n   - name: string\n   - description: string\n   - type: string\n   - dependencies_requires: array\n\n```mermaid\nerDiagram\n    GOVERNANCE_TEMPLATE ||--o{ WORKFLOW_TEMPLATE : contains\n    WORKFLOW_TEMPLATE ||--o{ CHECKLIST_ITEM_TEMPLATE : contains\n    GOVERNANCE_TEMPLATE {\n        ObjectId _id\n        string version\n        string name\n        string description\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_TEMPLATE {\n        ObjectId _id\n        ObjectId governanceTemplateId\n        string name\n        string description\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_TEMPLATE {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        string name\n        string description\n        string type\n        array dependencies_requires\n    }\n```\n\nThe data models are stored in MongoDB collections: 'governanceTemplates', 'workflowTemplates', and 'checklistItemTemplates'. The code handles data validation using Joi schemas and performs CRUD operations on these collections.",
      "interfaces": "The code defines the following RESTful API endpoints:\n\n1. POST /api/v1/governance-templates\n   - Description: Create a new governance template\n   - Request body: { version: string, name: string, description: string }\n   - Response: 200 OK with created template, 400 Bad Request, 409 Conflict\n\n2. GET /api/v1/governance-templates/{id}\n   - Description: Get a governance template by ID\n   - Path parameter: id (MongoDB ObjectId)\n   - Response: 200 OK with template, 404 Not Found, 400 Bad Request\n\n3. PUT /api/v1/governance-templates/{id}\n   - Description: Update a governance template\n   - Path parameter: id (MongoDB ObjectId)\n   - Request body: { version: string, name: string, description: string }\n   - Response: 200 OK with updated template, 404 Not Found, 400 Bad Request, 409 Conflict\n\n4. DELETE /api/v1/governance-templates/{id}\n   - Description: Delete a governance template\n   - Path parameter: id (MongoDB ObjectId)\n   - Response: 204 No Content, 404 Not Found, 400 Bad Request\n\n5. GET /api/v1/governance-templates\n   - Description: Get all governance templates with their workflow templates sorted by order\n   - Response: 200 OK with array of templates, 400 Bad Request\n\nThe API is documented using Swagger (hapi-swagger plugin) for easy integration and testing. The interfaces handle input validation, error responses, and appropriate HTTP status codes.",
      "business_logic": "The business logic in this code chunk includes:\n\n1. Governance Template Management:\n   - Creation of governance templates with version, name, and description\n   - Retrieval of individual governance templates by ID\n   - Updating existing governance templates\n   - Deletion of governance templates with cascading delete for associated workflow templates and checklist items\n   - Listing all governance templates with their associated workflow templates\n\n2. Workflow Template Association:\n   - Governance templates contain associated workflow templates\n   - Workflow templates are sorted by an 'order' field when retrieved\n\n3. Cascading Delete Logic:\n   - When a governance template is deleted, all associated workflow templates are also deleted\n   - For each deleted workflow template, all associated checklist item templates are deleted\n\n4. Data Integrity:\n   - Ensuring unique combinations of template name and version\n   - Handling conflicts when attempting to create or update templates with existing name-version combinations\n\n5. Error Handling:\n   - Proper error responses for various scenarios (not found, bad request, conflict)\n   - Use of Boom for generating HTTP-friendly error objects\n\n6. Date Tracking:\n   - Automatic creation and update of timestamps (createdAt, updatedAt) for governance templates\n\nThis business logic ensures proper management of governance templates and their associated entities in the context of AI model development and deployment governance.",
      "dependencies": "The code relies on the following dependencies:\n\n1. @hapi/hapi: Web framework for building the API server\n2. @hapi/boom: HTTP-friendly error objects\n3. mongodb: MongoDB driver for Node.js\n4. joi: Data validation library\n5. hapi-swagger: Swagger documentation generator for Hapi\n\nExternal services:\n- MongoDB: Used as the database for storing governance templates, workflow templates, and checklist item templates\n\nThe code interacts with MongoDB collections:\n- governanceTemplates\n- workflowTemplates\n- checklistItemTemplates\n\nAPI calls are made to these collections for CRUD operations. The MongoDB ObjectId is used for generating and handling unique identifiers for documents in the collections.",
      "configuration": "The code doesn't explicitly show configuration management, but it implies the following configuration needs:\n\n1. MongoDB connection: The code assumes a MongoDB connection is available through `request.db`. This likely requires configuration for:\n   - MongoDB connection string\n   - Database name\n   - Authentication credentials (if required)\n\n2. API versioning: The API routes are prefixed with '/api/v1/', indicating version 1 of the API.\n\n3. Hapi server configuration: The code is a Hapi plugin, which requires server setup and configuration (not shown in this chunk).\n\n4. Swagger configuration: The 'hapi-swagger' plugin is used for API documentation, which may require additional configuration for customization.\n\n5. Environment-specific configuration: While not explicitly shown, the code structure suggests that environment-specific configurations (development, production, etc.) might be used for different deployment scenarios.\n\nProper configuration management, including environment variables or configuration files, would be necessary for deploying this code in different environments.",
      "infrastructure": "The code doesn't directly include infrastructure-related elements, but it implies the following infrastructure needs:\n\n1. Node.js runtime environment for executing the JavaScript code.\n\n2. MongoDB database server for storing and managing the data.\n\n3. Web server (likely Hapi.js based on the code structure) to host the API endpoints.\n\n4. Potential need for a reverse proxy (e.g., Nginx) for production deployments.\n\n5. Possible containerization (e.g., Docker) for consistent deployment across environments.\n\n6. CI/CD pipeline for automated testing and deployment (suggested by the presence of E2E tests).\n\n7. API documentation hosting for the Swagger documentation generated by hapi-swagger.\n\n8. Potential cloud hosting platform for deploying the application and database (e.g., AWS, Google Cloud, Azure).\n\nWhile not explicitly defined in the code, these infrastructure components would be necessary for deploying and running the application in a production environment.",
      "non_functional": "The code addresses several non-functional aspects:\n\n1. Performance:\n   - Use of MongoDB for efficient data storage and retrieval\n   - Indexing is implied (e.g., unique index on name and version fields)\n\n2. Security:\n   - Input validation using Joi schemas to prevent injection attacks\n   - Use of MongoDB ObjectId for secure identifier generation\n\n3. Error Handling:\n   - Comprehensive error handling using Boom for HTTP-friendly error responses\n   - Specific error handling for common scenarios (e.g., not found, conflicts)\n\n4. Testing:\n   - Includes E2E tests for API endpoints using Playwright\n   - Tests cover main CRUD operations and cascade delete functionality\n\n5. API Documentation:\n   - Uses hapi-swagger for automatic API documentation generation\n\n6. Data Integrity:\n   - Ensures data consistency with cascading deletes for related entities\n   - Handles potential conflicts in template creation/updates\n\n7. Scalability:\n   - Stateless API design allows for horizontal scaling\n\n8. Logging and Monitoring:\n   - While not explicitly implemented, the error handling structure allows for easy integration of logging\n\n9. Compliance and Data Privacy:\n   - The structure allows for implementing access controls and audit trails (not shown in this chunk)\n\nThese non-functional aspects contribute to the overall quality, reliability, and maintainability of the application."
    },
    {
      "chunk_id": "workflow_template_management",
      "summary": "This code implements a workflow template management system for governance templates. It provides CRUD operations for workflow templates, including creation, retrieval, updating, and deletion. The system manages the order of workflow templates within a governance template, automatically adjusting orders when templates are added, updated, or deleted. It also includes cascade deletion of associated checklist items when a workflow template is removed.",
      "data_model": "The code defines two main data models: WorkflowTemplate and ChecklistItemTemplate.\n\nWorkflowTemplate:\n- _id: ObjectId (unique identifier)\n- governanceTemplateId: ObjectId (reference to parent GovernanceTemplate)\n- name: string (required)\n- description: string (optional)\n- metadata: object (optional, for additional configuration)\n- order: number (integer, for manual ordering)\n- createdAt: Date\n- updatedAt: Date\n\nChecklistItemTemplate:\n- _id: ObjectId (unique identifier)\n- workflowTemplateId: ObjectId (reference to parent WorkflowTemplate)\n- name: string\n- description: string\n- type: string (e.g., 'approval')\n- dependencies_requires: array of ObjectId (references to other ChecklistItemTemplates)\n\nRelationships:\n- A GovernanceTemplate has many WorkflowTemplates\n- A WorkflowTemplate has many ChecklistItemTemplates\n- ChecklistItemTemplates can have dependencies on other ChecklistItemTemplates\n\n```mermaid\nerDiagram\n    GovernanceTemplate ||--o{ WorkflowTemplate : contains\n    WorkflowTemplate ||--o{ ChecklistItemTemplate : contains\n    ChecklistItemTemplate }o--o{ ChecklistItemTemplate : depends_on\n```\n\nData validation is performed using Joi schemas for input validation and MongoDB ObjectId validation.",
      "interfaces": "The code exposes the following RESTful API endpoints:\n\n1. POST /api/v1/workflow-templates\n   - Creates a new workflow template\n   - Request body: { governanceTemplateId, name, description, metadata }\n   - Response: Created workflow template object\n\n2. GET /api/v1/workflow-templates/{id}\n   - Retrieves a specific workflow template by ID\n   - Response: Workflow template object\n\n3. PUT /api/v1/workflow-templates/{id}\n   - Updates a workflow template\n   - Request body: { name, description, metadata, order }\n   - Response: Updated workflow template object\n\n4. DELETE /api/v1/workflow-templates/{id}\n   - Deletes a workflow template and its associated checklist items\n   - Response: 204 No Content\n\n5. GET /api/v1/workflow-templates\n   - Retrieves all workflow templates, optionally filtered by governanceTemplateId\n   - Query parameters: governanceTemplateId (optional)\n   - Response: Array of workflow template objects\n\nEach endpoint includes proper error handling and returns appropriate HTTP status codes and error messages.",
      "business_logic": "The core business logic includes:\n\n1. Workflow template management:\n   - Creation of workflow templates with automatic order assignment\n   - Retrieval of individual and all workflow templates\n   - Updating workflow templates, including order management\n   - Deletion of workflow templates with cascade deletion of associated checklist items\n\n2. Order management:\n   - Automatic assignment of order when creating new workflow templates\n   - Reordering of workflow templates when updating order\n   - Adjusting orders of remaining templates when a template is deleted\n\n3. Dependency management:\n   - Handling dependencies between checklist items\n   - Cascade deletion of checklist items when deleting a workflow template\n\n4. Validation:\n   - Ensuring unique names for workflow templates within a governance template\n   - Preventing duplicate order numbers for workflow templates\n   - Validating input data using Joi schemas\n\n5. Filtering and sorting:\n   - Ability to filter workflow templates by governanceTemplateId\n   - Sorting workflow templates by order when filtered by governanceTemplateId\n\nThe business logic is separated into controller functions, model creation functions, and validation schemas, following a clear separation of concerns.",
      "dependencies": "The code relies on the following external dependencies:\n\n1. @hapi/hapi: Web framework for building the API\n2. @hapi/boom: HTTP-friendly error objects\n3. mongodb: MongoDB driver for Node.js\n4. joi: Data validation library\n5. @playwright/test: Testing framework for end-to-end tests\n\nThe code interacts with a MongoDB database for data persistence, using the official MongoDB driver. It uses the ObjectId class from MongoDB for handling unique identifiers.\n\nThe API is built using the Hapi framework, with routes defined and handlers implemented using Hapi's plugin system.\n\nJoi is used extensively for input validation and schema definition throughout the codebase.\n\nThe testing suite uses Playwright for end-to-end API testing, simulating HTTP requests and validating responses.",
      "configuration": "The code includes configuration for:\n\n1. API routes: Defined in the plugin registration function, including path, method, handler, and validation options for each endpoint.\n\n2. Swagger documentation: Each route includes Swagger configuration for API documentation, specifying response schemas and examples.\n\n3. Database collection names: 'workflowTemplates', 'governanceTemplates', and 'checklistItemTemplates' are used throughout the code.\n\n4. Validation schemas: Defined using Joi for input validation on create and update operations.\n\n5. Custom Joi extension: For MongoDB ObjectId validation.\n\nEnvironment variables and secrets management are not explicitly shown in the provided code, but would likely be needed for database connection strings and any authentication mechanisms.",
      "infrastructure": "The code does not explicitly define infrastructure elements. However, based on the code structure and dependencies, the following can be inferred:\n\n1. The application is likely deployed as a Node.js service.\n2. It requires a MongoDB database for data persistence.\n3. The API could be hosted on a web server or serverless platform that supports Node.js.\n\nNo specific deployment configuration, containerization, or CI/CD pipeline setup is present in the provided code.",
      "non_functional": "1. Performance and reliability:\n   - The code uses MongoDB indexes for efficient querying (implied by the use of `findOne` and `find` operations).\n   - Batch operations are used for updating multiple documents, improving performance.\n\n2. Error handling:\n   - Comprehensive error handling is implemented using try-catch blocks and Boom for creating HTTP-friendly error responses.\n   - Specific error types (e.g., not found, conflict) are handled appropriately.\n\n3. Testing:\n   - Extensive end-to-end tests are implemented using Playwright.\n   - Tests cover CRUD operations, order management, cascade deletion, and edge cases.\n\n4. Data integrity:\n   - Input validation is performed using Joi schemas.\n   - Database operations are wrapped in try-catch blocks to handle potential errors.\n\n5. Security:\n   - Input validation helps prevent injection attacks.\n   - ObjectId validation is used to ensure valid identifiers.\n\n6. Logging and monitoring:\n   - No explicit logging or monitoring is implemented in the provided code.\n\n7. Scalability:\n   - The use of MongoDB allows for horizontal scaling of the database layer.\n   - The stateless nature of the API endpoints supports horizontal scaling of the application layer.\n\n8. Maintainability:\n   - The code is well-structured with clear separation of concerns (controllers, models, validation).\n   - Consistent naming conventions and code style are used throughout."
    },
    {
      "chunk_id": "checklist_item_template_management",
      "summary": "This code chunk implements a comprehensive management system for checklist item templates within workflow templates. It provides CRUD operations for checklist item templates, handles dependencies between templates, manages ordering of templates, and supports filtering based on workflow and governance templates. The system ensures data integrity by preventing duplicate orders and self-dependencies, and automatically resequences templates when changes occur.",
      "data_model": "The code defines a data model for checklist item templates with the following structure:\n\n```mermaid\nerDiagram\n    ChecklistItemTemplate {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        string name\n        string description\n        string type\n        ObjectId[] dependencies_requires\n        object metadata\n        number order\n        date createdAt\n        date updatedAt\n    }\n    WorkflowTemplate {\n        ObjectId _id\n        string name\n        ObjectId governanceTemplateId\n    }\n    GovernanceTemplate {\n        ObjectId _id\n        string name\n    }\n    ChecklistItemTemplate }o--|| WorkflowTemplate : belongs_to\n    WorkflowTemplate }o--|| GovernanceTemplate : belongs_to\n```\n\nFields:\n- _id: Unique identifier (ObjectId)\n- workflowTemplateId: Reference to parent WorkflowTemplate (ObjectId)\n- name: Display name of the checklist item (string)\n- description: Detailed description (string)\n- type: Type of checklist item (e.g., 'approval', 'document', 'task') (string)\n- dependencies_requires: Array of checklist item template IDs that this item depends on (ObjectId[])\n- metadata: Additional configuration (object)\n- order: Manual ordering position for the checklist item (number)\n- createdAt: Timestamp of creation (Date)\n- updatedAt: Timestamp of last update (Date)\n\nThe code implements data validation, integrity checks, and handles relationships between templates, including preventing self-dependencies and maintaining order consistency.",
      "interfaces": "The code defines the following API endpoints:\n\n1. POST /api/v1/checklist-item-templates\n   - Creates a new checklist item template\n   - Request body: workflowTemplateId, name, description, type, dependencies_requires, metadata\n   - Response: 201 Created with the created template data\n\n2. GET /api/v1/checklist-item-templates/{id}\n   - Retrieves a specific checklist item template by ID\n   - Response: 200 OK with the template data, including populated dependencies\n\n3. PUT /api/v1/checklist-item-templates/{id}\n   - Updates a checklist item template\n   - Request body: name, description, type, dependencies_requires, metadata, order\n   - Response: 200 OK with the updated template data\n\n4. DELETE /api/v1/checklist-item-templates/{id}\n   - Deletes a checklist item template\n   - Response: 204 No Content\n\n5. GET /api/v1/checklist-item-templates\n   - Retrieves all checklist item templates, with optional filtering by workflowTemplateId or governanceTemplateId\n   - Query parameters: workflowTemplateId, governanceTemplateId\n   - Response: 200 OK with an array of template data\n\nEach endpoint includes proper error handling and validation of input data.",
      "business_logic": "The business logic in this code chunk includes:\n\n1. Template Creation and Validation:\n   - Ensures the referenced workflowTemplate exists\n   - Automatically assigns the next available order number\n   - Prevents duplicate order numbers\n\n2. Dependency Management:\n   - Allows specifying dependencies between checklist item templates\n   - Prevents self-dependencies\n   - Updates dependent templates when a template is deleted\n\n3. Order Management:\n   - Maintains a consistent order of checklist items within a workflow\n   - Automatically resequences items when an item is deleted or its order is changed\n   - Ensures no duplicate order numbers exist\n\n4. Filtering and Retrieval:\n   - Supports filtering templates by workflowTemplateId or governanceTemplateId\n   - Returns templates in order when filtered\n\n5. Template Updates:\n   - Handles partial updates of template fields\n   - Manages order changes and their impact on other templates\n\n6. Template Deletion:\n   - Removes the template and updates the order of remaining templates\n   - Removes the deleted template from the dependencies of other templates\n\nThe business logic ensures data integrity, maintains consistent relationships between templates, and provides efficient filtering and ordering mechanisms.",
      "dependencies": "The code relies on the following dependencies:\n\n1. MongoDB: Used as the database for storing and querying checklist item templates, workflow templates, and governance templates.\n   - The `mongodb` package is used, specifically the `ObjectId` class for handling MongoDB document IDs.\n\n2. Hapi: The code is structured as a Hapi plugin, indicating that the Hapi framework is used for the API server.\n   - The `@hapi/hapi` package is used for defining routes and handling requests.\n\n3. Boom: Used for generating HTTP-friendly error objects.\n   - The `@hapi/boom` package is imported for creating standardized error responses.\n\n4. Joi: Used for request validation and response documentation.\n   - The `joi` package is used to define validation schemas for API inputs and outputs.\n\n5. hapi-swagger: While not directly imported, the code includes configuration for Swagger documentation, indicating this plugin is used for API documentation.\n\n6. Playwright: Used in the test file for end-to-end testing of the API endpoints.\n   - The `@playwright/test` package is used in the test file.\n\nThese dependencies are crucial for the functionality of the checklist item template management system, providing database access, API routing, validation, error handling, and testing capabilities.",
      "configuration": "The code does not explicitly define configuration files or environment variables. However, it assumes the existence of certain configuration:\n\n1. Database Connection: The code expects a MongoDB database connection to be available through `request.db`. This suggests that database configuration (connection string, credentials) is handled elsewhere in the application.\n\n2. Collections: The code uses specific collection names ('checklistItemTemplates', 'workflowTemplates') which should be consistent across the application.\n\n3. API Versioning: The API routes are prefixed with '/api/v1/', indicating a versioning strategy for the API.\n\n4. Swagger Documentation: The code includes configuration for Swagger documentation, suggesting that the hapi-swagger plugin is configured in the main server setup.\n\n5. Test Configuration: The test file likely relies on environment-specific configuration for connecting to a test database and setting up the test environment.\n\nWhile not explicitly defined in this chunk, proper configuration management for these aspects is crucial for the system's functionality and maintainability.",
      "infrastructure": null,
      "non_functional": "The code implements several non-functional aspects:\n\n1. Error Handling: Comprehensive error handling is implemented, with specific error messages for various scenarios (e.g., \"Workflow template not found\", \"Duplicate order number detected\").\n\n2. Data Integrity: The code ensures data integrity by preventing duplicate orders, self-dependencies, and maintaining consistent relationships between templates.\n\n3. Performance Considerations:\n   - Uses database indexing (implied by the use of `findOne` on `_id` fields)\n   - Implements efficient querying and updating of templates\n\n4. Security:\n   - Input validation is performed using Joi schemas\n   - MongoDB ObjectId validation is implemented to prevent injection attacks\n\n5. Testing:\n   - Comprehensive end-to-end tests are implemented using Playwright\n   - Tests cover various scenarios including CRUD operations, dependency management, and error cases\n\n6. API Documentation: The code includes Swagger documentation configuration, enhancing API usability and documentation.\n\n7. Scalability: The code is designed to handle multiple templates and complex relationships between them efficiently.\n\n8. Maintainability: The code is well-structured with clear separation of concerns between route definitions, controllers, and data models.\n\nThese non-functional aspects contribute to the overall quality, reliability, and maintainability of the checklist item template management system."
    },
    {
      "chunk_id": "project_management",
      "summary": "This code implements a project management system with CRUD operations for projects based on governance templates. It includes functionality for creating projects with associated workflow instances and checklist items, handling dependencies between checklist items, and managing project lifecycle. The system uses a MongoDB database for data persistence and exposes RESTful API endpoints for project operations.",
      "data_model": "```mermaid\nerDiagram\n    Project ||--o{ WorkflowInstance : has\n    Project ||--o{ ChecklistItemInstance : contains\n    Project }|--|| GovernanceTemplate : uses\n    WorkflowInstance }|--|| WorkflowTemplate : based_on\n    ChecklistItemInstance }|--|| ChecklistItemTemplate : based_on\n    WorkflowTemplate }|--|| GovernanceTemplate : belongs_to\n    ChecklistItemTemplate }|--|| WorkflowTemplate : belongs_to\n    ChecklistItemInstance ||--o{ ChecklistItemInstance : depends_on\n\n    Project {\n        ObjectId _id\n        String name\n        String description\n        ObjectId governanceTemplateId\n        ObjectId[] selectedWorkflowTemplateIds\n        Object metadata\n        Date createdAt\n        Date updatedAt\n    }\n\n    WorkflowInstance {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        String name\n        String description\n        Object metadata\n        Number order\n        String status\n        Date createdAt\n        Date updatedAt\n    }\n\n    ChecklistItemInstance {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        String name\n        String description\n        String type\n        String status\n        ObjectId[] dependencies_requires\n        Object metadata\n        Number order\n        Date createdAt\n        Date updatedAt\n    }\n```\n\nThe data model consists of the following main entities:\n\n1. Project: Represents a project with its basic information, associated governance template, and selected workflow templates.\n2. WorkflowInstance: Represents an instance of a workflow template associated with a project.\n3. ChecklistItemInstance: Represents an instance of a checklist item template associated with a workflow instance.\n4. GovernanceTemplate: Represents a governance template that projects are based on (referenced by Project).\n5. WorkflowTemplate: Represents a workflow template that workflow instances are based on (referenced by WorkflowInstance).\n6. ChecklistItemTemplate: Represents a checklist item template that checklist item instances are based on (referenced by ChecklistItemInstance).\n\nData validation and integrity checks are performed using Joi schemas for input validation and MongoDB ObjectId validation. The system ensures referential integrity by verifying the existence of referenced entities (e.g., governance templates and workflow templates) before creating projects.",
      "interfaces": "The code exposes the following RESTful API endpoints:\n\n1. POST /api/v1/projects\n   - Creates a new project\n   - Request body: JSON object with project details\n   - Response: 201 Created with project details\n\n2. GET /api/v1/projects/{id}\n   - Retrieves a project by ID\n   - Response: 200 OK with project details\n\n3. PUT /api/v1/projects/{id}\n   - Updates a project\n   - Request body: JSON object with updated project details\n   - Response: 200 OK with updated project details\n\n4. DELETE /api/v1/projects/{id}\n   - Deletes a project\n   - Response: 204 No Content\n\n5. GET /api/v1/projects\n   - Retrieves all projects\n   - Response: 200 OK with an array of project details\n\nAll endpoints use JSON for request and response bodies. The API is documented using Swagger/OpenAPI specifications through the hapi-swagger plugin.",
      "business_logic": "The core business logic includes:\n\n1. Project creation:\n   - Validates the existence of the specified governance template\n   - Verifies that all selected workflow templates exist and belong to the governance template\n   - Creates workflow instances for each selected workflow template\n   - Creates checklist item instances for each workflow instance\n   - Establishes dependencies between checklist items based on their templates\n\n2. Project retrieval, update, and deletion:\n   - Implements CRUD operations for projects\n   - Ensures data integrity and consistency when updating or deleting projects\n\n3. Workflow and checklist item management:\n   - Creates workflow instances and checklist item instances as part of project creation\n   - Manages dependencies between checklist items\n\n4. Data validation and integrity:\n   - Validates input data using Joi schemas\n   - Ensures referential integrity between projects, governance templates, and workflow templates\n\nThe business logic is primarily implemented in the controller functions (createProjectHandler, getProjectHandler, updateProjectHandler, deleteProjectHandler, getAllProjectsHandler) and the createProject function in the model.",
      "dependencies": "External dependencies include:\n\n1. @hapi/hapi: Web framework for building the API server\n2. @hapi/boom: HTTP-friendly error objects\n3. mongodb: MongoDB driver for Node.js\n4. joi: Data validation library\n5. @hapi/swagger: Swagger documentation generator for Hapi\n6. @playwright/test: Testing framework for end-to-end tests\n\nThe code interacts with a MongoDB database for data persistence, using the mongodb driver to perform CRUD operations on various collections (projects, governanceTemplates, workflowTemplates, workflowInstances, checklistItemTemplates, checklistItemInstances).",
      "configuration": "Configuration elements include:\n\n1. MongoDB connection: The code assumes a configured MongoDB connection is available through `request.db`\n2. API versioning: The API is versioned as v1 in the route paths\n3. Swagger documentation: The API is configured to use Swagger for documentation\n4. Logging: The code uses a custom logger for error logging and debugging\n\nEnvironment variables or configuration files for database connection strings, API keys, or other sensitive information are not directly visible in the provided code snippet but are likely managed elsewhere in the application.",
      "infrastructure": "The code does not directly include infrastructure-related elements. However, it is designed to work with:\n\n1. A MongoDB database for data persistence\n2. A web server capable of running Node.js and Hapi framework\n3. An environment that supports running Playwright for end-to-end testing\n\nDeployment, containerization, and CI/CD pipeline configurations are not present in the provided code snippet.",
      "non_functional": "Non-functional aspects include:\n\n1. Error handling: The code uses try-catch blocks and Boom for generating HTTP-friendly error responses\n2. Logging: Debug and error logging is implemented using a custom logger\n3. Input validation: Joi schemas are used for validating input data\n4. Testing: End-to-end tests are implemented using Playwright\n5. API documentation: Swagger is used for API documentation\n6. Performance considerations: The code uses MongoDB's native driver for efficient database operations\n7. Security: Input validation helps prevent injection attacks, but further security measures (e.g., authentication, authorization) are not visible in the provided snippet\n8. Data integrity: The code ensures referential integrity between related entities\n\nThe code demonstrates good practices in error handling, logging, and testing, but may benefit from additional security measures and performance optimizations depending on the specific requirements and deployment environment."
    },
    {
      "chunk_id": "workflow_instance_management",
      "summary": "This code chunk implements functionality for managing workflow instances within projects. It provides a RESTful API endpoint to retrieve workflow instances for a specific project, including sorting and grouping of associated checklist items. The code includes data models for workflow instances, API route definitions, request validation, and response formatting.",
      "data_model": "The code defines a data model for WorkflowInstance with the following fields:\n\n- _id: ObjectId (unique identifier)\n- projectId: ObjectId (reference to parent Project)\n- workflowTemplateId: ObjectId (reference to source WorkflowTemplate)\n- name: string (required)\n- description: string (optional)\n- metadata: object (optional)\n- order: number (optional, for manual ordering)\n- status: string ('active' or 'completed')\n- createdAt: Date\n- updatedAt: Date\n\nRelated collections:\n- projects\n- workflowInstances\n- checklistItemInstances\n\n```mermaid\nerDiagram\n    Project ||--o{ WorkflowInstance : has\n    WorkflowInstance ||--o{ ChecklistItemInstance : contains\n    WorkflowTemplate ||--o{ WorkflowInstance : instantiates\n\n    Project {\n        ObjectId _id\n    }\n    WorkflowInstance {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        string name\n        string description\n        object metadata\n        number order\n        string status\n        Date createdAt\n        Date updatedAt\n    }\n    ChecklistItemInstance {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        string status\n    }\n    WorkflowTemplate {\n        ObjectId _id\n    }\n```\n\nData validation is performed using Joi schemas for creating and updating workflow instances.",
      "interfaces": "The code defines a RESTful API endpoint:\n\nGET /api/v1/workflow-instances\n\nQuery Parameters:\n- projectId: string (required, MongoDB ObjectId of the project)\n\nResponse:\n- 200 OK: Array of WorkflowInstance objects\n- 400 Bad Request: Validation error\n- 404 Not Found: Project not found\n\nThe API is documented using Swagger via the hapi-swagger plugin.",
      "business_logic": "The business logic includes:\n\n1. Retrieving workflow instances for a specific project\n2. Sorting workflow instances based on:\n   a. Manual order field (if available)\n   b. Number of completed checklist items (more completed items first)\n   c. Total number of checklist items (more items first)\n3. Grouping checklist items by workflow\n4. Formatting workflow instance data for API response\n5. Validating project existence before retrieving workflow instances\n\nThe `compareWorkflowsByItems` function implements the custom sorting logic for workflows based on their checklist items.",
      "dependencies": "External dependencies:\n\n1. @hapi/boom: For creating HTTP-friendly error objects\n2. mongodb: For working with MongoDB, including ObjectId\n3. joi: For request validation and response schemas\n4. @hapi/hapi: The web framework used for the API (implied by the plugin structure)\n5. hapi-swagger: For API documentation (implied by the configuration)\n\nThe code interacts with MongoDB collections: 'projects', 'workflowInstances', and 'checklistItemInstances'.",
      "configuration": "Configuration elements include:\n\n1. API versioning: The endpoint is prefixed with '/api/v1/'\n2. Swagger documentation configuration for the API endpoint\n3. Joi schemas for request validation and response formatting\n4. MongoDB connection (implied, not explicitly shown in the provided code)\n\nNo explicit configuration files or environment variables are present in the given code.",
      "infrastructure": null,
      "non_functional": "Non-functional aspects include:\n\n1. Error handling: Use of Boom for creating HTTP-friendly error responses\n2. Input validation: Joi schemas for validating request parameters and payload\n3. API documentation: Swagger integration for clear API documentation\n4. Data integrity: Validation of project existence before processing requests\n5. Performance consideration: Efficient sorting and grouping of workflow instances and checklist items\n6. Code organization: Separation of concerns with controller, model, and validation in separate files\n\nThe code does not explicitly address logging, monitoring, or security beyond basic input validation."
    },
    {
      "chunk_id": "checklist_item_instance_management",
      "summary": "This code chunk implements functionality for managing checklist item instances within workflow instances. It provides APIs for updating checklist item statuses, retrieving checklist items for a workflow, and handling dependencies between items. The system supports different types of checklist items (approval, document, task) with specific metadata and validation rules. It also includes audit logging for status changes and implements a topological sorting mechanism for displaying items based on their dependencies and completion status.",
      "data_model": "The code defines a data model for ChecklistItemInstance with the following structure:\n\n```mermaid\nerDiagram\n    ChecklistItemInstance {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        String name\n        String description\n        String type\n        String status\n        ObjectId[] dependencies_requires\n        Object metadata\n        Number order\n        Date createdAt\n        Date updatedAt\n    }\n    WorkflowInstance {\n        ObjectId _id\n        Number order\n    }\n    ChecklistItemInstance }o--|| WorkflowInstance : belongs_to\n```\n\nFields:\n- _id: MongoDB ObjectId (unique identifier)\n- workflowInstanceId: Reference to parent WorkflowInstance (required)\n- checklistItemTemplateId: Reference to the template this instance is based on (required)\n- name: Display name of the checklist item (required)\n- description: Detailed description (optional)\n- type: Type of checklist item (e.g., 'approval', 'document', 'task') (required)\n- status: Current status (e.g., 'incomplete', 'complete', 'not_required') (required)\n- dependencies_requires: Array of checklist item instance IDs that this item depends on\n- metadata: Additional configuration based on checklist item type\n- order: Manual ordering position for the checklist item\n- createdAt: When the instance was created (required)\n- updatedAt: When the instance was last updated (required)\n\nThe code also interacts with WorkflowInstance and AuditLog collections, though their full structures are not explicitly defined in this chunk.",
      "interfaces": "The code defines the following API endpoints:\n\n1. GET /api/v1/checklist-item-instances\n   - Description: Get checklist item instances for a workflow instance\n   - Query Parameters:\n     - workflowInstanceId: MongoDB ObjectId of the workflow instance (required)\n   - Response: Array of ChecklistItemInstance objects\n\n2. PUT /api/v1/checklist-item-instances/{id}\n   - Description: Update a checklist item instance\n   - Path Parameters:\n     - id: MongoDB ObjectId of the checklist item instance\n   - Request Body: JSON object with fields to update (name, description, type, status, metadata)\n   - Response: Updated ChecklistItemInstance object\n\nBoth endpoints use Joi for request validation and define Swagger documentation for API consumers. The response schemas are defined using Joi and include detailed information about the ChecklistItemInstance structure.",
      "business_logic": "The business logic in this code chunk includes:\n\n1. Dependency validation: Before marking a checklist item as complete, the system checks if all its dependencies are complete.\n\n2. Status update rules: Different types of checklist items (approval, document, task) have specific rules for status updates and required metadata.\n\n3. Audit logging: Status changes are recorded in an audit log, including the old and new status, timestamp, and user who made the change.\n\n4. Workflow sorting: Workflows are sorted based on the completion status of their checklist items, with more completed items taking precedence.\n\n5. Topological sorting: Checklist items are sorted based on their dependencies and manual order field.\n\n6. Type-specific metadata validation:\n   - Approval items require an approver and set an approval date when completed.\n   - Document items require a document URL when marked as complete.\n   - Task items automatically set the completedBy and completedDate fields when marked as complete.\n\n7. Prevention of direct dependency updates: The system prevents users from directly updating the dependencies of a checklist item, as these are managed by the system.",
      "dependencies": "The code relies on the following external dependencies:\n\n1. MongoDB: Used for database operations (ObjectId, Collection)\n2. @hapi/boom: For generating HTTP-friendly error objects\n3. @hapi/hapi: Web framework for building the API (implied by the plugin structure)\n4. Joi: For request validation and response schemas\n5. hapi-swagger: For generating Swagger documentation (implied by the plugin options)\n\nInternal dependencies:\n1. Logger: A custom logging module (createLogger function)\n2. Authentication: The code assumes an authentication system is in place (request.auth.credentials)\n\nThe code interacts with several MongoDB collections:\n- checklistItemInstances\n- workflowInstances\n- auditLogs",
      "configuration": "The code doesn't explicitly define configuration files or environment variables. However, it implies the existence of a configured MongoDB connection accessible through `request.db`.\n\nThe Joi schemas in the route definitions serve as configuration for input validation and API documentation. They define the expected structure and constraints for API requests and responses.\n\nThe checklist item types ('approval', 'document', 'task') and statuses ('incomplete', 'complete', 'not_required') are hardcoded in the validation schemas, suggesting that these are fixed configurations in the system.",
      "infrastructure": "The code doesn't contain explicit infrastructure-related elements. However, it is designed as a Hapi plugin, which implies it's part of a larger Hapi-based API server infrastructure. The use of MongoDB suggests a database infrastructure requirement.\n\nThe code structure and use of modern JavaScript features (e.g., ES6 modules) indicate that it's likely running in a Node.js environment. The presence of Swagger documentation hints at an API-first approach, which could be part of a microservices architecture.",
      "non_functional": "1. Performance: The code implements caching of all workflow instances and checklist items to optimize sorting and comparison operations.\n\n2. Error Handling: The code uses try-catch blocks and Boom for generating HTTP-friendly error responses.\n\n3. Logging: A custom logger is used to record errors, particularly for audit log failures.\n\n4. Data Integrity: The code implements validation checks to ensure data consistency, especially for status updates and metadata fields.\n\n5. Security: The code assumes an authentication system is in place and uses it for identifying users in audit logs and task completion.\n\n6. Scalability: The topological sorting and workflow comparison algorithms may have performance implications for large numbers of checklist items or workflows.\n\n7. Maintainability: The code is modular and uses clear function names, improving readability and maintainability.\n\n8. API Documentation: The use of Swagger ensures that the API is well-documented for consumers.\n\n9. Data Privacy: The code handles user IDs, which could be considered sensitive information, particularly in audit logs.\n\n10. Testability: The modular structure and clear separation of concerns facilitate unit testing, although no tests are included in this chunk."
    },
    {
      "chunk_id": "api_routing",
      "summary": "This code chunk sets up a Hapi.js server for an AI SDLC Governance API. It defines the server configuration, registers various plugins for logging, tracing, security, and database connections, and sets up API routes for different modules such as projects, workflows, and checklist items. The code also configures Swagger documentation for the API endpoints and includes error handling for unhandled rejections.",
      "data_model": null,
      "interfaces": "# API Endpoints\n\nThe code sets up the following API endpoints:\n\n1. Health Check: `/health` (used by the platform to check if the service is running)\n2. API Documentation: `/docs`, `/docs/swagger`, `/docs/swagger.json`\n3. Base API path: `/api/v1`\n\n## API Modules:\n\n- Projects\n- Governance Templates\n- Workflow Templates\n- Checklist Item Templates\n- Workflow Instances\n- Checklist Item Instances\n- Example (for demonstration purposes)\n\nEach module likely has its own set of CRUD operations and specific endpoints, which are not detailed in the provided code.\n\n## Swagger Documentation\n\nThe API is documented using Swagger/OpenAPI specification. The documentation is accessible at:\n\n- `/docs`: Main documentation page\n- `/docs/swagger`: Swagger UI\n- `/docs/swagger.json`: Raw Swagger JSON\n\nThe API is grouped into the following tags:\n\n1. api: General API Endpoints\n2. project: Project instances created from governance templates\n3. governance-template: Top-level templates defining governance processes\n4. workflow-template: Templates defining workflow steps within a governance template\n5. checklist-item-template: Individual checklist items within workflow templates\n6. workflow-instance: Active workflow instances within projects\n7. checklist-item-instance: Active checklist items within workflow instances\n\n## Authentication\n\nThe API uses JWT authentication. The `Authorization` header is expected for authenticated requests.\n\n## Request/Response Format\n\nThe exact request/response formats are not provided in the code, but they are likely JSON-based and documented in the Swagger specification.",
      "business_logic": "The code primarily focuses on setting up the API infrastructure rather than implementing specific business logic. However, it does reveal the overall structure of the AI SDLC Governance system:\n\n1. Governance Templates: Top-level templates that define governance processes\n2. Workflow Templates: Templates that define workflow steps within a governance template\n3. Checklist Item Templates: Individual checklist items within workflow templates\n4. Projects: Instances created from governance templates\n5. Workflow Instances: Active workflow instances within projects\n6. Checklist Item Instances: Active checklist items within workflow instances\n\nThis structure suggests a hierarchical approach to AI SDLC governance, where:\n\n- Governance templates define overall processes\n- Workflows break down these processes into steps\n- Checklist items provide specific tasks or checks within workflows\n- Projects instantiate these templates\n- Workflow and checklist item instances represent the active state of a project's governance process\n\nThe business logic for creating, managing, and progressing through these governance structures is likely implemented in the individual route handlers for each module.",
      "dependencies": "The code relies on the following external dependencies:\n\n1. @hapi/hapi: The core framework for building the API server\n2. @hapi/inert: Static file and directory handling plugin for Hapi\n3. @hapi/vision: Template rendering plugin for Hapi\n4. hapi-swagger: Swagger documentation generator for Hapi\n5. path: Node.js built-in module for handling file paths\n6. fs: Node.js built-in module for file system operations\n7. url: Node.js built-in module for URL parsing\n\nInternal dependencies and custom modules:\n\n1. config: Custom configuration module\n2. router: Custom routing module\n3. requestLogger: Custom request logging plugin\n4. mongoDb: Custom MongoDB connection plugin\n5. failAction: Custom error handling function\n6. secureContext: Custom security context plugin\n7. pulse: Custom shutdown handler plugin\n8. requestTracing: Custom request tracing plugin\n9. setupProxy: Custom proxy setup function\n\nThe code also imports various route modules for different parts of the application (health, example, governance-templates, workflow-templates, etc.).\n\nDatabase:\n- MongoDB is used as the database, with a custom connection pool setup.\n\nVersion information:\n- The API version is read from the package.json file.",
      "configuration": "The code uses a configuration system with the following elements:\n\n1. Environment-based configuration:\n   - `config.get('port')`: Server port\n   - `config.get('root')`: Root directory for serving static files\n\n2. Server configuration:\n   - CORS: Not explicitly configured, likely handled elsewhere\n   - Security headers:\n     - HSTS (HTTP Strict Transport Security): maxAge 31536000, includeSubDomains true, preload false\n     - XSS Protection: enabled\n     - noSniff: true (X-Content-Type-Options)\n     - X-Frame-Options: true\n   - Route validation: abortEarly set to false\n   - Trailing slash handling: stripTrailingSlash set to true\n\n3. Swagger configuration:\n   - Title: \"AI SDLC Governance API Documentation\"\n   - Version: Read from package.json\n   - Security scheme: JWT (apiKey in Authorization header)\n   - Base path: \"/api/v1\"\n   - UI options: defaultModelsExpandDepth set to -1\n\n4. Plugin configuration:\n   - Various custom plugins are registered (requestLogger, requestTracing, secureContext, pulse, mongoDb)\n\n5. Package.json:\n   - Used to read the API version for documentation\n\n6. Environment variables:\n   - While not explicitly shown, the code likely uses environment variables for sensitive information like database credentials and API keys\n\n7. Logging configuration:\n   - A custom logger is created, but specific configuration is not shown in the provided code\n\nThe configuration seems to be centralized in a `config` module, which is imported and used throughout the application. This allows for easy management of configuration across different environments.",
      "infrastructure": "While the code doesn't directly define infrastructure as code, it provides insights into the application's infrastructure requirements:\n\n1. Server:\n   - Node.js runtime environment\n   - Hapi.js as the web framework\n\n2. Database:\n   - MongoDB (indicated by the mongoDb plugin)\n\n3. API Documentation:\n   - Swagger UI for interactive API documentation\n\n4. Logging and Monitoring:\n   - Custom request logging implementation\n   - Request tracing functionality (possibly for distributed tracing)\n\n5. Security:\n   - SSL/TLS support (implied by HSTS configuration)\n   - Secure context loading (possibly for managing SSL certificates)\n\n6. Proxy:\n   - A proxy setup function is called, indicating the application might be behind a reverse proxy\n\n7. Static File Serving:\n   - Capability to serve static files from a '.public' directory\n\n8. Error Handling:\n   - Global unhandled rejection handler for improved reliability\n\n9. Graceful Shutdown:\n   - The 'pulse' plugin likely handles graceful shutdown procedures\n\n10. Environment:\n    - The application seems designed to run in different environments (development, production, etc.) with appropriate configuration\n\nWhile not explicitly defined, this application would likely benefit from:\n- Containerization (e.g., Docker)\n- Orchestration (e.g., Kubernetes)\n- CI/CD pipeline for automated testing and deployment\n- Cloud hosting for scalability and reliability",
      "non_functional": "The code implements several non-functional aspects:\n\n1. Security:\n   - HSTS (HTTP Strict Transport Security) enabled\n   - XSS protection enabled\n   - Content-Type sniffing prevention\n   - X-Frame-Options header set\n   - JWT authentication for API endpoints\n   - Secure context loading (possibly for SSL/TLS certificates)\n\n2. Performance:\n   - MongoDB connection pooling for efficient database connections\n   - Trailing slash handling for consistent routing\n\n3. Reliability:\n   - Global unhandled rejection handler to prevent crashes\n   - Custom error handling for route validation failures\n\n4. Observability:\n   - Request logging for monitoring and debugging\n   - Request tracing for distributed systems observability\n\n5. Documentation:\n   - Swagger/OpenAPI documentation for API endpoints\n   - Detailed API grouping and tagging for better organization\n\n6. Maintainability:\n   - Modular code structure with separate files for different concerns\n   - Use of plugins for extending functionality\n   - Centralized configuration management\n\n7. Scalability:\n   - Use of async/await for non-blocking operations\n   - Database connection pooling\n\n8. Compliance:\n   - API versioning (v1) for backward compatibility\n   - Structured error responses (implied by custom failAction)\n\n9. Testing:\n   - While not explicitly shown, the structure supports easy integration of testing frameworks\n\n10. Graceful Shutdown:\n    - The 'pulse' plugin likely handles graceful shutdown procedures\n\n11. Flexibility:\n    - Environment-based configuration for easy deployment across different environments\n\nThese non-functional aspects contribute to a robust, secure, and maintainable API service. However, specific details on load testing, data privacy measures, and comprehensive error handling strategies are not provided in the given code snippet."
    },
    {
      "chunk_id": "database_management",
      "summary": "This code chunk implements a MongoDB database management system for an AI-driven software development lifecycle (SDLC) governance API. It includes functionality for connecting to MongoDB, setting up schema validations, creating indexes, and managing database operations. The code also provides utilities for dumping and restoring database states, as well as resetting schema validations. It's designed to work with various collections related to governance templates, projects, workflows, and checklist items.",
      "data_model": "The code defines several data models for the MongoDB collections:\n\n1. Governance Templates\n2. Projects\n3. Workflow Templates\n4. Workflow Instances\n5. Checklist Item Templates\n6. Checklist Item Instances\n\nHere's a Mermaid ERD diagram representing the relationships:\n\n```mermaid\nerDiagram\n    GOVERNANCE_TEMPLATE ||--o{ WORKFLOW_TEMPLATE : contains\n    GOVERNANCE_TEMPLATE ||--o{ PROJECT : uses\n    PROJECT ||--o{ WORKFLOW_INSTANCE : has\n    WORKFLOW_TEMPLATE ||--o{ WORKFLOW_INSTANCE : instantiates\n    WORKFLOW_TEMPLATE ||--o{ CHECKLIST_ITEM_TEMPLATE : contains\n    WORKFLOW_INSTANCE ||--o{ CHECKLIST_ITEM_INSTANCE : has\n    CHECKLIST_ITEM_TEMPLATE ||--o{ CHECKLIST_ITEM_INSTANCE : instantiates\n\n    GOVERNANCE_TEMPLATE {\n        ObjectId _id\n        string name\n        string version\n        string description\n        date createdAt\n        date updatedAt\n    }\n    PROJECT {\n        ObjectId _id\n        string name\n        string description\n        ObjectId governanceTemplateId\n        ObjectId[] selectedWorkflowTemplateIds\n        object metadata\n        date createdAt\n        date updatedAt\n    }\n    WORKFLOW_TEMPLATE {\n        ObjectId _id\n        ObjectId governanceTemplateId\n        string name\n        string description\n        object metadata\n        int order\n        date createdAt\n        date updatedAt\n    }\n    WORKFLOW_INSTANCE {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        string name\n        string description\n        object metadata\n        int order\n        string status\n        date createdAt\n        date updatedAt\n    }\n    CHECKLIST_ITEM_TEMPLATE {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        string name\n        string description\n        string type\n        ObjectId[] dependencies_requires\n        object metadata\n        int order\n        date createdAt\n        date updatedAt\n    }\n    CHECKLIST_ITEM_INSTANCE {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        string name\n        string description\n        string type\n        string status\n        ObjectId[] dependencies_requires\n        object metadata\n        int order\n        date createdAt\n        date updatedAt\n    }\n```\n\nEach model has fields for creation and update timestamps, as well as specific fields relevant to their function in the SDLC governance system. The code implements strict schema validations for each collection, ensuring data integrity and consistency. It also sets up indexes for efficient querying, particularly for fields used in relationships between collections.",
      "interfaces": "The code exposes several interfaces:\n\n1. MongoDB Plugin Interface:\n   - Decorates the Hapi server with `db`, `mongoClient`, and `locker` properties.\n   - Provides access to the MongoDB database, client, and lock manager.\n\n2. Command-line Interface (CLI):\n   - Implemented using yargs for managing MongoDB operations.\n   - Commands:\n     - `dump`: Dumps the current state of MongoDB to a JSON file.\n     - `restore`: Restores the database from a dump file.\n     - `deleteAll`: Deletes all data from all collections.\n     - `reset-schema`: Resets schema validations for all collections.\n\n3. Lock Management Interface:\n   - `acquireLock(locker, resource, logger)`: Attempts to acquire a lock on a resource.\n   - `requireLock(locker, resource)`: Acquires a lock on a resource or throws an error if unsuccessful.\n\n4. Database Management Interface:\n   - `MongoHandler` class with methods for connecting, closing, deleting all data, dumping, and restoring the database.\n\n5. Schema Validation Interface:\n   - `resetSchemaValidations()`: Resets and applies schema validations for all collections.",
      "business_logic": "The business logic in this code revolves around managing the data structures and operations for an AI-driven SDLC governance system:\n\n1. Governance Templates: Represent high-level governance structures that contain workflow templates.\n\n2. Projects: Associate with a governance template and select specific workflow templates to use.\n\n3. Workflow Templates: Define the structure of workflows within a governance template.\n\n4. Workflow Instances: Represent active workflows within a project, based on workflow templates.\n\n5. Checklist Item Templates: Define individual tasks or checks within a workflow template.\n\n6. Checklist Item Instances: Represent active checklist items within a workflow instance.\n\nThe code enforces relationships between these entities through schema validations and indexes. It also implements logic for:\n\n- Ensuring data integrity through strict schema validations\n- Managing dependencies between checklist items\n- Handling status transitions for workflows and checklist items\n- Maintaining metadata for various entities\n- Versioning of governance templates\n\nThe business logic is primarily implemented through the data model structure and the schema validations, ensuring that the SDLC governance system maintains consistent and valid data throughout its operations.",
      "dependencies": "The code has several external dependencies:\n\n1. MongoDB: Used as the primary database system.\n   - `mongodb` package for database operations\n   - `mongo-locks` package for distributed locking\n\n2. Hapi: Web framework used for the API (implied by the server decorations).\n   - `@hapi/hapi` package\n\n3. Configuration Management:\n   - Custom `config` module (likely using a configuration library like `dotenv` or `config`)\n\n4. File System Operations:\n   - Node.js `fs` module (promises version)\n\n5. Command-line Argument Parsing:\n   - `yargs` package for CLI argument handling\n\n6. Testing:\n   - Jest testing framework (implied by the test files)\n\n7. Logging:\n   - Custom logger (likely using a logging library like `pino` or `winston`)\n\n8. Other Node.js core modules:\n   - `path` for file path operations\n   - `url` for URL parsing\n\nThese dependencies are crucial for the functioning of the database management system, API server, and CLI tools. The code also implies the use of ES modules (`import` statements) and appears to be designed for a Node.js environment.",
      "configuration": "The code uses a configuration system, likely based on environment variables or configuration files:\n\n1. MongoDB Connection:\n   - `mongoUri`: MongoDB connection string\n   - `mongoDatabase`: Name of the database to use\n\n2. Database Options:\n   - `retryWrites`: Set to `false` in the example\n   - `readPreference`: Set to `'secondary'` in the example\n\n3. Server Configuration:\n   - Implied server configuration for Hapi (not directly visible in the provided code)\n\n4. Secure Context:\n   - Optional `secureContext` for MongoDB connection (if provided by the server)\n\n5. Configuration Retrieval:\n   - Uses a `config.get()` method to retrieve configuration values\n\n6. Environment-specific Configuration:\n   - Implied by the use of a configuration system, likely supporting different environments (development, testing, production)\n\n7. Secrets Management:\n   - MongoDB URI (which may contain credentials) is retrieved from the configuration system, suggesting a centralized secrets management approach\n\nThe configuration system allows for flexible deployment across different environments and provides a centralized way to manage database connection details and other settings. The exact implementation of the configuration system is not visible in the provided code, but it's likely using a library like `dotenv` or a custom configuration module.",
      "infrastructure": "While the code doesn't directly define infrastructure, it implies certain infrastructure requirements:\n\n1. MongoDB Database:\n   - Requires a running MongoDB instance\n   - Supports replica sets (indicated by `readPreference` option)\n\n2. Node.js Runtime:\n   - The code is written in JavaScript and uses ES modules, indicating a Node.js environment\n\n3. API Server:\n   - Uses Hapi framework, suggesting a RESTful API server\n\n4. Command-line Interface:\n   - Provides CLI tools for database management, implying server-side scripts\n\n5. Testing Environment:\n   - Presence of test files indicates a testing infrastructure, likely using Jest\n\n6. Deployment Considerations:\n   - The configuration system suggests support for multiple environments (development, testing, production)\n\n7. Potential for Containerization:\n   - The modular nature of the code and use of configuration management makes it suitable for containerization (e.g., Docker)\n\n8. Scalability:\n   - Use of MongoDB and support for replica sets indicates potential for horizontal scaling\n\n9. CI/CD Integration:\n   - The presence of tests and CLI tools for database management suggests potential integration with CI/CD pipelines\n\nWhile not explicitly defined in the code, these infrastructure elements are implied by the code structure and dependencies, suggesting a scalable, cloud-ready application architecture.",
      "non_functional": "The code addresses several non-functional aspects:\n\n1. Performance and Reliability:\n   - Uses MongoDB indexes for efficient querying\n   - Supports MongoDB replica sets for high availability\n   - Implements distributed locking for concurrent operations\n\n2. Security:\n   - Uses schema validations to prevent invalid data\n   - Supports secure MongoDB connections (implied by `secureContext`)\n   - Handles sensitive configuration data through a config system\n\n3. Data Integrity:\n   - Implements strict schema validations for all collections\n   - Uses transactions for data consistency (implied by `retryWrites` option)\n\n4. Scalability:\n   - Supports MongoDB replica sets for read scaling\n   - Uses efficient indexing for large datasets\n\n5. Maintainability:\n   - Modular code structure with separation of concerns\n   - Clear naming conventions and code organization\n\n6. Testability:\n   - Includes unit tests for critical functions\n   - Supports database state management for testing (dump/restore functionality)\n\n7. Observability:\n   - Implements logging for critical operations and errors\n\n8. Error Handling:\n   - Includes error handling for database operations and CLI commands\n\n9. Flexibility and Extensibility:\n   - Configurable system supporting multiple environments\n   - Modular design allowing for easy addition of new features or collections\n\n10. Compliance and Auditing:\n    - Maintains creation and update timestamps for all records\n    - Supports potential auditing through the data model (e.g., `auditLogs` collection)\n\nThese non-functional aspects contribute to a robust, scalable, and maintainable system, suitable for managing critical SDLC governance data in various deployment scenarios."
    },
    {
      "chunk_id": "logging_and_metrics",
      "summary": "This code chunk implements logging and metrics functionality for a Node.js application. It sets up a logging system using the Pino logger with configurable options, including ECS (Elastic Common Schema) formatting and development-specific settings. The chunk also includes a metrics counter function that uses AWS Embedded Metrics to track custom metrics. Unit tests are provided for the metrics functionality.",
      "data_model": null,
      "interfaces": null,
      "business_logic": null,
      "dependencies": "The code chunk has the following dependencies:\n\n1. External libraries:\n   - pino: Used for logging\n   - @elastic/ecs-pino-format: Provides ECS formatting for Pino logger\n   - @defra/hapi-tracing: Used to get trace IDs\n   - hapi-pino: Hapi plugin for Pino logger\n   - aws-embedded-metrics: Used for metrics logging\n\n2. Node.js built-in modules:\n   - node:fs/promises: For file system operations\n   - node:path: For path manipulations\n   - node:fs: For synchronous file operations\n\n3. Internal dependencies:\n   - ~/src/config/index.js: Configuration module\n   - ~/src/api/common/helpers/logging/logger-options.js: Logger options\n   - ~/src/api/common/helpers/logging/logger.js: Logger creation\n\n4. Testing dependencies:\n   - jest: Used for unit testing\n\nVersion compatibility considerations are not explicitly mentioned in the provided code.",
      "configuration": "The code chunk includes the following configuration elements:\n\n1. Logger configuration:\n   - Stored in the `config` object, accessed via `config.get('log')`\n   - Configurable options include:\n     - Enabled/disabled status\n     - Log level (defaulting to 'debug' in development mode)\n     - Log format (ECS or pino-pretty)\n     - Paths to ignore for logging\n     - Fields to redact from logs\n\n2. Service configuration:\n   - Service name: `config.get('serviceName')`\n   - Service version: `config.get('serviceVersion')`\n   - Development mode flag: `config.get('isDevelopment')`\n\n3. Metrics configuration:\n   - Metrics enabled/disabled flag: `config.get('isMetricsEnabled')`\n\n4. Environment-specific configuration:\n   - In development mode:\n     - Log level is set to 'debug' if not explicitly set\n     - Logs are written to both console and a file (`./logs/app.log`)\n\n5. Logger options:\n   - Defined in `loggerOptions` object\n   - Includes settings for enabled status, ignored paths, redaction, log level, formatting, and custom mixin for trace IDs\n\nThe configuration appears to be managed through a central `config` object, likely loaded from environment variables or configuration files, though the exact source is not shown in the provided code.",
      "infrastructure": null,
      "non_functional": "The code chunk addresses several non-functional aspects:\n\n1. Logging:\n   - Uses Pino logger for efficient logging\n   - Supports different log formats (ECS and pino-pretty)\n   - Configurable log levels and redaction for sensitive information\n   - Development mode has additional file logging\n   - Request logging through hapi-pino plugin\n\n2. Metrics:\n   - Uses AWS Embedded Metrics for custom metric tracking\n   - Supports counting metrics with configurable names and values\n\n3. Error handling:\n   - Metrics function includes try-catch block to handle and log errors\n\n4. Testing:\n   - Includes unit tests for the metrics functionality\n   - Uses Jest for testing framework\n   - Mocks external dependencies for isolated testing\n\n5. Tracing:\n   - Incorporates trace IDs in logs for distributed tracing\n\n6. Performance:\n   - Uses efficient logging library (Pino)\n   - Metrics are only recorded when enabled, reducing overhead\n\n7. Environment-specific behavior:\n   - Different logging configurations for development and production environments\n\n8. Security:\n   - Supports redaction of sensitive information in logs\n\nThis code demonstrates attention to observability, error handling, and environment-specific configurations, which are important for maintaining and troubleshooting the application in different environments."
    },
    {
      "chunk_id": "server_health_and_security",
      "summary": "This code chunk implements server health checks and security features for a Node.js application using the Hapi framework. It includes a health check endpoint, secure context configuration for TLS connections, and helper functions to manage trust store certificates. The code also contains unit tests for these features, ensuring reliability and correct functionality.",
      "data_model": null,
      "interfaces": "# API Endpoints\n\n1. Health Check Endpoint\n   - **Method**: GET\n   - **Path**: `/health`\n   - **Response Format**:\n     ```json\n     {\n       \"message\": \"success\"\n     }\n     ```\n   - **Status Code**: 200 OK\n\n# Plugin Interfaces\n\n1. Health Plugin\n   - Registers the health check endpoint\n\n2. Secure Context Plugin\n   - Decorates the server with a custom `secureContext` when enabled\n   - Modifies the `tls.createSecureContext` function to include trust store certificates",
      "business_logic": null,
      "dependencies": "# External Dependencies\n\n1. @hapi/hapi\n   - Core framework for building the server\n\n2. hapi-pino\n   - Logging plugin for Hapi (mocked in tests)\n\n# Node.js Core Modules\n\n1. node:tls\n   - Used for creating and modifying secure contexts\n\n# Internal Dependencies\n\n1. ~/src/api/common/constants/status-codes.js\n   - Provides HTTP status codes\n\n2. ~/src/config/index.js\n   - Application configuration\n\n3. ~/src/api/common/helpers/logging/request-logger.js\n   - Request logging functionality\n\n# Testing Dependencies\n\n1. Jest\n   - Testing framework used for unit tests",
      "configuration": "# Configuration\n\n1. Environment Variables\n   - `TRUSTSTORE_*`: Base64 encoded certificates for the trust store\n     - Multiple certificates can be added using different suffixes (e.g., TRUSTSTORE_CA_ONE, TRUSTSTORE_CA_TWO)\n\n2. Application Configuration\n   - `isSecureContextEnabled`: Boolean flag to enable/disable custom secure context\n     - Accessed via `config.get('isSecureContextEnabled')`\n\n# Secrets Management\n\n- Trust store certificates are stored as base64 encoded strings in environment variables\n- The application decodes these certificates at runtime",
      "infrastructure": null,
      "non_functional": "# Security\n\n1. TLS Configuration\n   - Custom secure context implementation for TLS connections\n   - Dynamic loading of trust store certificates from environment variables\n\n2. Certificate Management\n   - Support for multiple CA certificates in the trust store\n   - Base64 encoding of certificates in environment variables\n\n# Testing\n\n1. Unit Tests\n   - Comprehensive test coverage for health check endpoint\n   - Tests for secure context plugin with different configurations\n   - Tests for trust store certificate loading\n\n2. Test Setup\n   - Use of `jest.mock()` for mocking dependencies\n   - Server initialization and cleanup in test lifecycle hooks\n\n# Logging\n\n- Use of `server.logger` for logging information and errors\n- Logging of secure context status and certificate availability\n\n# Error Handling\n\n- Graceful handling of missing trust store certificates\n\n# Performance\n\n- Caching of created secure context to avoid repeated certificate processing\n\n# Modularity and Extensibility\n\n- Plugin-based architecture for easy extension and modification of server functionality\n- Separation of concerns between health checks and security features"
    },
    {
      "chunk_id": "server_utilities",
      "summary": "This code chunk contains various server utilities and helpers for a Node.js application using the Hapi framework. It includes functions for error handling, server startup, request tracing, graceful shutdown, and HTTP proxy setup. The code also includes unit tests for these utilities, demonstrating a focus on code quality and testability.",
      "data_model": null,
      "interfaces": null,
      "business_logic": null,
      "dependencies": "- @hapi/hapi: Web framework for building server-side applications\n- hapi-pulse: Plugin for handling graceful server shutdown\n- @defra/hapi-tracing: Plugin for request tracing\n- undici: HTTP/1.1 client, used for proxy setup\n- global-agent: Global HTTP/HTTPS proxy configuration\n- jest: Testing framework for unit tests\n- hapi-pino: Logging plugin for Hapi\n\nThese dependencies are used throughout the utility functions and tests to provide core functionality, logging, tracing, and testing capabilities.",
      "configuration": "The code uses a configuration module imported from '~/src/config/index.js'. It includes:\n\n1. Port configuration:\n   - Used in server startup to determine the port number\n\n2. Tracing configuration:\n   - `tracing.header`: Configures the header used for request tracing\n\n3. HTTP Proxy configuration:\n   - `httpProxy`: Configures the URL for the HTTP proxy\n\nThe configuration is accessed using a `config.get()` method, suggesting a centralized configuration management approach. Environment variables are also used, particularly for setting the port in the test environment.",
      "infrastructure": null,
      "non_functional": "1. Error Handling:\n   - The `failAction` function logs warnings for errors and rethrows them, ensuring proper error propagation.\n\n2. Logging:\n   - Uses a custom logger created with `createLogger()` function.\n   - Hapi-pino is used for server logging, providing structured logs.\n\n3. Graceful Shutdown:\n   - The `pulse` plugin (hapi-pulse) is used to handle graceful server shutdown with a 10-second timeout.\n\n4. Request Tracing:\n   - Implements request tracing using the @defra/hapi-tracing plugin, enhancing observability.\n\n5. Testing:\n   - Extensive unit tests are provided for the utility functions, including mocking of dependencies and edge case testing.\n   - Jest is used as the testing framework.\n\n6. Security:\n   - HTTP proxy setup is available, which can be used to enhance security by routing traffic through a controlled proxy.\n\n7. Performance:\n   - The proxy setup uses the high-performance undici HTTP client.\n\n8. Modularity:\n   - The code is well-organized into separate files for different functionalities, promoting maintainability.\n\nThese non-functional aspects demonstrate a focus on reliability, observability, security, and code quality in the server utilities."
    },
    {
      "chunk_id": "migrations",
      "summary": "This code chunk implements a database migration system for a MongoDB-based application. It includes a main migration runner that checks for and executes pending migrations, as well as two specific migration scripts. The first migration adds an 'order' field to checklist item templates and instances, while the second adds an 'order' field to workflow templates and instances. These migrations ensure data consistency and support ordered relationships within the application's data model.",
      "data_model": "The code implies the following data model:\n\n```mermaid\nerDiagram\n    GovernanceTemplate ||--o{ WorkflowTemplate : contains\n    WorkflowTemplate ||--o{ ChecklistItemTemplate : contains\n    Project ||--o{ WorkflowInstance : contains\n    WorkflowInstance ||--o{ ChecklistItemInstance : contains\n    WorkflowTemplate ||--o{ WorkflowInstance : instantiates\n    ChecklistItemTemplate ||--o{ ChecklistItemInstance : instantiates\n\n    GovernanceTemplate {\n        ObjectId _id\n    }\n    WorkflowTemplate {\n        ObjectId _id\n        ObjectId governanceTemplateId\n        String name\n        Int order\n    }\n    ChecklistItemTemplate {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        String name\n        Int order\n    }\n    Project {\n        ObjectId _id\n    }\n    WorkflowInstance {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        String name\n        Int order\n    }\n    ChecklistItemInstance {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        String name\n        Int order\n    }\n    Migration {\n        String name\n        Date completedAt\n    }\n```\n\nEntities and their fields:\n1. GovernanceTemplate: Contains multiple WorkflowTemplates\n2. WorkflowTemplate: Contains ChecklistItemTemplates, has name and order\n3. ChecklistItemTemplate: Has name and order, belongs to a WorkflowTemplate\n4. Project: Contains WorkflowInstances\n5. WorkflowInstance: Contains ChecklistItemInstances, has name and order, associated with a Project and a WorkflowTemplate\n6. ChecklistItemInstance: Has name and order, belongs to a WorkflowInstance and associated with a ChecklistItemTemplate\n7. Migration: Tracks completed migrations with name and completedAt date\n\nThe migrations add 'order' fields to WorkflowTemplates, WorkflowInstances, ChecklistItemTemplates, and ChecklistItemInstances to establish a specific sequence within their respective parent entities.",
      "interfaces": null,
      "business_logic": "The business logic in this code chunk revolves around maintaining data consistency and introducing ordered relationships in the application's workflow and checklist system. Key aspects include:\n\n1. Migration system:\n   - Checks for pending migrations by comparing completed migrations with available migration files.\n   - Executes pending migrations in sequence.\n   - Records successful migrations in the database.\n\n2. Checklist item ordering:\n   - Adds an 'order' field to checklist item templates, initially based on their names.\n   - Updates checklist item instances with the order from their corresponding templates.\n   - Ensures consistent ordering of checklist items within workflows.\n\n3. Workflow ordering:\n   - Adds an 'order' field to workflow templates, initially based on their names.\n   - Updates workflow instances with the order from their corresponding templates.\n   - Ensures consistent ordering of workflows within governance templates and projects.\n\n4. Hierarchical structure:\n   - Maintains relationships between governance templates, workflow templates, checklist item templates, projects, workflow instances, and checklist item instances.\n   - Ensures that changes in template ordering are reflected in their respective instances.\n\nThis business logic supports a structured approach to managing workflows and checklists, allowing for ordered presentation and processing of these elements within the application.",
      "dependencies": "The code chunk has the following dependencies:\n\n1. MongoDB: The application uses MongoDB as its database. This is evident from the use of the `mongodb` driver and operations like `db.collection()`, `find()`, `updateOne()`, etc.\n\n2. Node.js built-in modules:\n   - `fs/promises`: For file system operations, used to read migration files.\n   - `path`: For working with file and directory paths.\n   - `url`: Specifically the `fileURLToPath` function, used for working with file URLs.\n\n3. ES Modules: The code uses ES Module syntax (`import` and `export`), indicating it's running in an environment that supports ES Modules.\n\n4. Logger: The code expects a logger object to be passed to functions, suggesting a logging library or custom logging solution is used in the broader application.\n\n5. External migration files: The migration runner dynamically imports migration scripts from a specified directory, indicating a dependency on these external files.\n\nVersion compatibility considerations:\n- The code uses modern JavaScript features like async/await, suggesting it requires a relatively recent version of Node.js.\n- The use of ES Modules indicates that the project is using Node.js version 12 or later, with ES Modules enabled.\n- The MongoDB driver version should be compatible with the used MongoDB operations and the version of MongoDB being used.",
      "configuration": "The code includes some configuration elements:\n\n1. Migration directory path:\n   ```javascript\n   const MIGRATIONS_DIR = path.resolve(\n     __dirname,\n     '../../../../../scripts/migrations'\n   )\n   ```\n   This sets the location of migration scripts relative to the current file.\n\n2. Database connection:\n   The code expects a MongoDB database instance to be passed to the `runMigrations` function, suggesting that database connection configuration is handled elsewhere in the application.\n\n3. Logger:\n   A logger instance is passed to various functions, indicating that logging configuration is managed externally.\n\n4. Migration naming convention:\n   Migration files are expected to have a `.js` extension and be named in a way that allows for alphabetical sorting to determine execution order.\n\n5. Collection names:\n   The code uses hardcoded collection names like 'migrations', 'workflowTemplates', 'checklistItemTemplates', etc. These could potentially be configurable in a more flexible setup.\n\nWhile some configuration elements are present, the code doesn't show explicit use of configuration files or environment variables. Sensitive data handling is not directly addressed in this code chunk, suggesting it's managed elsewhere in the application.",
      "infrastructure": null,
      "non_functional": "The code chunk addresses several non-functional aspects:\n\n1. Performance and reliability:\n   - Migrations are run sequentially to ensure data consistency.\n   - The system checks for already completed migrations to avoid redundant operations.\n   - Large-scale data updates are performed using database-level operations, which can be more efficient than application-level loops for large datasets.\n\n2. Error handling:\n   - The migration runner catches and logs errors during individual migrations.\n   - If a migration fails, the error is thrown, likely to halt the process and prevent partial migration states.\n\n3. Logging:\n   - Extensive logging is implemented throughout the migration process, providing visibility into the migration status and progress.\n   - Each step of the migration process is logged, including start, completion, and any errors encountered.\n\n4. Data integrity:\n   - The migration system ensures that each migration is run only once by tracking completed migrations.\n   - Ordering is maintained for both templates and instances, ensuring data consistency across the system.\n\n5. Scalability considerations:\n   - The code uses MongoDB's native methods for querying and updating, which can handle large datasets efficiently.\n   - However, for very large datasets, the in-memory sorting and processing of all items could potentially cause performance issues.\n\n6. Maintainability:\n   - The migration system is designed to be extensible, allowing new migrations to be added easily as separate files.\n   - The code is modular and follows clear separation of concerns, improving maintainability.\n\n7. Testing considerations:\n   - While no explicit testing code is present, the modular nature of the migrations would allow for unit testing of individual migration scripts.\n   - The main migration runner could be integration tested with a test database.\n\n8. Security:\n   - No direct security measures are implemented in this code. Database access control and other security measures would need to be handled at the application and database configuration level.\n\nThese non-functional aspects contribute to the overall reliability, maintainability, and scalability of the migration system, though there's room for improvement in areas like security and handling of very large datasets."
    },
    {
      "chunk_id": "configuration",
      "summary": "This code chunk contains configuration files and setup for a Node.js backend application. It includes environment configuration, Docker setup, database connections, and development tools. The application uses MongoDB, Redis, and AWS services (via LocalStack for local development). It's designed with a focus on configurability, containerization, and follows modern Node.js development practices.",
      "data_model": null,
      "interfaces": null,
      "business_logic": null,
      "dependencies": "The application has the following key dependencies:\n\n1. Node.js (>=22)\n2. MongoDB (v6.0.13)\n3. Redis (v7.2.3)\n4. LocalStack (v3.0.2) for AWS service emulation\n5. Key npm packages:\n   - @hapi/hapi: Web framework\n   - convict: Configuration management\n   - pino: Logging\n   - mongodb: MongoDB driver\n   - @babel/core and related packages: For transpilation\n   - jest: Testing framework\n   - eslint and prettier: Code linting and formatting\n   - typescript: Type checking\n   - playwright: End-to-end testing\n\nDevelopment tools:\n- nodemon: For auto-restarting during development\n- husky: For git hooks\n- various linting and formatting tools\n\nThe package.json file lists all npm dependencies with their versions, split into production and development dependencies.",
      "configuration": "The configuration setup includes:\n\n1. Environment-based configuration (src/config/index.js):\n   - Uses 'convict' for schema-based configuration\n   - Configures service version, environment, port, service name, logging, MongoDB connection, HTTP proxy, and more\n   - Supports production, development, and test environments\n   - Uses environment variables for configuration\n\n2. Docker configuration (compose.yml):\n   - Sets up services for LocalStack (AWS emulation), Redis, MongoDB, and the backend application\n   - Defines network setup and volume management\n\n3. Dockerfile:\n   - Multi-stage build for development and production\n   - Uses defradigital/node-development and defradigital/node base images\n   - Installs dependencies, builds the application, and sets up the production environment\n\n4. AWS configuration (compose/aws.env):\n   - Sets AWS region and credentials for local development\n\n5. Node.js configuration:\n   - nodemon.json for development auto-reloading\n   - package.json for npm scripts, dependencies, and project metadata\n   - tsconfig.json and tsconfig.test.json for TypeScript configuration\n\n6. Environment variables:\n   - Various environment variables are used throughout the configuration files for flexibility and security\n\nThe configuration emphasizes environment-specific settings, containerization, and development tooling setup.",
      "infrastructure": "The infrastructure setup includes:\n\n1. Docker containerization:\n   - Dockerfile for building the application container\n   - compose.yml for defining and orchestrating multiple services:\n     - LocalStack for AWS service emulation\n     - Redis for caching\n     - MongoDB for database\n     - Backend application container\n\n2. Local development environment:\n   - LocalStack for emulating AWS services (S3, SQS, SNS, Firehose)\n   - Redis and MongoDB containers for local data storage and caching\n\n3. Networking:\n   - Custom bridge network 'cdp-tenant' for container communication\n\n4. Volume management:\n   - Persistent volume for MongoDB data\n\n5. Health checks:\n   - Defined for LocalStack service\n\n6. Port mappings:\n   - Exposed ports for each service (e.g., 4566 for LocalStack, 6379 for Redis, 27017 for MongoDB, 3555 for the backend)\n\n7. Environment configuration:\n   - AWS credentials and region settings for local development\n   - Application-specific environment variables\n\n8. Build and runtime configuration:\n   - Multi-stage Dockerfile for optimized production builds\n   - Development-specific configurations for hot-reloading and debugging\n\nThis setup allows for consistent development, testing, and production environments, with a focus on containerization and local emulation of cloud services.",
      "non_functional": "Non-functional aspects of the configuration include:\n\n1. Security:\n   - Environment-based configuration for sensitive data\n   - Secure context enablement for production\n   - Redaction of sensitive log data in production\n\n2. Logging and Monitoring:\n   - Configurable logging levels and formats\n   - ECS (Elastic Common Schema) log format for production\n   - Metrics reporting configuration\n\n3. Performance:\n   - Redis integration for potential caching\n   - MongoDB for data persistence\n\n4. Scalability:\n   - Containerized architecture supporting potential orchestration\n\n5. Development Experience:\n   - Hot reloading with nodemon\n   - Linting and formatting with ESLint and Prettier\n   - Git hooks with Husky for pre-commit checks\n\n6. Testing:\n   - Jest for unit testing\n   - Playwright for end-to-end and API testing\n   - Test coverage reporting\n\n7. Build and Deployment:\n   - Multi-stage Docker builds for optimized images\n   - npm scripts for various build and run scenarios\n\n8. Compliance and Standards:\n   - TypeScript for type safety\n   - Strict linting rules\n\n9. Error Handling and Debugging:\n   - Debug port exposed in development container\n   - Configurable log levels\n\n10. Compatibility:\n    - Node.js version specification (>=22)\n    - Dependency version management in package.json\n\nThese non-functional aspects contribute to the overall quality, maintainability, and operability of the application."
    },
    {
      "chunk_id": "testing_setup",
      "summary": "This code chunk contains configuration files for various testing and development tools. It includes Babel configuration for JavaScript transpilation, Jest configuration for unit testing, Jest MongoDB configuration for database testing, and Playwright configuration for end-to-end API testing. These files set up the testing environment, define test execution parameters, and configure code transformation and module resolution for the project.",
      "data_model": null,
      "interfaces": null,
      "business_logic": null,
      "dependencies": "The code chunk reveals several key dependencies:\n\n1. Babel:\n   - @babel/preset-env\n   - babel-plugin-module-resolver\n   - babel-plugin-transform-import-meta\n\n2. Jest:\n   - @shelf/jest-mongodb\n   - github-actions reporter\n\n3. Playwright:\n   - @playwright/test\n\n4. MongoDB:\n   - MongoDB Memory Server (version 4.0.3)\n\n5. Node.js:\n   - The code uses Node.js environment variables and modules\n\n6. Other:\n   - ESM (ECMAScript Modules) support is configured\n   - node-fetch is mentioned as an ESM-only dependency\n   - @defra/hapi-tracing is mentioned as an ESM-only dependency\n\nVersion compatibility considerations:\n- Babel is configured to handle different environments (test vs. production)\n- Jest is set up to work with MongoDB Memory Server version 4.0.3\n- The project seems to use a mix of CommonJS (.cjs files) and ES Modules (.js files with import/export)",
      "configuration": "The code chunk contains several configuration files:\n\n1. babel.config.cjs:\n   - Configures Babel for JavaScript transpilation\n   - Sets up presets: @babel/preset-env\n   - Configures module resolution and aliasing\n   - Adds special configuration for the test environment\n\n2. jest-mongodb-config.cjs:\n   - Configures MongoDB Memory Server for testing\n   - Sets MongoDB version to 4.0.3\n   - Configures database name and replica set\n\n3. jest.config.js:\n   - Configures Jest for unit testing\n   - Sets up test matching, coverage reporting, and transforms\n   - Configures reporters, including github-actions\n   - Sets up file watching and ignore patterns\n\n4. playwright.config.js:\n   - Configures Playwright for end-to-end API testing\n   - Sets timeout values, base URL, and HTTP headers\n   - Defines test projects and matching patterns\n\nEnvironment variables:\n- NODE_ENV: Used in Babel config to determine module handling\n- BASE_URL: Used in Playwright config for the base URL of the API\n\nThe configurations handle different environments (test, production) and set up aliases and module resolution to support the project structure.",
      "infrastructure": null,
      "non_functional": "The configuration files in this code chunk address several non-functional aspects:\n\n1. Testing strategies:\n   - Unit testing with Jest\n   - API testing with Playwright\n   - Database testing with Jest MongoDB\n\n2. Code coverage:\n   - Jest is configured to collect coverage from src/**/*.js\n   - Coverage reports are generated in the coverage directory\n\n3. Performance considerations:\n   - Timeouts are set for Playwright tests (30s for tests, 5s for expectations)\n\n4. Reliability:\n   - Use of in-memory MongoDB for testing ensures consistent test environment\n\n5. Error handling:\n   - Jest is configured with verbose output and custom reporters\n\n6. Logging and monitoring:\n   - Jest is set up with multiple reporters, including 'github-actions' and 'summary'\n\n7. Security considerations:\n   - MongoDB Memory Server is configured to skip MD5 (potentially for performance reasons, but this could have security implications)\n\n8. Compliance and compatibility:\n   - Babel is configured to handle different JavaScript module systems\n   - Specific handling for ESM-only dependencies\n\n9. Testing environment setup:\n   - Custom setup files for Jest (.jest/setup.js and .jest/setup-after-env.js)\n\n10. Continuous Integration:\n    - GitHub Actions reporter suggests integration with CI/CD pipelines\n\nThese configurations contribute to the overall quality, reliability, and maintainability of the codebase by ensuring comprehensive testing, consistent environments, and integration with development workflows."
    },
    {
      "chunk_id": "documentation",
      "summary": "This code chunk contains project documentation for an AI SDLC Governance API. It includes a comprehensive README file detailing setup instructions, development guidelines, API endpoints, and Docker usage. The documentation also covers features for checklist item ordering and workflow ordering, explaining their implementation, API usage, and migration strategies. The project appears to be a Node.js backend template for a core delivery platform with governance and workflow management capabilities.",
      "data_model": "The documentation implies the existence of several data models, though not explicitly defined:\n\n1. Checklist Item Template\n2. Checklist Item Instance\n3. Workflow Template\n4. Workflow Instance\n5. Project\n6. Governance Template\n\n```mermaid\nerDiagram\n    GOVERNANCE_TEMPLATE ||--o{ WORKFLOW_TEMPLATE : contains\n    WORKFLOW_TEMPLATE ||--o{ CHECKLIST_ITEM_TEMPLATE : contains\n    PROJECT ||--o{ WORKFLOW_INSTANCE : contains\n    WORKFLOW_INSTANCE ||--o{ CHECKLIST_ITEM_INSTANCE : contains\n    WORKFLOW_TEMPLATE ||--|| WORKFLOW_INSTANCE : instantiates\n    CHECKLIST_ITEM_TEMPLATE ||--|| CHECKLIST_ITEM_INSTANCE : instantiates\n\n    GOVERNANCE_TEMPLATE {\n        string id\n        string name\n        string description\n    }\n    WORKFLOW_TEMPLATE {\n        string id\n        string governanceTemplateId\n        string name\n        string description\n        json metadata\n        int order\n        datetime createdAt\n        datetime updatedAt\n    }\n    CHECKLIST_ITEM_TEMPLATE {\n        string id\n        string workflowTemplateId\n        string name\n        string description\n        string type\n        array dependencies_requires\n        json metadata\n        int order\n        datetime createdAt\n        datetime updatedAt\n    }\n    PROJECT {\n        string id\n        string name\n    }\n    WORKFLOW_INSTANCE {\n        string id\n        string projectId\n        string workflowTemplateId\n        string name\n        string description\n        json metadata\n        int order\n        string status\n        datetime createdAt\n        datetime updatedAt\n    }\n    CHECKLIST_ITEM_INSTANCE {\n        string id\n        string workflowInstanceId\n        string checklistItemTemplateId\n        string name\n        string description\n        string type\n        string status\n        array dependencies_requires\n        json metadata\n        int order\n        datetime createdAt\n        datetime updatedAt\n    }\n```\n\nEach model includes fields for identification, relationships, metadata, and timestamps. The 'order' field is used for custom sorting in both templates and instances. Data integrity is maintained by copying order values from templates to instances during project creation.",
      "interfaces": "The documentation describes several interfaces:\n\n1. API Endpoints:\n   - `GET: /health`: Health check endpoint\n   - `GET: /example`: Example API endpoint\n   - `GET: /example/<id>`: Example API endpoint with ID parameter\n\n2. Checklist Item Template API:\n   - `POST /api/v1/checklist-item-templates`: Create a new checklist item template\n   - `PATCH /api/v1/checklist-item-templates/<id>`: Update an existing checklist item template\n   - `DELETE /api/v1/checklist-item-templates/<id>`: Delete a checklist item template\n   - `GET /api/v1/checklist-item-templates?workflowTemplateId=<id>`: Retrieve checklist item templates for a workflow template\n\n3. Workflow Template API (implied):\n   - Similar CRUD operations for workflow templates\n\n4. Project API (implied):\n   - Endpoints for creating and managing projects\n\n5. Docker interfaces:\n   - Development image: Port 3001\n   - Production image: Port 3001\n\n6. npm scripts interface for various development tasks\n\n7. MongoDB interface for data persistence and locking mechanism\n\n8. Proxy interface for making HTTP requests",
      "business_logic": "The business logic described in the documentation includes:\n\n1. Checklist Item Ordering:\n   - Automatic calculation of the 'order' field when creating new checklist item templates\n   - Copying 'order' values from templates to instances during project creation\n   - Reordering remaining items when a checklist item template is deleted\n   - Sorting checklist items by 'order' when retrieving them\n\n2. Workflow Ordering:\n   - Similar ordering logic applied to workflow templates and instances\n   - Automatic calculation of the 'order' field for new workflow templates\n   - Copying 'order' values from templates to instances during project creation\n   - Reordering remaining workflows when a workflow template is deleted\n   - Sorting workflows by 'order' when retrieving them\n\n3. Project Creation:\n   - Instantiation of workflow instances from workflow templates\n   - Instantiation of checklist item instances from checklist item templates\n\n4. Governance Template:\n   - Hierarchical structure of governance templates containing workflow templates\n\n5. Approval Process:\n   - Checklist items can have an 'approver' specified in their metadata\n\nThese business rules form the core of the AI SDLC governance process, allowing for customizable, ordered workflows and checklists for AI project management.",
      "dependencies": "The documentation mentions several dependencies:\n\n1. Node.js (>= v18) and npm (>= v9)\n2. MongoDB for data storage and locking mechanism\n3. Redis (mentioned in Docker Compose setup)\n4. Docker for containerization\n5. Docker Compose for local development environment\n6. Localstack for AWS services emulation (S3, SQS)\n7. npm packages (not explicitly listed, but implied):\n   - undici for HTTP requests with proxy support\n   - fastify (implied by the server structure)\n   - jest or another testing framework (implied by test scripts)\n   - eslint and prettier for code formatting\n8. SonarCloud for code quality analysis\n9. Dependabot for dependency management (optional)\n\nThe project uses a package.json file to manage npm dependencies, but specific versions are not provided in the documentation.",
      "configuration": "Configuration details mentioned in the documentation include:\n\n1. Environment variables:\n   - PORT: For setting the server port (e.g., 3001)\n\n2. npm scripts defined in package.json for various tasks:\n   - dev: Run the application in development mode\n   - test: Run tests\n   - start: Run the application in production mode\n\n3. Docker configuration:\n   - Dockerfile with multi-stage builds (development and production)\n   - docker-compose.yml for local development environment\n\n4. Git configuration:\n   - Recommendation to set `core.autocrlf` to false on Windows\n\n5. Dependabot configuration:\n   - Example configuration file provided (.github/example.dependabot.yml)\n\n6. SonarCloud configuration:\n   - Mentioned in sonar-project.properties file (not provided in the documentation)\n\n7. Proxy configuration:\n   - Global dispatcher set up for HTTP requests\n\n8. MongoDB lock configuration:\n   - Available through server.locker or request.locker\n\nThe documentation suggests that there may be additional configuration files or environment variables not explicitly mentioned.",
      "infrastructure": "The infrastructure elements described in the documentation include:\n\n1. Docker containerization:\n   - Development image\n   - Production image\n   - Docker Compose setup for local development\n\n2. Docker Compose local environment:\n   - Localstack for AWS services (S3, SQS)\n   - Redis\n   - MongoDB\n   - The main service (ai-sdlc-governance-api)\n   - Optional frontend service (commented out)\n\n3. Node.js runtime environment\n\n4. MongoDB database\n\n5. Redis cache\n\n6. Proxy server for HTTP requests\n\n7. CI/CD implications:\n   - npm scripts for various development and build tasks\n   - Dependabot for automated dependency updates\n   - SonarCloud integration for code quality analysis\n\n8. Local development setup using npm\n\nWhile not explicitly mentioned, the use of Docker and the inclusion of AWS service emulation suggest that the production deployment might involve cloud infrastructure, possibly on AWS.",
      "non_functional": "Non-functional aspects covered in the documentation include:\n\n1. Performance and Reliability:\n   - Use of MongoDB locks for managing concurrent write operations\n   - Proxy configuration for HTTP requests, potentially improving network performance\n\n2. Security:\n   - Mention of a proxy setup, which could be used for security purposes\n   - Implied use of environment variables for configuration, which is a security best practice\n\n3. Development Practices:\n   - Code formatting guidelines and tools (eslint, prettier)\n   - Testing setup (npm test script)\n   - Use of dependabot for keeping dependencies up-to-date\n   - SonarCloud integration for code quality analysis\n\n4. Scalability:\n   - Docker containerization, enabling easier scaling and deployment\n\n5. Maintainability:\n   - Clear project structure and documentation\n   - Use of templates for workflows and checklist items, promoting reusability\n\n6. Compliance:\n   - Open Government Licence v3.0 for the project\n\n7. Logging and Monitoring:\n   - Health check endpoint (/health) for basic monitoring\n\n8. Error Handling:\n   - Example of error handling in MongoDB lock usage\n\nWhile not explicitly detailed, the project structure and tools used imply a focus on code quality, maintainability, and scalability."
    },
    {
      "chunk_id": "example_api",
      "summary": "This code implements a basic RESTful API for an example resource using the Hapi.js framework and MongoDB. It provides two endpoints: one for retrieving all example data and another for retrieving a single example by ID. The API includes controllers, database helpers, and unit tests for both endpoints. It demonstrates a modular structure with separation of concerns between route handling, data access, and testing.",
      "data_model": "The code interacts with a MongoDB collection named 'example-data'. The data model can be inferred as follows:\n\n```mermaid\nerDiagram\n    EXAMPLE_DATA {\n        string exampleId\n        string exampleData\n    }\n```\n\nFields:\n- exampleId (string): A unique identifier for each example entry\n- exampleData (string): The data associated with each example entry\n\nThe collection is accessed using MongoDB's native driver. Indexes are mentioned to be created elsewhere in the codebase (src/server/api/common/helpers/mongodb.js).\n\nData flow:\n1. Data is retrieved from the 'example-data' collection in MongoDB.\n2. When querying, the '_id' field is excluded from the projection.\n3. For findAll, all documents are returned as an array.\n4. For findOne, a single document is returned based on the exampleId, or null if not found.",
      "interfaces": "The code defines two API endpoints:\n\n1. GET /example\n   - Description: Retrieves all example data\n   - Response format:\n     ```json\n     {\n       \"message\": \"success\",\n       \"entities\": [\n         {\n           \"exampleId\": \"string\",\n           \"exampleData\": \"string\"\n         },\n         ...\n       ]\n     }\n     ```\n   - Status code: 200 OK\n\n2. GET /example/{exampleId}\n   - Description: Retrieves a single example by ID\n   - Parameters:\n     - exampleId (path parameter): The unique identifier of the example\n   - Response format (success):\n     ```json\n     {\n       \"message\": \"success\",\n       \"entity\": {\n         \"exampleId\": \"string\",\n         \"exampleData\": \"string\"\n       }\n     }\n     ```\n   - Status code: 200 OK\n   - Response format (not found):\n     ```json\n     {\n       \"error\": \"Not Found\",\n       \"message\": \"Not Found\",\n       \"statusCode\": 404\n     }\n     ```\n   - Status code: 404 Not Found\n\nThese endpoints are implemented using Hapi.js route handlers and are registered in the 'example' plugin.",
      "business_logic": "The business logic in this code is relatively simple:\n\n1. Retrieving all example data:\n   - The `exampleFindAllController` handles requests to fetch all example data.\n   - It uses the `findAllExampleData` helper to retrieve all documents from the 'example-data' collection.\n   - The retrieved data is returned with a success message and 200 OK status code.\n\n2. Retrieving a single example by ID:\n   - The `exampleFindOneController` handles requests to fetch a single example by its ID.\n   - It uses the `findExampleData` helper to query the 'example-data' collection for a document with the specified exampleId.\n   - If found, the data is returned with a success message and 200 OK status code.\n   - If not found, a 404 Not Found error is returned using Boom.\n\nThe business logic is separated from the route definitions and database access, following a basic separation of concerns. Controllers handle the request/response cycle, while helper functions encapsulate the database queries.",
      "dependencies": "The code relies on the following dependencies:\n\n1. @hapi/hapi: The Hapi.js framework for building the API server and defining routes.\n2. @hapi/boom: Used for generating HTTP-friendly error objects (e.g., 404 Not Found).\n3. mongodb: The official MongoDB driver for Node.js, used for database operations.\n4. lodash/isNull: A utility function from Lodash, used for null checks.\n\nExternal services:\n- MongoDB: The code interacts with a MongoDB database for data storage and retrieval.\n\nCustom dependencies:\n- src/api/common/constants/status-codes.js: Provides HTTP status codes.\n- src/api/common/helpers/mongodb.js: Mentioned for database index creation (not included in the provided code).\n- src/api/index.js: Used for creating and initializing the server in tests.\n\nThe code uses ES modules (import/export syntax) for dependency management.",
      "configuration": "The provided code doesn't explicitly show configuration management. However, there are indications of potential configuration needs:\n\n1. Database connection: The code assumes a database connection is available, likely configured elsewhere in the application.\n\n2. Server initialization: The `createServer()` function in the test files suggests server configuration is handled in a separate file (src/api/index.js).\n\n3. Plugin registration: The 'example' plugin is defined with a name and register function, which would be used in the main server configuration.\n\n4. Route configuration: Routes are defined with methods and paths, which could potentially be moved to a configuration file for easier management.\n\n5. Status codes: Imported from a constants file, suggesting some level of centralized configuration.\n\nNo explicit environment variables or configuration files are shown in the provided code snippet. Sensitive data handling (like database credentials) is not visible in this code and is likely managed elsewhere in the application.",
      "infrastructure": "The code doesn't directly include infrastructure-related elements. However, it provides some insights into the potential infrastructure setup:\n\n1. Application server: The code uses Hapi.js, indicating a Node.js runtime environment.\n\n2. Database: MongoDB is used as the database, suggesting a MongoDB instance needs to be deployed and accessible.\n\n3. Testing environment: The test files use `createServer()` and `server.initialize()`, indicating a need for a testing environment that can spin up a server instance and connect to a test database.\n\n4. Modular structure: The code is organized into separate files and modules, which could facilitate easier deployment and scaling.\n\nNo explicit deployment configurations, containerization, or CI/CD setups are present in the provided code. These aspects would likely be handled in separate configuration files or scripts not included in this code chunk.",
      "non_functional": "1. Testing:\n   - Unit tests are provided for both API endpoints.\n   - Tests use the Hapi server's inject method for simulating HTTP requests.\n   - Test setup includes database seeding and cleanup.\n   - Both success and error scenarios are tested.\n\n2. Error Handling:\n   - The findOne endpoint uses Boom to generate a standardized 404 error response when an entity is not found.\n   - Error responses follow HTTP standards (e.g., using appropriate status codes).\n\n3. Performance:\n   - Database queries exclude the '_id' field to reduce data transfer.\n   - The findAll query might need pagination for large datasets (not implemented in the current code).\n\n4. Security:\n   - No explicit security measures are visible in this code snippet.\n   - Input validation and sanitization are not shown and should be considered.\n\n5. Logging and Monitoring:\n   - No explicit logging or monitoring is implemented in the provided code.\n\n6. Data Integrity:\n   - Database operations use specific queries to ensure correct data is retrieved.\n   - No data modification operations are present in this code.\n\n7. Scalability:\n   - The modular design allows for easier scaling and maintenance.\n   - MongoDB is used, which can be scaled horizontally.\n\n8. Code Organization:\n   - The code follows a clear structure with separate files for controllers, helpers, and tests.\n   - ES modules are used for better code organization and potential tree-shaking.\n\nFurther non-functional aspects like rate limiting, authentication, and authorization are not present in this code snippet and should be considered for a production-ready API."
    },
    {
      "chunk_id": "scripts_and_utilities",
      "summary": "This code chunk contains utility scripts and configuration files for development and deployment. It includes a Git repository synchronization script, a development server startup script, and SonarCloud configuration for code quality analysis. These tools facilitate efficient development workflows, version control management, and code quality monitoring.",
      "data_model": null,
      "interfaces": null,
      "business_logic": null,
      "dependencies": "- Bash shell for running scripts\n- Git for version control\n- Node.js and npm for running the development server\n- SonarCloud for code quality analysis",
      "configuration": "The configuration in this chunk is primarily related to SonarCloud setup:\n\n1. SonarCloud Project Configuration (sonar-project.properties):\n   - Project Key: DEFRA_ai-sdlc-governance-api\n   - Organization: defra\n   - Project Links:\n     - Homepage: https://github.com/DEFRA/ai-sdlc-governance-api\n     - CI: https://github.com/DEFRA/ai-sdlc-governance-api/actions\n     - SCM: https://github.com/DEFRA/ai-sdlc-governance-api\n     - Issue Tracker: https://github.com/DEFRA/ai-sdlc-governance-api/issues\n   - Source Code Path: src/\n   - Test Code Path: src/\n   - Test Inclusions: src/**/*.test.js\n   - Code Coverage Report Path: ./coverage/lcov.info\n\n2. Development Environment Configuration (start_dev_server.sh):\n   - NODE_ENV: development\n   - LOG_LEVEL: debug\n\nNote: The configuration mentions that additional setup may be required in GitHub workflow files (check-pull-request.yml, publish.yml, publish-hotfix.yml) for full SonarCloud integration.",
      "infrastructure": "The infrastructure-related elements in this chunk include:\n\n1. Git Repository Management:\n   - The `git_cleanup.sh` script provides a way to synchronize local Git repository with remote branches, which is crucial for maintaining a clean and up-to-date development environment.\n   - It performs actions such as fetching from remote, pruning branches, and creating local branches for each remote branch.\n\n2. Development Environment Setup:\n   - The `start_dev_server.sh` script sets up the development environment by setting environment variables and starting the development server using npm.\n\n3. Code Quality Analysis:\n   - The `sonar-project.properties` file configures SonarCloud for continuous code quality analysis.\n   - It defines the project structure, test locations, and code coverage report paths for SonarCloud to analyze.\n\n4. CI/CD Integration:\n   - The SonarCloud configuration mentions integration with GitHub Actions workflows (check-pull-request.yml, publish.yml, publish-hotfix.yml), indicating a CI/CD pipeline setup for automated code quality checks and potentially deployment processes.\n\nThese elements contribute to a structured development and deployment infrastructure, focusing on version control, code quality, and automated processes.",
      "non_functional": "Non-functional aspects addressed in this code chunk include:\n\n1. Code Quality:\n   - Integration with SonarCloud for continuous code quality analysis, which can help identify and track issues related to code smells, bugs, and vulnerabilities.\n\n2. Development Efficiency:\n   - The Git cleanup script (`git_cleanup.sh`) improves development workflow by automating the synchronization of local and remote branches, reducing manual effort and potential errors.\n   - The development server startup script (`start_dev_server.sh`) streamlines the process of setting up the development environment.\n\n3. Maintainability:\n   - The use of scripts for common tasks (Git cleanup, server startup) promotes consistency and reduces the likelihood of errors in repetitive operations.\n\n4. Logging and Debugging:\n   - The development server script sets LOG_LEVEL to debug, indicating a focus on detailed logging for development purposes.\n\n5. Testing:\n   - The SonarCloud configuration includes settings for test inclusions and code coverage reporting, suggesting a focus on maintaining good test coverage.\n\n6. Continuous Integration:\n   - References to GitHub Actions workflows in the SonarCloud configuration indicate the use of CI/CD practices for automated testing and quality checks.\n\n7. Version Control Best Practices:\n   - The Git cleanup script enforces good version control practices by ensuring local branches are in sync with the remote repository and cleaning up stale branches.\n\nThese non-functional aspects contribute to the overall quality, maintainability, and efficiency of the development process."
    },
    {
      "chunk_id": "test_data",
      "summary": "This code chunk represents a MongoDB dump of a governance and workflow management system. It defines structures for governance templates, workflow templates, and checklist item templates. The system appears to be designed for managing service assessments, spend control, and project workflows in a government or large organization context. It includes data for various stages of project lifecycles, from kickoff to discovery and alpha phases, with dependencies between tasks.",
      "data_model": "The data model consists of several collections in MongoDB:\n\n1. governanceTemplates\n2. workflowInstances\n3. projects\n4. auditLogs\n5. mongo-locks\n6. workflowTemplates\n7. checklistItemTemplates\n8. checklistItemInstances\n\nKey entities and their relationships:\n\n```mermaid\nerDiagram\n    governanceTemplates ||--o{ workflowTemplates : contains\n    workflowTemplates ||--o{ checklistItemTemplates : contains\n    checklistItemTemplates ||--o{ checklistItemTemplates : depends_on\n```\n\nDetailed breakdown:\n\n1. governanceTemplates:\n   - _id: ObjectId\n   - version: String\n   - name: String\n   - description: String\n   - createdAt: Date\n   - updatedAt: Date\n\n2. workflowTemplates:\n   - _id: ObjectId\n   - governanceTemplateId: ObjectId (references governanceTemplates)\n   - name: String\n   - description: String\n   - createdAt: Date\n   - updatedAt: Date\n\n3. checklistItemTemplates:\n   - _id: ObjectId\n   - workflowTemplateId: ObjectId (references workflowTemplates)\n   - name: String\n   - description: String (optional)\n   - type: String (e.g., \"task\", \"document\", \"approval\")\n   - dependencies_requires: Array of ObjectId (references other checklistItemTemplates)\n   - createdAt: Date\n   - updatedAt: Date\n\nThe data model supports a hierarchical structure of governance templates, workflow templates, and checklist items. Checklist items can have dependencies on other items, creating a directed acyclic graph of tasks within a workflow.",
      "interfaces": null,
      "business_logic": "The business logic embedded in this data structure represents a governance and workflow management system for government or large organizational projects. Key aspects include:\n\n1. Governance Template: Represents an overarching governance model (e.g., \"Defra Service Governance\").\n\n2. Workflow Templates: Define specific processes within the governance model:\n   - GDS Service Assessments\n   - GDS Spend Control\n   - Service Readiness\n   - Change Management\n\n3. Checklist Item Templates: Represent individual tasks, documents, or approvals within workflows. They include:\n   - Task types: \"task\", \"document\", \"approval\"\n   - Dependencies between items (dependencies_requires field)\n   - Chronological order of activities in project lifecycle\n\n4. Project Lifecycle Stages:\n   - Project Kickoff\n   - Discovery Phase\n   - Alpha Phase\n\n5. Key Business Processes:\n   - Project initiation and setup\n   - Spend control approvals\n   - Service assessments\n   - Portfolio Assurance Board reviews\n   - Equality Analysis\n   - Phase transitions (e.g., Discovery to Alpha)\n\nThe system enforces a structured approach to project management, ensuring compliance with governance standards and proper sequencing of tasks throughout the project lifecycle.",
      "dependencies": null,
      "configuration": null,
      "infrastructure": null,
      "non_functional": "While not explicitly defined in the data, the following non-functional aspects can be inferred:\n\n1. Data Integrity: The use of MongoDB ObjectIds and structured documents suggests a focus on data integrity and relationships between entities.\n\n2. Auditability: The presence of an `auditLogs` collection implies a system for tracking changes and maintaining an audit trail.\n\n3. Concurrency Control: The `mongo-locks` collection suggests implementation of concurrency control mechanisms to manage simultaneous access to resources.\n\n4. Timestamps: `createdAt` and `updatedAt` fields on entities support tracking of data lifecycle and potential for implementing data retention policies.\n\n5. Scalability: The modular structure of templates and instances allows for scalability in managing multiple projects and workflows.\n\n6. Flexibility: The system appears designed to accommodate various types of workflows and governance models, indicating flexibility in its application.\n\n7. Compliance: The structured approach to project management and governance suggests a focus on ensuring compliance with organizational or regulatory standards.\n\nThese aspects contribute to the overall reliability, maintainability, and compliance of the system, which are crucial for government and large organizational contexts."
    },
    {
      "chunk_id": "constants",
      "summary": "This code defines a constant object `statusCodes` that maps HTTP status code names to their corresponding numeric values. It includes common status codes such as OK (200), Bad Request (400), and Not Found (404), as well as the humorous I'm a Teapot (418) status. The constant is exported for use throughout the application, providing a centralized and consistent way to reference HTTP status codes.",
      "data_model": null,
      "interfaces": null,
      "business_logic": null,
      "dependencies": null,
      "configuration": null,
      "infrastructure": null,
      "non_functional": "The use of a centralized constants file for HTTP status codes contributes to code maintainability and consistency. It reduces the likelihood of errors from mistyped status codes and makes it easier to update or add new status codes across the application. The inclusion of JSDoc type definition (`@typedef {Record<string, number>} StatusCodes`) improves code documentation and may assist with type checking in development environments that support it."
    }
  ],
  "report_sections": {
    "data_model": "# Data Model Report\n\n## Logical Data Models and Entities\n\nThe codebase implements a comprehensive data model for an AI SDLC governance system. The main entities in the system are:\n\n1. Governance Template\n2. Workflow Template\n3. Checklist Item Template\n4. Project\n5. Workflow Instance\n6. Checklist Item Instance\n\nThese entities form a hierarchical structure that allows for the creation and management of governance templates, which can be instantiated into projects with specific workflows and checklist items.\n\n## Mermaid ERD Diagram\n\n```mermaid\nerDiagram\n    GOVERNANCE_TEMPLATE ||--o{ WORKFLOW_TEMPLATE : contains\n    WORKFLOW_TEMPLATE ||--o{ CHECKLIST_ITEM_TEMPLATE : contains\n    GOVERNANCE_TEMPLATE ||--o{ PROJECT : uses\n    PROJECT ||--o{ WORKFLOW_INSTANCE : has\n    WORKFLOW_TEMPLATE ||--o{ WORKFLOW_INSTANCE : instantiates\n    WORKFLOW_INSTANCE ||--o{ CHECKLIST_ITEM_INSTANCE : has\n    CHECKLIST_ITEM_TEMPLATE ||--o{ CHECKLIST_ITEM_INSTANCE : instantiates\n    CHECKLIST_ITEM_TEMPLATE }o--o{ CHECKLIST_ITEM_TEMPLATE : depends_on\n    CHECKLIST_ITEM_INSTANCE }o--o{ CHECKLIST_ITEM_INSTANCE : depends_on\n\n    GOVERNANCE_TEMPLATE {\n        ObjectId _id\n        string version\n        string name\n        string description\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_TEMPLATE {\n        ObjectId _id\n        ObjectId governanceTemplateId\n        string name\n        string description\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_TEMPLATE {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        string name\n        string description\n        string type\n        ObjectId[] dependencies_requires\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    PROJECT {\n        ObjectId _id\n        String name\n        String description\n        ObjectId governanceTemplateId\n        ObjectId[] selectedWorkflowTemplateIds\n        Object metadata\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_INSTANCE {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        String name\n        String description\n        Object metadata\n        Number order\n        String status\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_INSTANCE {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        String name\n        String description\n        String type\n        String status\n        ObjectId[] dependencies_requires\n        Object metadata\n        Number order\n        Date createdAt\n        Date updatedAt\n    }\n```\n\n## Detailed Breakdown of Each Model's Fields, Types, and Relationships\n\n### 1. Governance Template\n- _id: MongoDB ObjectId (unique identifier)\n- version: string\n- name: string\n- description: string (optional)\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Contains multiple Workflow Templates\n\n### 2. Workflow Template\n- _id: MongoDB ObjectId (unique identifier)\n- governanceTemplateId: MongoDB ObjectId (reference to Governance Template)\n- name: string\n- description: string\n- metadata: object (for additional configuration)\n- order: integer (for manual ordering)\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Governance Template\n  - Contains multiple Checklist Item Templates\n\n### 3. Checklist Item Template\n- _id: MongoDB ObjectId (unique identifier)\n- workflowTemplateId: MongoDB ObjectId (reference to Workflow Template)\n- name: string\n- description: string\n- type: string (e.g., 'approval', 'document', 'task')\n- dependencies_requires: array of ObjectId (references to other Checklist Item Templates)\n- metadata: object (additional configuration based on checklist item type)\n- order: number (for manual ordering)\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Workflow Template\n  - Can have dependencies on other Checklist Item Templates\n\n### 4. Project\n- _id: MongoDB ObjectId (unique identifier)\n- name: string\n- description: string\n- governanceTemplateId: ObjectId (reference to Governance Template)\n- selectedWorkflowTemplateIds: array of ObjectId (references to Workflow Templates)\n- metadata: object\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Uses a Governance Template\n  - Contains multiple Workflow Instances\n\n### 5. Workflow Instance\n- _id: MongoDB ObjectId (unique identifier)\n- projectId: ObjectId (reference to Project)\n- workflowTemplateId: ObjectId (reference to Workflow Template)\n- name: string\n- description: string\n- metadata: object\n- order: number\n- status: string (e.g., 'active', 'completed')\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Project\n  - Based on a Workflow Template\n  - Contains multiple Checklist Item Instances\n\n### 6. Checklist Item Instance\n- _id: MongoDB ObjectId (unique identifier)\n- workflowInstanceId: ObjectId (reference to Workflow Instance)\n- checklistItemTemplateId: ObjectId (reference to Checklist Item Template)\n- name: string\n- description: string\n- type: string\n- status: string (e.g., 'incomplete', 'complete', 'not_required')\n- dependencies_requires: array of ObjectId (references to other Checklist Item Instances)\n- metadata: object\n- order: number\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Workflow Instance\n  - Based on a Checklist Item Template\n  - Can have dependencies on other Checklist Item Instances\n\n## Data Flow and Transformations\n\n1. Governance Templates are created as the top-level structure.\n2. Workflow Templates are associated with Governance Templates.\n3. Checklist Item Templates are created within Workflow Templates.\n4. When a Project is created, it is associated with a Governance Template.\n5. Workflow Instances are created based on the selected Workflow Templates for the Project.\n6. Checklist Item Instances are created for each Workflow Instance, based on the Checklist Item Templates.\n7. The system maintains the hierarchical structure and relationships between templates and instances.\n8. Order values are copied from templates to instances during project creation to maintain consistent sorting.\n9. Status updates and progress tracking occur at the Checklist Item Instance and Workflow Instance levels.\n\n## Data Validation and Integrity Checks\n\n1. Input validation is performed using Joi schemas for all data models.\n2. MongoDB ObjectId validation is implemented to ensure valid references between entities.\n3. The system prevents self-dependencies in Checklist Item Templates and Instances.\n4. Referential integrity is maintained by verifying the existence of referenced entities before creating new records (e.g., checking if a Governance Template exists before creating a Project).\n5. Order consistency is maintained across templates and instances.\n6. Status values are validated against predefined sets of allowed values.\n7. Date fields (createdAt, updatedAt) are automatically managed to ensure accurate timestamps.\n8. Unique indexes are created on relevant fields to prevent duplicate entries.\n9. The system ensures that Checklist Item Instances maintain the same dependency structure as their corresponding templates.\n10. Migrations are tracked to manage schema changes and data updates over time.\n\nThese validation and integrity checks ensure data consistency and reliability throughout the SDLC governance system.",
    "interfaces": "# Interfaces Report\n\n## User Interfaces (UI)\n\nThe codebase does not appear to expose any direct user interfaces. However, it does provide API documentation through Swagger UI, which can be accessed at:\n\n- `/docs`: Main documentation page\n- `/docs/swagger`: Swagger UI\n- `/docs/swagger.json`: Raw Swagger JSON\n\n## API Endpoints\n\nThe codebase exposes a RESTful API with the following endpoints:\n\n### Health Check\n\n- `GET /health`\n  - Description: Check if the service is running\n  - Response: \n    ```json\n    {\n      \"message\": \"success\"\n    }\n    ```\n  - Status Code: 200 OK\n\n### Governance Templates\n\n- `POST /api/v1/governance-templates`\n  - Description: Create a new governance template\n  - Request Body: `{ version: string, name: string, description: string }`\n  - Response: Created template\n  - Status Codes: 200 OK, 400 Bad Request, 409 Conflict\n\n- `GET /api/v1/governance-templates/{id}`\n  - Description: Get a governance template by ID\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Response: Template object\n  - Status Codes: 200 OK, 404 Not Found, 400 Bad Request\n\n- `PUT /api/v1/governance-templates/{id}`\n  - Description: Update a governance template\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Request Body: `{ version: string, name: string, description: string }`\n  - Response: Updated template\n  - Status Codes: 200 OK, 404 Not Found, 400 Bad Request, 409 Conflict\n\n- `DELETE /api/v1/governance-templates/{id}`\n  - Description: Delete a governance template\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Status Codes: 204 No Content, 404 Not Found, 400 Bad Request\n\n- `GET /api/v1/governance-templates`\n  - Description: Get all governance templates with their workflow templates sorted by order\n  - Response: Array of templates\n  - Status Codes: 200 OK, 400 Bad Request\n\n### Workflow Templates\n\n- `POST /api/v1/workflow-templates`\n  - Description: Create a new workflow template\n  - Request Body: `{ governanceTemplateId, name, description, metadata }`\n  - Response: Created workflow template object\n  - Status Code: 201 Created\n\n- `GET /api/v1/workflow-templates/{id}`\n  - Description: Get a specific workflow template by ID\n  - Path Parameter: `id`\n  - Response: Workflow template object\n  - Status Code: 200 OK\n\n- `PUT /api/v1/workflow-templates/{id}`\n  - Description: Update a workflow template\n  - Path Parameter: `id`\n  - Request Body: `{ name, description, metadata, order }`\n  - Response: Updated workflow template object\n  - Status Code: 200 OK\n\n- `DELETE /api/v1/workflow-templates/{id}`\n  - Description: Delete a workflow template and its associated checklist items\n  - Path Parameter: `id`\n  - Status Code: 204 No Content\n\n- `GET /api/v1/workflow-templates`\n  - Description: Get all workflow templates, optionally filtered by governanceTemplateId\n  - Query Parameter: `governanceTemplateId` (optional)\n  - Response: Array of workflow template objects\n  - Status Code: 200 OK\n\n### Checklist Item Templates\n\n- `POST /api/v1/checklist-item-templates`\n  - Description: Create a new checklist item template\n  - Request Body: `{ workflowTemplateId, name, description, type, dependencies_requires, metadata }`\n  - Response: Created template data\n  - Status Code: 201 Created\n\n- `GET /api/v1/checklist-item-templates/{id}`\n  - Description: Get a specific checklist item template by ID\n  - Path Parameter: `id`\n  - Response: Template data, including populated dependencies\n  - Status Code: 200 OK\n\n- `PUT /api/v1/checklist-item-templates/{id}`\n  - Description: Update a checklist item template\n  - Path Parameter: `id`\n  - Request Body: `{ name, description, type, dependencies_requires, metadata, order }`\n  - Response: Updated template data\n  - Status Code: 200 OK\n\n- `DELETE /api/v1/checklist-item-templates/{id}`\n  - Description: Delete a checklist item template\n  - Path Parameter: `id`\n  - Status Code: 204 No Content\n\n- `GET /api/v1/checklist-item-templates`\n  - Description: Get all checklist item templates, with optional filtering\n  - Query Parameters: `workflowTemplateId`, `governanceTemplateId`\n  - Response: Array of template data\n  - Status Code: 200 OK\n\n### Projects\n\n- `POST /api/v1/projects`\n  - Description: Create a new project\n  - Request Body: JSON object with project details\n  - Response: Created project details\n  - Status Code: 201 Created\n\n- `GET /api/v1/projects/{id}`\n  - Description: Get a project by ID\n  - Path Parameter: `id`\n  - Response: Project details\n  - Status Code: 200 OK\n\n- `PUT /api/v1/projects/{id}`\n  - Description: Update a project\n  - Path Parameter: `id`\n  - Request Body: JSON object with updated project details\n  - Response: Updated project details\n  - Status Code: 200 OK\n\n- `DELETE /api/v1/projects/{id}`\n  - Description: Delete a project\n  - Path Parameter: `id`\n  - Status Code: 204 No Content\n\n- `GET /api/v1/projects`\n  - Description: Get all projects\n  - Response: Array of project details\n  - Status Code: 200 OK\n\n### Workflow Instances\n\n- `GET /api/v1/workflow-instances`\n  - Description: Get workflow instances for a project\n  - Query Parameter: `projectId` (required, MongoDB ObjectId)\n  - Response: Array of WorkflowInstance objects\n  - Status Codes: 200 OK, 400 Bad Request, 404 Not Found\n\n### Checklist Item Instances\n\n- `GET /api/v1/checklist-item-instances`\n  - Description: Get checklist item instances for a workflow instance\n  - Query Parameter: `workflowInstanceId` (required, MongoDB ObjectId)\n  - Response: Array of ChecklistItemInstance objects\n  - Status Code: 200 OK\n\n- `PUT /api/v1/checklist-item-instances/{id}`\n  - Description: Update a checklist item instance\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Request Body: JSON object with fields to update (name, description, type, status, metadata)\n  - Response: Updated ChecklistItemInstance object\n  - Status Code: 200 OK\n\n### Example API (for demonstration purposes)\n\n- `GET /example`\n  - Description: Get all example data\n  - Response: \n    ```json\n    {\n      \"message\": \"success\",\n      \"entities\": [\n        {\n          \"exampleId\": \"string\",\n          \"exampleData\": \"string\"\n        }\n      ]\n    }\n    ```\n  - Status Code: 200 OK\n\n- `GET /example/{exampleId}`\n  - Description: Get a single example by ID\n  - Path Parameter: `exampleId`\n  - Response (success): \n    ```json\n    {\n      \"message\": \"success\",\n      \"entity\": {\n        \"exampleId\": \"string\",\n        \"exampleData\": \"string\"\n      }\n    }\n    ```\n  - Response (not found):\n    ```json\n    {\n      \"error\": \"Not Found\",\n      \"message\": \"Not Found\",\n      \"statusCode\": 404\n    }\n    ```\n  - Status Codes: 200 OK, 404 Not Found\n\n## Batch Processing Interfaces\n\nThe codebase includes a command-line interface (CLI) for managing MongoDB operations:\n\n- `dump`: Dumps the current state of MongoDB to a JSON file\n- `restore`: Restores the database from a dump file\n- `deleteAll`: Deletes all data from all collections\n- `reset-schema`: Resets schema validations for all collections\n\n## Event-Driven Interfaces\n\nThe codebase does not appear to expose any explicit event-driven interfaces or message queues.\n\n## Other Interfaces\n\n### Docker Interfaces\n\n- Development image: Exposes port 3001\n- Production image: Exposes port 3001\n\n### Authentication\n\nThe API uses JWT authentication. The `Authorization` header is expected for authenticated requests.\n\n### Database Interface\n\nThe codebase interacts with MongoDB for data persistence and includes a locking mechanism for resource management.\n\n### Proxy Interface\n\nThere is a proxy interface for making HTTP requests, but no specific details are provided in the given context.\n\nNote: All API endpoints use JSON for request and response bodies, and the API is documented using Swagger/OpenAPI specifications.",
    "business_logic": "# Business Logic Report\n\n## Core Business Rules and Domain Logic\n\n1. Governance Template Management:\n   - Creation, retrieval, updating, and deletion of governance templates\n   - Governance templates contain associated workflow templates\n   - Unique combinations of template name and version are enforced\n   - Cascading delete for associated workflow templates and checklist items\n\n2. Workflow Template Management:\n   - Creation, retrieval, updating, and deletion of workflow templates\n   - Automatic order assignment and management\n   - Unique names within a governance template\n   - Cascading delete for associated checklist items\n\n3. Checklist Item Template Management:\n   - Creation, retrieval, updating, and deletion of checklist item templates\n   - Automatic order assignment and management\n   - Dependency management between checklist items\n   - Prevention of self-dependencies\n\n4. Project Management:\n   - Creation of projects based on governance templates\n   - Selection of workflow templates for each project\n   - Creation of workflow instances and checklist item instances\n   - CRUD operations for projects\n\n5. Workflow Instance Management:\n   - Retrieval and sorting of workflow instances for a project\n   - Sorting based on manual order, completion status, and number of items\n\n6. Checklist Item Instance Management:\n   - Status updates with specific rules for different item types (approval, document, task)\n   - Dependency validation before marking items as complete\n   - Audit logging for status changes\n   - Type-specific metadata validation\n\n7. Data Integrity and Validation:\n   - Input data validation using Joi schemas\n   - Referential integrity between entities\n   - Prevention of direct dependency updates for checklist items\n\n## Business Process Flows\n\n1. Project Lifecycle:\n   - Project Kickoff\n   - Discovery Phase\n   - Alpha Phase\n   - Transition between phases\n\n2. Governance Process:\n   - Creation of governance templates\n   - Definition of workflow templates within governance templates\n   - Creation of checklist item templates within workflow templates\n   - Instantiation of projects based on governance templates\n   - Progression through workflow instances and checklist items\n\n3. Approval and Review Process:\n   - GDS Service Assessments\n   - GDS Spend Control\n   - Service Readiness\n   - Change Management\n   - Portfolio Assurance Board reviews\n\n4. Document Management:\n   - Submission of required documents at various stages\n   - Validation of document URLs for completion\n\n5. Task Completion:\n   - Sequential completion of tasks based on dependencies\n   - Automatic updating of completion status and metadata\n\n## Business Rules\n\n1. Ordering:\n   - Automatic calculation of 'order' field for new workflow and checklist item templates\n   - Reordering of remaining items when a template is deleted\n   - Sorting of workflows and checklist items by 'order' when retrieving\n\n2. Dependencies:\n   - Checklist items can have dependencies on other items\n   - All dependencies must be complete before an item can be marked as complete\n\n3. Status Updates:\n   - Approval items require an approver and set an approval date when completed\n   - Document items require a document URL when marked as complete\n   - Task items automatically set the completedBy and completedDate fields when marked as complete\n\n4. Workflow Sorting:\n   - Workflows are sorted based on completion status of their checklist items\n   - More completed items take precedence in sorting\n\n5. Versioning:\n   - Governance templates are versioned to allow for updates and tracking\n\n6. Uniqueness:\n   - Unique combinations of template name and version for governance templates\n   - Unique names for workflow templates within a governance template\n   - No duplicate order numbers for workflow templates or checklist items\n\n## Separation of Concerns between Business Logic and Other Layers\n\n1. Controller-Service-Model Pattern:\n   - Controllers handle request/response cycle\n   - Services contain core business logic\n   - Models define data structures and database interactions\n\n2. Validation:\n   - Input validation using Joi schemas, separate from core business logic\n\n3. Error Handling:\n   - Use of Boom for generating HTTP-friendly error objects\n\n4. Database Access:\n   - Separation of database queries into helper functions\n\n5. API Routing:\n   - Clear separation of route definitions from business logic implementation\n\n6. Migration System:\n   - Separate module for handling database migrations and schema updates\n\n## Domain-Driven Design Patterns\n\n1. Aggregates:\n   - Governance Template as the root aggregate, containing Workflow Templates and Checklist Item Templates\n   - Project as another root aggregate, containing Workflow Instances and Checklist Item Instances\n\n2. Entities:\n   - Governance Template\n   - Workflow Template\n   - Checklist Item Template\n   - Project\n   - Workflow Instance\n   - Checklist Item Instance\n\n3. Value Objects:\n   - Status (for checklist items)\n   - Order (for workflows and checklist items)\n\n4. Repositories:\n   - Implicit use of repositories for data access, encapsulated in model functions\n\n5. Services:\n   - Domain services for complex operations like project creation and checklist item status updates\n\n6. Factories:\n   - Implicit use of factories for creating new instances of entities\n\n7. Bounded Contexts:\n   - Clear separation between template management and instance management contexts\n\nThis business logic report outlines the core components and rules governing the AI SDLC governance API, highlighting the structured approach to project management, workflow execution, and compliance with governance standards throughout the project lifecycle.",
    "dependencies": "# Dependencies Report\n\n## External Dependencies (Libraries and Frameworks)\n\n1. **Node.js and npm**: The project requires Node.js (>= v22) and npm (>= v9) for runtime and package management.\n\n2. **Hapi.js Ecosystem**:\n   - @hapi/hapi: Core web framework for building the API server\n   - @hapi/inert: Static file and directory handling\n   - @hapi/vision: Template rendering\n   - @hapi/boom: HTTP-friendly error objects\n   - hapi-swagger: API documentation generator\n   - hapi-pino: Logging integration for Hapi\n   - hapi-pulse: Graceful server shutdown handling\n\n3. **MongoDB**: \n   - mongodb: Official MongoDB driver for Node.js\n   - mongo-locks: Distributed locking mechanism\n\n4. **Logging and Metrics**:\n   - pino: Logging library\n   - @elastic/ecs-pino-format: ECS formatting for Pino\n   - aws-embedded-metrics: Metrics logging\n\n5. **Validation and Schema**:\n   - joi: Data validation library\n\n6. **Configuration Management**:\n   - convict: Configuration management\n\n7. **Testing**:\n   - Jest: Testing framework\n   - @playwright/test: End-to-end testing\n   - @shelf/jest-mongodb: MongoDB integration for Jest\n\n8. **Build and Development Tools**:\n   - @babel/core and related packages: For transpilation\n   - typescript: Type checking\n   - eslint and prettier: Code linting and formatting\n   - nodemon: Auto-restarting during development\n   - husky: Git hooks management\n\n9. **Miscellaneous**:\n   - undici: HTTP/1.1 client (used for proxy setup)\n   - global-agent: Global HTTP/HTTPS proxy configuration\n   - yargs: Command-line argument parsing\n   - lodash: Utility functions\n\n## API Calls and External Services\n\n1. **MongoDB**: Primary database for storing various templates, projects, and instances.\n\n2. **Redis**: Mentioned in Docker Compose setup, likely used for caching or session management.\n\n3. **LocalStack**: Used for emulating AWS services locally, specifically:\n   - S3 (Simple Storage Service)\n   - SQS (Simple Queue Service)\n\n4. **SonarCloud**: Integrated for code quality analysis.\n\n## Database Connections and ORM Usage\n\n1. **MongoDB**:\n   - Used as the primary database system.\n   - Direct interaction using the official MongoDB driver.\n   - No ORM is explicitly mentioned; raw queries are used.\n   - Collections include:\n     - governanceTemplates\n     - workflowTemplates\n     - checklistItemTemplates\n     - projects\n     - workflowInstances\n     - checklistItemInstances\n     - auditLogs\n\n2. **MongoDB Memory Server**: Used for testing purposes (version 4.0.3).\n\n## Third-Party Integrations\n\n1. **Dependabot**: Optional integration for dependency management.\n\n2. **GitHub Actions**: Used for CI/CD processes, including running tests and reporting.\n\n3. **Docker and Docker Compose**: Used for containerization and local development environment setup.\n\n## Other External Dependencies\n\n1. **Node.js Core Modules**: Extensive use of built-in modules like `fs`, `path`, `url`, and `tls`.\n\n2. **Environment Variables**: Used for configuration management.\n\n3. **External Configuration Files**: The application relies on external configuration and migration files.\n\n## Versioning and Compatibility Considerations\n\n1. **Node.js Version**: The project requires Node.js version 22 or higher, indicating the use of modern JavaScript features.\n\n2. **MongoDB Version**: The project is configured to use MongoDB version 6.0.13.\n\n3. **Redis Version**: Redis version 7.2.3 is specified in the setup.\n\n4. **ES Modules**: The project uses ES Module syntax, requiring Node.js version 12 or later with ES Modules enabled.\n\n5. **Babel Configuration**: Babel is set up to handle different environments (test vs. production), ensuring compatibility across various setups.\n\n6. **Package Versioning**: While specific versions for npm packages are not provided in the documentation, they are likely specified in the `package.json` file.\n\n7. **ESM-only Dependencies**: Some dependencies like `node-fetch` and `@defra/hapi-tracing` are noted as ESM-only, which may affect compatibility with CommonJS modules.\n\n8. **Mixed Module Systems**: The project uses a mix of CommonJS (.cjs files) and ES Modules (.js files with import/export), which requires careful management of interoperability.\n\nThis report provides a comprehensive overview of the dependencies and integrations used in the project, highlighting the complex ecosystem of tools and services required for its operation and development.",
    "configuration": "# Configuration Report\n\n## Configuration Files\n\n1. **package.json**: Contains npm scripts, dependencies, and project metadata.\n\n2. **nodemon.json**: Configuration for development auto-reloading.\n\n3. **tsconfig.json** and **tsconfig.test.json**: TypeScript configuration files.\n\n4. **babel.config.cjs**: Configures Babel for JavaScript transpilation.\n\n5. **jest-mongodb-config.cjs**: Configures MongoDB Memory Server for testing.\n\n6. **jest.config.js**: Configures Jest for unit testing.\n\n7. **playwright.config.js**: Configures Playwright for end-to-end API testing.\n\n8. **sonar-project.properties**: SonarCloud configuration file.\n\n9. **Dockerfile**: Multi-stage build configuration for development and production.\n\n10. **compose.yml**: Docker Compose configuration for local development environment.\n\n11. **compose/aws.env**: AWS configuration for local development.\n\n## Configuration Variables\n\n1. **Server Configuration**:\n   - `port`: Server port number (default: 3001)\n   - `root`: Root directory for serving static files\n\n2. **API Configuration**:\n   - `serviceName`: Name of the service\n   - `serviceVersion`: Version of the service\n   - `isDevelopment`: Boolean flag for development mode\n\n3. **Database Configuration**:\n   - `mongoUri`: MongoDB connection string\n   - `mongoDatabase`: Name of the database\n   - `retryWrites`: Boolean (default: false)\n   - `readPreference`: String (default: 'secondary')\n\n4. **Logging Configuration**:\n   - `log.enabled`: Boolean to enable/disable logging\n   - `log.level`: Log level (default: 'debug' in development)\n   - `log.format`: Log format (ECS or pino-pretty)\n   - `log.ignorePaths`: Paths to ignore for logging\n   - `log.redact`: Fields to redact from logs\n\n5. **Metrics Configuration**:\n   - `isMetricsEnabled`: Boolean to enable/disable metrics\n\n6. **Security Configuration**:\n   - `isSecureContextEnabled`: Boolean to enable/disable custom secure context\n\n7. **Tracing Configuration**:\n   - `tracing.header`: Header used for request tracing\n\n8. **HTTP Proxy Configuration**:\n   - `httpProxy`: URL for the HTTP proxy\n\n## Environment Variables and Config Files\n\n1. **Environment Variables**:\n   - `NODE_ENV`: Application environment (production, development, test)\n   - `PORT`: Server port number\n   - `LOG_LEVEL`: Logging level\n   - `TRUSTSTORE_*`: Base64 encoded certificates for the trust store\n   - `BASE_URL`: Base URL for the API (used in Playwright config)\n\n2. **Config Files**:\n   - `src/config/index.js`: Central configuration file using 'convict' for schema-based configuration\n   - `.env`: (implied) For storing environment-specific variables\n\n3. **AWS Configuration**:\n   - `AWS_REGION`: AWS region for local development\n   - `AWS_ACCESS_KEY_ID`: AWS access key for local development\n   - `AWS_SECRET_ACCESS_KEY`: AWS secret key for local development\n\n## Secrets Management and Sensitive Data Handling\n\n1. **Environment Variables**: Sensitive data such as database credentials, API keys, and certificates are stored as environment variables.\n\n2. **Trust Store Certificates**: Stored as base64 encoded strings in environment variables (TRUSTSTORE_*) and decoded at runtime.\n\n3. **MongoDB Connection String**: Retrieved from the configuration system, suggesting a centralized secrets management approach.\n\n4. **Logging Redaction**: Sensitive fields can be redacted from logs using the `log.redact` configuration.\n\n5. **Secure Context**: Optional `secureContext` for MongoDB connection, if provided by the server.\n\n6. **Docker Secrets**: While not explicitly shown, the use of Docker suggests potential use of Docker secrets for managing sensitive data in production environments.\n\n7. **Configuration Retrieval**: Sensitive data is retrieved using `config.get()` method, indicating a centralized and potentially secure method of accessing configuration values.\n\n8. **SonarCloud Integration**: Sensitive data for SonarCloud integration is likely managed through GitHub Secrets in the CI/CD pipeline.\n\nNote: The exact implementation of secrets management is not fully visible in the provided code snippets. It's recommended to use a dedicated secrets management solution (e.g., HashiCorp Vault, AWS Secrets Manager) for production environments.",
    "infrastructure": "# Infrastructure Report\n\n## Deployment Configuration and Infrastructure as Code (IaC)\n\nThe codebase does not explicitly define Infrastructure as Code (IaC) configurations. However, the presence of Docker-related files suggests a containerized approach to deployment:\n\n- A Dockerfile is used for building the application container\n- A `compose.yml` file defines and orchestrates multiple services\n- The setup allows for consistent development, testing, and production environments\n\nWhile not directly visible in the code, the application's structure and dependencies imply that it could benefit from IaC tools like Terraform or AWS CloudFormation for managing cloud resources in production environments.\n\n## Deployment and Environment Setup\n\nThe application's deployment and environment setup are primarily managed through Docker and npm scripts:\n\n1. Docker Compose local environment:\n   - LocalStack for emulating AWS services (S3, SQS, SNS, Firehose)\n   - Redis for caching\n   - MongoDB for database\n   - Backend application container\n   - Custom bridge network 'cdp-tenant' for container communication\n   - Persistent volume for MongoDB data\n   - Health checks for services like LocalStack\n\n2. Environment configuration:\n   - AWS credentials and region settings for local development\n   - Application-specific environment variables\n\n3. Local development:\n   - npm scripts for various development and build tasks\n   - `start_dev_server.sh` script for setting up the development environment\n\n4. Production build:\n   - Multi-stage Dockerfile for optimized production builds\n\n5. Git repository management:\n   - `git_cleanup.sh` script for synchronizing local Git repository with remote branches\n\n## Cloud Services Integration\n\nWhile the code doesn't explicitly define cloud service configurations, it suggests potential integration with cloud services:\n\n1. AWS service emulation using LocalStack, indicating possible use of:\n   - Amazon S3\n   - Amazon SQS\n   - Amazon SNS\n   - Amazon Kinesis Data Firehose\n\n2. The application structure and use of MongoDB suggest it could be deployed on cloud platforms like:\n   - Amazon Web Services (AWS)\n   - Google Cloud Platform (GCP)\n   - Microsoft Azure\n\n3. Potential use of cloud-based managed services for:\n   - Database (e.g., Amazon DocumentDB, Azure Cosmos DB)\n   - Caching (e.g., Amazon ElastiCache, Azure Cache for Redis)\n   - API Gateway\n   - Load Balancing\n\n## Containerization and Orchestration\n\nThe application uses Docker for containerization:\n\n1. Dockerfile for building the application container\n2. Docker Compose for local development environment\n3. Separate configurations for development and production containers\n\nWhile not explicitly defined, the containerized nature of the application suggests it could be easily deployed to container orchestration platforms like:\n\n- Kubernetes\n- Amazon ECS (Elastic Container Service)\n- Azure Kubernetes Service (AKS)\n\n## CI/CD Pipeline Setup\n\nThe codebase includes elements that indicate a CI/CD pipeline setup:\n\n1. GitHub Actions integration:\n   - Mentioned in the SonarCloud configuration file\n   - Workflows: check-pull-request.yml, publish.yml, publish-hotfix.yml\n\n2. Code quality analysis:\n   - SonarCloud integration configured in `sonar-project.properties`\n   - Defines project structure, test locations, and code coverage report paths\n\n3. Automated testing:\n   - Presence of end-to-end (E2E) tests using Playwright\n\n4. Dependency management:\n   - Dependabot for automated dependency updates\n\n5. Build and deployment scripts:\n   - npm scripts for various development and build tasks\n\nWhile the specific CI/CD tool (apart from GitHub Actions) is not explicitly mentioned, the codebase is structured to support automated testing, code quality checks, and potentially automated deployment processes.\n\nIn conclusion, while many infrastructure aspects are implied rather than explicitly defined in the codebase, the application is designed with a modern, cloud-native architecture in mind. It leverages containerization for consistency across environments and is prepared for integration with cloud services and CI/CD pipelines.",
    "non_functional": "# Non-Functional Aspects Report\n\n## Performance and Reliability Aspects\n\n1. Database Optimization:\n   - MongoDB is used for efficient data storage and retrieval\n   - Indexing is implemented for improved query performance\n   - MongoDB connection pooling is utilized for efficient database connections\n\n2. Caching:\n   - Caching of workflow instances and checklist items is implemented to optimize sorting and comparison operations\n   - Redis integration is available for potential caching mechanisms\n\n3. Efficient Data Operations:\n   - Batch operations are used for updating multiple documents\n   - Database-level operations are used for large-scale data updates\n   - MongoDB's native driver is used for efficient database operations\n\n4. Scalability:\n   - Stateless API design allows for horizontal scaling\n   - MongoDB replica sets support read scaling\n   - Containerized architecture supports potential orchestration\n\n5. Concurrency Control:\n   - Distributed locking is implemented for concurrent operations\n   - MongoDB locks are used for managing concurrent write operations\n\n6. High Availability:\n   - MongoDB replica sets are supported for high availability\n\n7. Performance Considerations:\n   - Efficient sorting and grouping of workflow instances and checklist items\n   - Use of async/await for non-blocking operations\n\n8. Graceful Shutdown:\n   - The 'pulse' plugin handles graceful shutdown procedures with a 10-second timeout\n\n## Security Considerations and Potential Vulnerabilities\n\n1. Input Validation:\n   - Joi schemas are used for input validation to prevent injection attacks\n   - MongoDB ObjectId validation is implemented\n\n2. Authentication and Authorization:\n   - JWT authentication is used for API endpoints\n   - Secure context loading for SSL/TLS certificates\n\n3. HTTP Security Headers:\n   - HSTS (HTTP Strict Transport Security) enabled\n   - XSS protection enabled\n   - Content-Type sniffing prevention\n   - X-Frame-Options header set\n\n4. Secure Configuration:\n   - Environment-based configuration for sensitive data\n   - Secure MongoDB connections supported\n\n5. TLS Configuration:\n   - Custom secure context implementation for TLS connections\n   - Dynamic loading of trust store certificates from environment variables\n\n6. Certificate Management:\n   - Support for multiple CA certificates in the trust store\n   - Base64 encoding of certificates in environment variables\n\n7. Proxy Setup:\n   - HTTP proxy setup available for enhanced security\n\n## Volume and Load Considerations\n\n1. Database Scalability:\n   - MongoDB's horizontal scaling capabilities\n   - Efficient indexing for large datasets\n\n2. API Performance:\n   - Stateless API design for horizontal scaling\n   - Caching mechanisms for frequently accessed data\n\n3. Concurrent Operations:\n   - Distributed locking for managing concurrent write operations\n\n4. Large Dataset Handling:\n   - Efficient database-level operations for large-scale updates\n   - Potential need for pagination in API responses for large datasets\n\n## Significant Error Handling and Recovery Mechanisms\n\n1. HTTP-Friendly Error Responses:\n   - Use of Boom for generating standardized HTTP error responses\n\n2. Global Error Handling:\n   - Unhandled rejection handler to prevent crashes\n   - Custom error handling for route validation failures\n\n3. Database Error Handling:\n   - Try-catch blocks around database operations\n   - Specific error handling for common scenarios (e.g., not found, conflicts)\n\n4. Migration Error Handling:\n   - Errors during migrations are caught, logged, and can halt the process to prevent partial migration states\n\n5. Graceful Degradation:\n   - Health check endpoints for monitoring system status\n\n## Logging, Monitoring, and Alerting\n\n1. Logging:\n   - Pino logger used for efficient logging\n   - Support for different log formats (ECS and pino-pretty)\n   - Configurable log levels and redaction for sensitive information\n   - Request logging through hapi-pino plugin\n\n2. Metrics:\n   - AWS Embedded Metrics used for custom metric tracking\n   - Support for counting metrics with configurable names and values\n\n3. Tracing:\n   - Request tracing implemented using @defra/hapi-tracing plugin\n   - Trace IDs incorporated in logs for distributed tracing\n\n4. Monitoring:\n   - Health check endpoint (/health) available for basic monitoring\n\n5. Alerting:\n   - While not explicitly implemented, the logging and metrics infrastructure provides a foundation for implementing alerting systems\n\n## Compliance Considerations\n\n1. Data Governance:\n   - Structured approach to project management and governance\n   - Audit logs for tracking changes and maintaining an audit trail\n\n2. Licensing:\n   - Open Government Licence v3.0 for the project\n\n3. Code Quality:\n   - Integration with SonarCloud for continuous code quality analysis\n   - Strict linting rules enforced\n\n4. Version Control:\n   - Git hooks with Husky for pre-commit checks\n\n## Data and Privacy Considerations\n\n1. Data Protection:\n   - Redaction of sensitive log data in production environments\n   - Secure handling of configuration data\n\n2. Data Integrity:\n   - Use of transactions for data consistency\n   - Strict schema validations for all collections\n\n3. Data Lifecycle Management:\n   - Timestamps (createdAt, updatedAt) on entities for tracking data lifecycle\n\n4. User Data Handling:\n   - Potential handling of user IDs in audit logs, which could be considered sensitive information\n\n## Testing Strategies and Code Coverage\n\n1. Unit Testing:\n   - Jest used as the primary testing framework\n   - Extensive unit tests for utility functions and API endpoints\n\n2. Integration Testing:\n   - API testing implemented using Playwright\n\n3. End-to-End Testing:\n   - E2E tests for API endpoints using Playwright\n\n4. Database Testing:\n   - Jest MongoDB used for database testing\n   - In-memory MongoDB used for consistent test environments\n\n5. Test Coverage:\n   - Jest configured to collect coverage from src/**/*.js\n   - Coverage reports generated in the coverage directory\n\n6. Continuous Integration:\n   - GitHub Actions used for running tests in CI/CD pipelines\n\n7. Test Environment:\n   - Custom setup files for Jest (.jest/setup.js and .jest/setup-after-env.js)\n   - Configurable timeouts for tests\n\n8. Mocking:\n   - Use of jest.mock() for mocking dependencies in tests\n\nThis report provides a comprehensive overview of the non-functional aspects of the codebase, highlighting the system's focus on performance, security, reliability, and maintainability. While many best practices are implemented, there are areas for potential improvement, particularly in explicit security measures and handling of very large datasets."
  },
  "consolidated_report": "# Code Analysis Report\n\n## Repository Information\n- **Repository URL:** https://github.com/DEFRA/ai-sdlc-governance-api\n- **Languages Used:** javascript\n\n# Data Model Report\n\n## Logical Data Models and Entities\n\nThe codebase implements a comprehensive data model for an AI SDLC governance system. The main entities in the system are:\n\n1. Governance Template\n2. Workflow Template\n3. Checklist Item Template\n4. Project\n5. Workflow Instance\n6. Checklist Item Instance\n\nThese entities form a hierarchical structure that allows for the creation and management of governance templates, which can be instantiated into projects with specific workflows and checklist items.\n\n## Mermaid ERD Diagram\n\n```mermaid\nerDiagram\n    GOVERNANCE_TEMPLATE ||--o{ WORKFLOW_TEMPLATE : contains\n    WORKFLOW_TEMPLATE ||--o{ CHECKLIST_ITEM_TEMPLATE : contains\n    GOVERNANCE_TEMPLATE ||--o{ PROJECT : uses\n    PROJECT ||--o{ WORKFLOW_INSTANCE : has\n    WORKFLOW_TEMPLATE ||--o{ WORKFLOW_INSTANCE : instantiates\n    WORKFLOW_INSTANCE ||--o{ CHECKLIST_ITEM_INSTANCE : has\n    CHECKLIST_ITEM_TEMPLATE ||--o{ CHECKLIST_ITEM_INSTANCE : instantiates\n    CHECKLIST_ITEM_TEMPLATE }o--o{ CHECKLIST_ITEM_TEMPLATE : depends_on\n    CHECKLIST_ITEM_INSTANCE }o--o{ CHECKLIST_ITEM_INSTANCE : depends_on\n\n    GOVERNANCE_TEMPLATE {\n        ObjectId _id\n        string version\n        string name\n        string description\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_TEMPLATE {\n        ObjectId _id\n        ObjectId governanceTemplateId\n        string name\n        string description\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_TEMPLATE {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        string name\n        string description\n        string type\n        ObjectId[] dependencies_requires\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    PROJECT {\n        ObjectId _id\n        String name\n        String description\n        ObjectId governanceTemplateId\n        ObjectId[] selectedWorkflowTemplateIds\n        Object metadata\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_INSTANCE {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        String name\n        String description\n        Object metadata\n        Number order\n        String status\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_INSTANCE {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        String name\n        String description\n        String type\n        String status\n        ObjectId[] dependencies_requires\n        Object metadata\n        Number order\n        Date createdAt\n        Date updatedAt\n    }\n```\n\n## Detailed Breakdown of Each Model's Fields, Types, and Relationships\n\n### 1. Governance Template\n- _id: MongoDB ObjectId (unique identifier)\n- version: string\n- name: string\n- description: string (optional)\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Contains multiple Workflow Templates\n\n### 2. Workflow Template\n- _id: MongoDB ObjectId (unique identifier)\n- governanceTemplateId: MongoDB ObjectId (reference to Governance Template)\n- name: string\n- description: string\n- metadata: object (for additional configuration)\n- order: integer (for manual ordering)\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Governance Template\n  - Contains multiple Checklist Item Templates\n\n### 3. Checklist Item Template\n- _id: MongoDB ObjectId (unique identifier)\n- workflowTemplateId: MongoDB ObjectId (reference to Workflow Template)\n- name: string\n- description: string\n- type: string (e.g., 'approval', 'document', 'task')\n- dependencies_requires: array of ObjectId (references to other Checklist Item Templates)\n- metadata: object (additional configuration based on checklist item type)\n- order: number (for manual ordering)\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Workflow Template\n  - Can have dependencies on other Checklist Item Templates\n\n### 4. Project\n- _id: MongoDB ObjectId (unique identifier)\n- name: string\n- description: string\n- governanceTemplateId: ObjectId (reference to Governance Template)\n- selectedWorkflowTemplateIds: array of ObjectId (references to Workflow Templates)\n- metadata: object\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Uses a Governance Template\n  - Contains multiple Workflow Instances\n\n### 5. Workflow Instance\n- _id: MongoDB ObjectId (unique identifier)\n- projectId: ObjectId (reference to Project)\n- workflowTemplateId: ObjectId (reference to Workflow Template)\n- name: string\n- description: string\n- metadata: object\n- order: number\n- status: string (e.g., 'active', 'completed')\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Project\n  - Based on a Workflow Template\n  - Contains multiple Checklist Item Instances\n\n### 6. Checklist Item Instance\n- _id: MongoDB ObjectId (unique identifier)\n- workflowInstanceId: ObjectId (reference to Workflow Instance)\n- checklistItemTemplateId: ObjectId (reference to Checklist Item Template)\n- name: string\n- description: string\n- type: string\n- status: string (e.g., 'incomplete', 'complete', 'not_required')\n- dependencies_requires: array of ObjectId (references to other Checklist Item Instances)\n- metadata: object\n- order: number\n- createdAt: Date\n- updatedAt: Date\n- Relationships:\n  - Belongs to a Workflow Instance\n  - Based on a Checklist Item Template\n  - Can have dependencies on other Checklist Item Instances\n\n## Data Flow and Transformations\n\n1. Governance Templates are created as the top-level structure.\n2. Workflow Templates are associated with Governance Templates.\n3. Checklist Item Templates are created within Workflow Templates.\n4. When a Project is created, it is associated with a Governance Template.\n5. Workflow Instances are created based on the selected Workflow Templates for the Project.\n6. Checklist Item Instances are created for each Workflow Instance, based on the Checklist Item Templates.\n7. The system maintains the hierarchical structure and relationships between templates and instances.\n8. Order values are copied from templates to instances during project creation to maintain consistent sorting.\n9. Status updates and progress tracking occur at the Checklist Item Instance and Workflow Instance levels.\n\n## Data Validation and Integrity Checks\n\n1. Input validation is performed using Joi schemas for all data models.\n2. MongoDB ObjectId validation is implemented to ensure valid references between entities.\n3. The system prevents self-dependencies in Checklist Item Templates and Instances.\n4. Referential integrity is maintained by verifying the existence of referenced entities before creating new records (e.g., checking if a Governance Template exists before creating a Project).\n5. Order consistency is maintained across templates and instances.\n6. Status values are validated against predefined sets of allowed values.\n7. Date fields (createdAt, updatedAt) are automatically managed to ensure accurate timestamps.\n8. Unique indexes are created on relevant fields to prevent duplicate entries.\n9. The system ensures that Checklist Item Instances maintain the same dependency structure as their corresponding templates.\n10. Migrations are tracked to manage schema changes and data updates over time.\n\nThese validation and integrity checks ensure data consistency and reliability throughout the SDLC governance system.\n\n# Interfaces Report\n\n## User Interfaces (UI)\n\nThe codebase does not appear to expose any direct user interfaces. However, it does provide API documentation through Swagger UI, which can be accessed at:\n\n- `/docs`: Main documentation page\n- `/docs/swagger`: Swagger UI\n- `/docs/swagger.json`: Raw Swagger JSON\n\n## API Endpoints\n\nThe codebase exposes a RESTful API with the following endpoints:\n\n### Health Check\n\n- `GET /health`\n  - Description: Check if the service is running\n  - Response: \n    ```json\n    {\n      \"message\": \"success\"\n    }\n    ```\n  - Status Code: 200 OK\n\n### Governance Templates\n\n- `POST /api/v1/governance-templates`\n  - Description: Create a new governance template\n  - Request Body: `{ version: string, name: string, description: string }`\n  - Response: Created template\n  - Status Codes: 200 OK, 400 Bad Request, 409 Conflict\n\n- `GET /api/v1/governance-templates/{id}`\n  - Description: Get a governance template by ID\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Response: Template object\n  - Status Codes: 200 OK, 404 Not Found, 400 Bad Request\n\n- `PUT /api/v1/governance-templates/{id}`\n  - Description: Update a governance template\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Request Body: `{ version: string, name: string, description: string }`\n  - Response: Updated template\n  - Status Codes: 200 OK, 404 Not Found, 400 Bad Request, 409 Conflict\n\n- `DELETE /api/v1/governance-templates/{id}`\n  - Description: Delete a governance template\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Status Codes: 204 No Content, 404 Not Found, 400 Bad Request\n\n- `GET /api/v1/governance-templates`\n  - Description: Get all governance templates with their workflow templates sorted by order\n  - Response: Array of templates\n  - Status Codes: 200 OK, 400 Bad Request\n\n### Workflow Templates\n\n- `POST /api/v1/workflow-templates`\n  - Description: Create a new workflow template\n  - Request Body: `{ governanceTemplateId, name, description, metadata }`\n  - Response: Created workflow template object\n  - Status Code: 201 Created\n\n- `GET /api/v1/workflow-templates/{id}`\n  - Description: Get a specific workflow template by ID\n  - Path Parameter: `id`\n  - Response: Workflow template object\n  - Status Code: 200 OK\n\n- `PUT /api/v1/workflow-templates/{id}`\n  - Description: Update a workflow template\n  - Path Parameter: `id`\n  - Request Body: `{ name, description, metadata, order }`\n  - Response: Updated workflow template object\n  - Status Code: 200 OK\n\n- `DELETE /api/v1/workflow-templates/{id}`\n  - Description: Delete a workflow template and its associated checklist items\n  - Path Parameter: `id`\n  - Status Code: 204 No Content\n\n- `GET /api/v1/workflow-templates`\n  - Description: Get all workflow templates, optionally filtered by governanceTemplateId\n  - Query Parameter: `governanceTemplateId` (optional)\n  - Response: Array of workflow template objects\n  - Status Code: 200 OK\n\n### Checklist Item Templates\n\n- `POST /api/v1/checklist-item-templates`\n  - Description: Create a new checklist item template\n  - Request Body: `{ workflowTemplateId, name, description, type, dependencies_requires, metadata }`\n  - Response: Created template data\n  - Status Code: 201 Created\n\n- `GET /api/v1/checklist-item-templates/{id}`\n  - Description: Get a specific checklist item template by ID\n  - Path Parameter: `id`\n  - Response: Template data, including populated dependencies\n  - Status Code: 200 OK\n\n- `PUT /api/v1/checklist-item-templates/{id}`\n  - Description: Update a checklist item template\n  - Path Parameter: `id`\n  - Request Body: `{ name, description, type, dependencies_requires, metadata, order }`\n  - Response: Updated template data\n  - Status Code: 200 OK\n\n- `DELETE /api/v1/checklist-item-templates/{id}`\n  - Description: Delete a checklist item template\n  - Path Parameter: `id`\n  - Status Code: 204 No Content\n\n- `GET /api/v1/checklist-item-templates`\n  - Description: Get all checklist item templates, with optional filtering\n  - Query Parameters: `workflowTemplateId`, `governanceTemplateId`\n  - Response: Array of template data\n  - Status Code: 200 OK\n\n### Projects\n\n- `POST /api/v1/projects`\n  - Description: Create a new project\n  - Request Body: JSON object with project details\n  - Response: Created project details\n  - Status Code: 201 Created\n\n- `GET /api/v1/projects/{id}`\n  - Description: Get a project by ID\n  - Path Parameter: `id`\n  - Response: Project details\n  - Status Code: 200 OK\n\n- `PUT /api/v1/projects/{id}`\n  - Description: Update a project\n  - Path Parameter: `id`\n  - Request Body: JSON object with updated project details\n  - Response: Updated project details\n  - Status Code: 200 OK\n\n- `DELETE /api/v1/projects/{id}`\n  - Description: Delete a project\n  - Path Parameter: `id`\n  - Status Code: 204 No Content\n\n- `GET /api/v1/projects`\n  - Description: Get all projects\n  - Response: Array of project details\n  - Status Code: 200 OK\n\n### Workflow Instances\n\n- `GET /api/v1/workflow-instances`\n  - Description: Get workflow instances for a project\n  - Query Parameter: `projectId` (required, MongoDB ObjectId)\n  - Response: Array of WorkflowInstance objects\n  - Status Codes: 200 OK, 400 Bad Request, 404 Not Found\n\n### Checklist Item Instances\n\n- `GET /api/v1/checklist-item-instances`\n  - Description: Get checklist item instances for a workflow instance\n  - Query Parameter: `workflowInstanceId` (required, MongoDB ObjectId)\n  - Response: Array of ChecklistItemInstance objects\n  - Status Code: 200 OK\n\n- `PUT /api/v1/checklist-item-instances/{id}`\n  - Description: Update a checklist item instance\n  - Path Parameter: `id` (MongoDB ObjectId)\n  - Request Body: JSON object with fields to update (name, description, type, status, metadata)\n  - Response: Updated ChecklistItemInstance object\n  - Status Code: 200 OK\n\n### Example API (for demonstration purposes)\n\n- `GET /example`\n  - Description: Get all example data\n  - Response: \n    ```json\n    {\n      \"message\": \"success\",\n      \"entities\": [\n        {\n          \"exampleId\": \"string\",\n          \"exampleData\": \"string\"\n        }\n      ]\n    }\n    ```\n  - Status Code: 200 OK\n\n- `GET /example/{exampleId}`\n  - Description: Get a single example by ID\n  - Path Parameter: `exampleId`\n  - Response (success): \n    ```json\n    {\n      \"message\": \"success\",\n      \"entity\": {\n        \"exampleId\": \"string\",\n        \"exampleData\": \"string\"\n      }\n    }\n    ```\n  - Response (not found):\n    ```json\n    {\n      \"error\": \"Not Found\",\n      \"message\": \"Not Found\",\n      \"statusCode\": 404\n    }\n    ```\n  - Status Codes: 200 OK, 404 Not Found\n\n## Batch Processing Interfaces\n\nThe codebase includes a command-line interface (CLI) for managing MongoDB operations:\n\n- `dump`: Dumps the current state of MongoDB to a JSON file\n- `restore`: Restores the database from a dump file\n- `deleteAll`: Deletes all data from all collections\n- `reset-schema`: Resets schema validations for all collections\n\n## Event-Driven Interfaces\n\nThe codebase does not appear to expose any explicit event-driven interfaces or message queues.\n\n## Other Interfaces\n\n### Docker Interfaces\n\n- Development image: Exposes port 3001\n- Production image: Exposes port 3001\n\n### Authentication\n\nThe API uses JWT authentication. The `Authorization` header is expected for authenticated requests.\n\n### Database Interface\n\nThe codebase interacts with MongoDB for data persistence and includes a locking mechanism for resource management.\n\n### Proxy Interface\n\nThere is a proxy interface for making HTTP requests, but no specific details are provided in the given context.\n\nNote: All API endpoints use JSON for request and response bodies, and the API is documented using Swagger/OpenAPI specifications.\n\n# Business Logic Report\n\n## Core Business Rules and Domain Logic\n\n1. Governance Template Management:\n   - Creation, retrieval, updating, and deletion of governance templates\n   - Governance templates contain associated workflow templates\n   - Unique combinations of template name and version are enforced\n   - Cascading delete for associated workflow templates and checklist items\n\n2. Workflow Template Management:\n   - Creation, retrieval, updating, and deletion of workflow templates\n   - Automatic order assignment and management\n   - Unique names within a governance template\n   - Cascading delete for associated checklist items\n\n3. Checklist Item Template Management:\n   - Creation, retrieval, updating, and deletion of checklist item templates\n   - Automatic order assignment and management\n   - Dependency management between checklist items\n   - Prevention of self-dependencies\n\n4. Project Management:\n   - Creation of projects based on governance templates\n   - Selection of workflow templates for each project\n   - Creation of workflow instances and checklist item instances\n   - CRUD operations for projects\n\n5. Workflow Instance Management:\n   - Retrieval and sorting of workflow instances for a project\n   - Sorting based on manual order, completion status, and number of items\n\n6. Checklist Item Instance Management:\n   - Status updates with specific rules for different item types (approval, document, task)\n   - Dependency validation before marking items as complete\n   - Audit logging for status changes\n   - Type-specific metadata validation\n\n7. Data Integrity and Validation:\n   - Input data validation using Joi schemas\n   - Referential integrity between entities\n   - Prevention of direct dependency updates for checklist items\n\n## Business Process Flows\n\n1. Project Lifecycle:\n   - Project Kickoff\n   - Discovery Phase\n   - Alpha Phase\n   - Transition between phases\n\n2. Governance Process:\n   - Creation of governance templates\n   - Definition of workflow templates within governance templates\n   - Creation of checklist item templates within workflow templates\n   - Instantiation of projects based on governance templates\n   - Progression through workflow instances and checklist items\n\n3. Approval and Review Process:\n   - GDS Service Assessments\n   - GDS Spend Control\n   - Service Readiness\n   - Change Management\n   - Portfolio Assurance Board reviews\n\n4. Document Management:\n   - Submission of required documents at various stages\n   - Validation of document URLs for completion\n\n5. Task Completion:\n   - Sequential completion of tasks based on dependencies\n   - Automatic updating of completion status and metadata\n\n## Business Rules\n\n1. Ordering:\n   - Automatic calculation of 'order' field for new workflow and checklist item templates\n   - Reordering of remaining items when a template is deleted\n   - Sorting of workflows and checklist items by 'order' when retrieving\n\n2. Dependencies:\n   - Checklist items can have dependencies on other items\n   - All dependencies must be complete before an item can be marked as complete\n\n3. Status Updates:\n   - Approval items require an approver and set an approval date when completed\n   - Document items require a document URL when marked as complete\n   - Task items automatically set the completedBy and completedDate fields when marked as complete\n\n4. Workflow Sorting:\n   - Workflows are sorted based on completion status of their checklist items\n   - More completed items take precedence in sorting\n\n5. Versioning:\n   - Governance templates are versioned to allow for updates and tracking\n\n6. Uniqueness:\n   - Unique combinations of template name and version for governance templates\n   - Unique names for workflow templates within a governance template\n   - No duplicate order numbers for workflow templates or checklist items\n\n## Separation of Concerns between Business Logic and Other Layers\n\n1. Controller-Service-Model Pattern:\n   - Controllers handle request/response cycle\n   - Services contain core business logic\n   - Models define data structures and database interactions\n\n2. Validation:\n   - Input validation using Joi schemas, separate from core business logic\n\n3. Error Handling:\n   - Use of Boom for generating HTTP-friendly error objects\n\n4. Database Access:\n   - Separation of database queries into helper functions\n\n5. API Routing:\n   - Clear separation of route definitions from business logic implementation\n\n6. Migration System:\n   - Separate module for handling database migrations and schema updates\n\n## Domain-Driven Design Patterns\n\n1. Aggregates:\n   - Governance Template as the root aggregate, containing Workflow Templates and Checklist Item Templates\n   - Project as another root aggregate, containing Workflow Instances and Checklist Item Instances\n\n2. Entities:\n   - Governance Template\n   - Workflow Template\n   - Checklist Item Template\n   - Project\n   - Workflow Instance\n   - Checklist Item Instance\n\n3. Value Objects:\n   - Status (for checklist items)\n   - Order (for workflows and checklist items)\n\n4. Repositories:\n   - Implicit use of repositories for data access, encapsulated in model functions\n\n5. Services:\n   - Domain services for complex operations like project creation and checklist item status updates\n\n6. Factories:\n   - Implicit use of factories for creating new instances of entities\n\n7. Bounded Contexts:\n   - Clear separation between template management and instance management contexts\n\nThis business logic report outlines the core components and rules governing the AI SDLC governance API, highlighting the structured approach to project management, workflow execution, and compliance with governance standards throughout the project lifecycle.\n\n# Dependencies Report\n\n## External Dependencies (Libraries and Frameworks)\n\n1. **Node.js and npm**: The project requires Node.js (>= v22) and npm (>= v9) for runtime and package management.\n\n2. **Hapi.js Ecosystem**:\n   - @hapi/hapi: Core web framework for building the API server\n   - @hapi/inert: Static file and directory handling\n   - @hapi/vision: Template rendering\n   - @hapi/boom: HTTP-friendly error objects\n   - hapi-swagger: API documentation generator\n   - hapi-pino: Logging integration for Hapi\n   - hapi-pulse: Graceful server shutdown handling\n\n3. **MongoDB**: \n   - mongodb: Official MongoDB driver for Node.js\n   - mongo-locks: Distributed locking mechanism\n\n4. **Logging and Metrics**:\n   - pino: Logging library\n   - @elastic/ecs-pino-format: ECS formatting for Pino\n   - aws-embedded-metrics: Metrics logging\n\n5. **Validation and Schema**:\n   - joi: Data validation library\n\n6. **Configuration Management**:\n   - convict: Configuration management\n\n7. **Testing**:\n   - Jest: Testing framework\n   - @playwright/test: End-to-end testing\n   - @shelf/jest-mongodb: MongoDB integration for Jest\n\n8. **Build and Development Tools**:\n   - @babel/core and related packages: For transpilation\n   - typescript: Type checking\n   - eslint and prettier: Code linting and formatting\n   - nodemon: Auto-restarting during development\n   - husky: Git hooks management\n\n9. **Miscellaneous**:\n   - undici: HTTP/1.1 client (used for proxy setup)\n   - global-agent: Global HTTP/HTTPS proxy configuration\n   - yargs: Command-line argument parsing\n   - lodash: Utility functions\n\n## API Calls and External Services\n\n1. **MongoDB**: Primary database for storing various templates, projects, and instances.\n\n2. **Redis**: Mentioned in Docker Compose setup, likely used for caching or session management.\n\n3. **LocalStack**: Used for emulating AWS services locally, specifically:\n   - S3 (Simple Storage Service)\n   - SQS (Simple Queue Service)\n\n4. **SonarCloud**: Integrated for code quality analysis.\n\n## Database Connections and ORM Usage\n\n1. **MongoDB**:\n   - Used as the primary database system.\n   - Direct interaction using the official MongoDB driver.\n   - No ORM is explicitly mentioned; raw queries are used.\n   - Collections include:\n     - governanceTemplates\n     - workflowTemplates\n     - checklistItemTemplates\n     - projects\n     - workflowInstances\n     - checklistItemInstances\n     - auditLogs\n\n2. **MongoDB Memory Server**: Used for testing purposes (version 4.0.3).\n\n## Third-Party Integrations\n\n1. **Dependabot**: Optional integration for dependency management.\n\n2. **GitHub Actions**: Used for CI/CD processes, including running tests and reporting.\n\n3. **Docker and Docker Compose**: Used for containerization and local development environment setup.\n\n## Other External Dependencies\n\n1. **Node.js Core Modules**: Extensive use of built-in modules like `fs`, `path`, `url`, and `tls`.\n\n2. **Environment Variables**: Used for configuration management.\n\n3. **External Configuration Files**: The application relies on external configuration and migration files.\n\n## Versioning and Compatibility Considerations\n\n1. **Node.js Version**: The project requires Node.js version 22 or higher, indicating the use of modern JavaScript features.\n\n2. **MongoDB Version**: The project is configured to use MongoDB version 6.0.13.\n\n3. **Redis Version**: Redis version 7.2.3 is specified in the setup.\n\n4. **ES Modules**: The project uses ES Module syntax, requiring Node.js version 12 or later with ES Modules enabled.\n\n5. **Babel Configuration**: Babel is set up to handle different environments (test vs. production), ensuring compatibility across various setups.\n\n6. **Package Versioning**: While specific versions for npm packages are not provided in the documentation, they are likely specified in the `package.json` file.\n\n7. **ESM-only Dependencies**: Some dependencies like `node-fetch` and `@defra/hapi-tracing` are noted as ESM-only, which may affect compatibility with CommonJS modules.\n\n8. **Mixed Module Systems**: The project uses a mix of CommonJS (.cjs files) and ES Modules (.js files with import/export), which requires careful management of interoperability.\n\nThis report provides a comprehensive overview of the dependencies and integrations used in the project, highlighting the complex ecosystem of tools and services required for its operation and development.\n\n# Configuration Report\n\n## Configuration Files\n\n1. **package.json**: Contains npm scripts, dependencies, and project metadata.\n\n2. **nodemon.json**: Configuration for development auto-reloading.\n\n3. **tsconfig.json** and **tsconfig.test.json**: TypeScript configuration files.\n\n4. **babel.config.cjs**: Configures Babel for JavaScript transpilation.\n\n5. **jest-mongodb-config.cjs**: Configures MongoDB Memory Server for testing.\n\n6. **jest.config.js**: Configures Jest for unit testing.\n\n7. **playwright.config.js**: Configures Playwright for end-to-end API testing.\n\n8. **sonar-project.properties**: SonarCloud configuration file.\n\n9. **Dockerfile**: Multi-stage build configuration for development and production.\n\n10. **compose.yml**: Docker Compose configuration for local development environment.\n\n11. **compose/aws.env**: AWS configuration for local development.\n\n## Configuration Variables\n\n1. **Server Configuration**:\n   - `port`: Server port number (default: 3001)\n   - `root`: Root directory for serving static files\n\n2. **API Configuration**:\n   - `serviceName`: Name of the service\n   - `serviceVersion`: Version of the service\n   - `isDevelopment`: Boolean flag for development mode\n\n3. **Database Configuration**:\n   - `mongoUri`: MongoDB connection string\n   - `mongoDatabase`: Name of the database\n   - `retryWrites`: Boolean (default: false)\n   - `readPreference`: String (default: 'secondary')\n\n4. **Logging Configuration**:\n   - `log.enabled`: Boolean to enable/disable logging\n   - `log.level`: Log level (default: 'debug' in development)\n   - `log.format`: Log format (ECS or pino-pretty)\n   - `log.ignorePaths`: Paths to ignore for logging\n   - `log.redact`: Fields to redact from logs\n\n5. **Metrics Configuration**:\n   - `isMetricsEnabled`: Boolean to enable/disable metrics\n\n6. **Security Configuration**:\n   - `isSecureContextEnabled`: Boolean to enable/disable custom secure context\n\n7. **Tracing Configuration**:\n   - `tracing.header`: Header used for request tracing\n\n8. **HTTP Proxy Configuration**:\n   - `httpProxy`: URL for the HTTP proxy\n\n## Environment Variables and Config Files\n\n1. **Environment Variables**:\n   - `NODE_ENV`: Application environment (production, development, test)\n   - `PORT`: Server port number\n   - `LOG_LEVEL`: Logging level\n   - `TRUSTSTORE_*`: Base64 encoded certificates for the trust store\n   - `BASE_URL`: Base URL for the API (used in Playwright config)\n\n2. **Config Files**:\n   - `src/config/index.js`: Central configuration file using 'convict' for schema-based configuration\n   - `.env`: (implied) For storing environment-specific variables\n\n3. **AWS Configuration**:\n   - `AWS_REGION`: AWS region for local development\n   - `AWS_ACCESS_KEY_ID`: AWS access key for local development\n   - `AWS_SECRET_ACCESS_KEY`: AWS secret key for local development\n\n## Secrets Management and Sensitive Data Handling\n\n1. **Environment Variables**: Sensitive data such as database credentials, API keys, and certificates are stored as environment variables.\n\n2. **Trust Store Certificates**: Stored as base64 encoded strings in environment variables (TRUSTSTORE_*) and decoded at runtime.\n\n3. **MongoDB Connection String**: Retrieved from the configuration system, suggesting a centralized secrets management approach.\n\n4. **Logging Redaction**: Sensitive fields can be redacted from logs using the `log.redact` configuration.\n\n5. **Secure Context**: Optional `secureContext` for MongoDB connection, if provided by the server.\n\n6. **Docker Secrets**: While not explicitly shown, the use of Docker suggests potential use of Docker secrets for managing sensitive data in production environments.\n\n7. **Configuration Retrieval**: Sensitive data is retrieved using `config.get()` method, indicating a centralized and potentially secure method of accessing configuration values.\n\n8. **SonarCloud Integration**: Sensitive data for SonarCloud integration is likely managed through GitHub Secrets in the CI/CD pipeline.\n\nNote: The exact implementation of secrets management is not fully visible in the provided code snippets. It's recommended to use a dedicated secrets management solution (e.g., HashiCorp Vault, AWS Secrets Manager) for production environments.\n\n# Infrastructure Report\n\n## Deployment Configuration and Infrastructure as Code (IaC)\n\nThe codebase does not explicitly define Infrastructure as Code (IaC) configurations. However, the presence of Docker-related files suggests a containerized approach to deployment:\n\n- A Dockerfile is used for building the application container\n- A `compose.yml` file defines and orchestrates multiple services\n- The setup allows for consistent development, testing, and production environments\n\nWhile not directly visible in the code, the application's structure and dependencies imply that it could benefit from IaC tools like Terraform or AWS CloudFormation for managing cloud resources in production environments.\n\n## Deployment and Environment Setup\n\nThe application's deployment and environment setup are primarily managed through Docker and npm scripts:\n\n1. Docker Compose local environment:\n   - LocalStack for emulating AWS services (S3, SQS, SNS, Firehose)\n   - Redis for caching\n   - MongoDB for database\n   - Backend application container\n   - Custom bridge network 'cdp-tenant' for container communication\n   - Persistent volume for MongoDB data\n   - Health checks for services like LocalStack\n\n2. Environment configuration:\n   - AWS credentials and region settings for local development\n   - Application-specific environment variables\n\n3. Local development:\n   - npm scripts for various development and build tasks\n   - `start_dev_server.sh` script for setting up the development environment\n\n4. Production build:\n   - Multi-stage Dockerfile for optimized production builds\n\n5. Git repository management:\n   - `git_cleanup.sh` script for synchronizing local Git repository with remote branches\n\n## Cloud Services Integration\n\nWhile the code doesn't explicitly define cloud service configurations, it suggests potential integration with cloud services:\n\n1. AWS service emulation using LocalStack, indicating possible use of:\n   - Amazon S3\n   - Amazon SQS\n   - Amazon SNS\n   - Amazon Kinesis Data Firehose\n\n2. The application structure and use of MongoDB suggest it could be deployed on cloud platforms like:\n   - Amazon Web Services (AWS)\n   - Google Cloud Platform (GCP)\n   - Microsoft Azure\n\n3. Potential use of cloud-based managed services for:\n   - Database (e.g., Amazon DocumentDB, Azure Cosmos DB)\n   - Caching (e.g., Amazon ElastiCache, Azure Cache for Redis)\n   - API Gateway\n   - Load Balancing\n\n## Containerization and Orchestration\n\nThe application uses Docker for containerization:\n\n1. Dockerfile for building the application container\n2. Docker Compose for local development environment\n3. Separate configurations for development and production containers\n\nWhile not explicitly defined, the containerized nature of the application suggests it could be easily deployed to container orchestration platforms like:\n\n- Kubernetes\n- Amazon ECS (Elastic Container Service)\n- Azure Kubernetes Service (AKS)\n\n## CI/CD Pipeline Setup\n\nThe codebase includes elements that indicate a CI/CD pipeline setup:\n\n1. GitHub Actions integration:\n   - Mentioned in the SonarCloud configuration file\n   - Workflows: check-pull-request.yml, publish.yml, publish-hotfix.yml\n\n2. Code quality analysis:\n   - SonarCloud integration configured in `sonar-project.properties`\n   - Defines project structure, test locations, and code coverage report paths\n\n3. Automated testing:\n   - Presence of end-to-end (E2E) tests using Playwright\n\n4. Dependency management:\n   - Dependabot for automated dependency updates\n\n5. Build and deployment scripts:\n   - npm scripts for various development and build tasks\n\nWhile the specific CI/CD tool (apart from GitHub Actions) is not explicitly mentioned, the codebase is structured to support automated testing, code quality checks, and potentially automated deployment processes.\n\nIn conclusion, while many infrastructure aspects are implied rather than explicitly defined in the codebase, the application is designed with a modern, cloud-native architecture in mind. It leverages containerization for consistency across environments and is prepared for integration with cloud services and CI/CD pipelines.\n\n# Non-Functional Aspects Report\n\n## Performance and Reliability Aspects\n\n1. Database Optimization:\n   - MongoDB is used for efficient data storage and retrieval\n   - Indexing is implemented for improved query performance\n   - MongoDB connection pooling is utilized for efficient database connections\n\n2. Caching:\n   - Caching of workflow instances and checklist items is implemented to optimize sorting and comparison operations\n   - Redis integration is available for potential caching mechanisms\n\n3. Efficient Data Operations:\n   - Batch operations are used for updating multiple documents\n   - Database-level operations are used for large-scale data updates\n   - MongoDB's native driver is used for efficient database operations\n\n4. Scalability:\n   - Stateless API design allows for horizontal scaling\n   - MongoDB replica sets support read scaling\n   - Containerized architecture supports potential orchestration\n\n5. Concurrency Control:\n   - Distributed locking is implemented for concurrent operations\n   - MongoDB locks are used for managing concurrent write operations\n\n6. High Availability:\n   - MongoDB replica sets are supported for high availability\n\n7. Performance Considerations:\n   - Efficient sorting and grouping of workflow instances and checklist items\n   - Use of async/await for non-blocking operations\n\n8. Graceful Shutdown:\n   - The 'pulse' plugin handles graceful shutdown procedures with a 10-second timeout\n\n## Security Considerations and Potential Vulnerabilities\n\n1. Input Validation:\n   - Joi schemas are used for input validation to prevent injection attacks\n   - MongoDB ObjectId validation is implemented\n\n2. Authentication and Authorization:\n   - JWT authentication is used for API endpoints\n   - Secure context loading for SSL/TLS certificates\n\n3. HTTP Security Headers:\n   - HSTS (HTTP Strict Transport Security) enabled\n   - XSS protection enabled\n   - Content-Type sniffing prevention\n   - X-Frame-Options header set\n\n4. Secure Configuration:\n   - Environment-based configuration for sensitive data\n   - Secure MongoDB connections supported\n\n5. TLS Configuration:\n   - Custom secure context implementation for TLS connections\n   - Dynamic loading of trust store certificates from environment variables\n\n6. Certificate Management:\n   - Support for multiple CA certificates in the trust store\n   - Base64 encoding of certificates in environment variables\n\n7. Proxy Setup:\n   - HTTP proxy setup available for enhanced security\n\n## Volume and Load Considerations\n\n1. Database Scalability:\n   - MongoDB's horizontal scaling capabilities\n   - Efficient indexing for large datasets\n\n2. API Performance:\n   - Stateless API design for horizontal scaling\n   - Caching mechanisms for frequently accessed data\n\n3. Concurrent Operations:\n   - Distributed locking for managing concurrent write operations\n\n4. Large Dataset Handling:\n   - Efficient database-level operations for large-scale updates\n   - Potential need for pagination in API responses for large datasets\n\n## Significant Error Handling and Recovery Mechanisms\n\n1. HTTP-Friendly Error Responses:\n   - Use of Boom for generating standardized HTTP error responses\n\n2. Global Error Handling:\n   - Unhandled rejection handler to prevent crashes\n   - Custom error handling for route validation failures\n\n3. Database Error Handling:\n   - Try-catch blocks around database operations\n   - Specific error handling for common scenarios (e.g., not found, conflicts)\n\n4. Migration Error Handling:\n   - Errors during migrations are caught, logged, and can halt the process to prevent partial migration states\n\n5. Graceful Degradation:\n   - Health check endpoints for monitoring system status\n\n## Logging, Monitoring, and Alerting\n\n1. Logging:\n   - Pino logger used for efficient logging\n   - Support for different log formats (ECS and pino-pretty)\n   - Configurable log levels and redaction for sensitive information\n   - Request logging through hapi-pino plugin\n\n2. Metrics:\n   - AWS Embedded Metrics used for custom metric tracking\n   - Support for counting metrics with configurable names and values\n\n3. Tracing:\n   - Request tracing implemented using @defra/hapi-tracing plugin\n   - Trace IDs incorporated in logs for distributed tracing\n\n4. Monitoring:\n   - Health check endpoint (/health) available for basic monitoring\n\n5. Alerting:\n   - While not explicitly implemented, the logging and metrics infrastructure provides a foundation for implementing alerting systems\n\n## Compliance Considerations\n\n1. Data Governance:\n   - Structured approach to project management and governance\n   - Audit logs for tracking changes and maintaining an audit trail\n\n2. Licensing:\n   - Open Government Licence v3.0 for the project\n\n3. Code Quality:\n   - Integration with SonarCloud for continuous code quality analysis\n   - Strict linting rules enforced\n\n4. Version Control:\n   - Git hooks with Husky for pre-commit checks\n\n## Data and Privacy Considerations\n\n1. Data Protection:\n   - Redaction of sensitive log data in production environments\n   - Secure handling of configuration data\n\n2. Data Integrity:\n   - Use of transactions for data consistency\n   - Strict schema validations for all collections\n\n3. Data Lifecycle Management:\n   - Timestamps (createdAt, updatedAt) on entities for tracking data lifecycle\n\n4. User Data Handling:\n   - Potential handling of user IDs in audit logs, which could be considered sensitive information\n\n## Testing Strategies and Code Coverage\n\n1. Unit Testing:\n   - Jest used as the primary testing framework\n   - Extensive unit tests for utility functions and API endpoints\n\n2. Integration Testing:\n   - API testing implemented using Playwright\n\n3. End-to-End Testing:\n   - E2E tests for API endpoints using Playwright\n\n4. Database Testing:\n   - Jest MongoDB used for database testing\n   - In-memory MongoDB used for consistent test environments\n\n5. Test Coverage:\n   - Jest configured to collect coverage from src/**/*.js\n   - Coverage reports generated in the coverage directory\n\n6. Continuous Integration:\n   - GitHub Actions used for running tests in CI/CD pipelines\n\n7. Test Environment:\n   - Custom setup files for Jest (.jest/setup.js and .jest/setup-after-env.js)\n   - Configurable timeouts for tests\n\n8. Mocking:\n   - Use of jest.mock() for mocking dependencies in tests\n\nThis report provides a comprehensive overview of the non-functional aspects of the codebase, highlighting the system's focus on performance, security, reliability, and maintainability. While many best practices are implemented, there are areas for potential improvement, particularly in explicit security measures and handling of very large datasets.",
  "product_requirements": "# Product Requirements Document\n\n# AI SDLC Governance API Product Requirements Document\n\n## Context\n\nThe AI SDLC Governance API is designed to manage and enforce governance processes throughout the lifecycle of AI projects. It provides a structured approach to creating, managing, and executing governance templates, workflows, and checklists. This system aims to ensure compliance, standardization, and best practices in AI development projects, particularly in government and regulated environments.\n\n## Data Model\n\n```mermaid\nerDiagram\n    GOVERNANCE_TEMPLATE ||--o{ WORKFLOW_TEMPLATE : contains\n    WORKFLOW_TEMPLATE ||--o{ CHECKLIST_ITEM_TEMPLATE : contains\n    GOVERNANCE_TEMPLATE ||--o{ PROJECT : uses\n    PROJECT ||--o{ WORKFLOW_INSTANCE : has\n    WORKFLOW_TEMPLATE ||--o{ WORKFLOW_INSTANCE : instantiates\n    WORKFLOW_INSTANCE ||--o{ CHECKLIST_ITEM_INSTANCE : has\n    CHECKLIST_ITEM_TEMPLATE ||--o{ CHECKLIST_ITEM_INSTANCE : instantiates\n    CHECKLIST_ITEM_TEMPLATE }o--o{ CHECKLIST_ITEM_TEMPLATE : depends_on\n    CHECKLIST_ITEM_INSTANCE }o--o{ CHECKLIST_ITEM_INSTANCE : depends_on\n\n    GOVERNANCE_TEMPLATE {\n        ObjectId _id\n        string version\n        string name\n        string description\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_TEMPLATE {\n        ObjectId _id\n        ObjectId governanceTemplateId\n        string name\n        string description\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_TEMPLATE {\n        ObjectId _id\n        ObjectId workflowTemplateId\n        string name\n        string description\n        string type\n        ObjectId[] dependencies_requires\n        object metadata\n        int order\n        Date createdAt\n        Date updatedAt\n    }\n    PROJECT {\n        ObjectId _id\n        String name\n        String description\n        ObjectId governanceTemplateId\n        ObjectId[] selectedWorkflowTemplateIds\n        Object metadata\n        Date createdAt\n        Date updatedAt\n    }\n    WORKFLOW_INSTANCE {\n        ObjectId _id\n        ObjectId projectId\n        ObjectId workflowTemplateId\n        String name\n        String description\n        Object metadata\n        Number order\n        String status\n        Date createdAt\n        Date updatedAt\n    }\n    CHECKLIST_ITEM_INSTANCE {\n        ObjectId _id\n        ObjectId workflowInstanceId\n        ObjectId checklistItemTemplateId\n        String name\n        String description\n        String type\n        String status\n        ObjectId[] dependencies_requires\n        Object metadata\n        Number order\n        Date createdAt\n        Date updatedAt\n    }\n```\n\n## Features and User Stories\n\n### 1. Governance Template Management\n\n#### 1.1 Create Governance Template\n- Backend API Story\n- As a governance administrator, I want to create a new governance template, so that I can define a standardized structure for AI project governance.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a POST request to `/api/v1/governance-templates` with valid template details\n  - Then a new governance template is created and stored in the database\n  - And the API returns the created template with a 201 status code\n- Architecture Design Notes:\n  - Use Joi for input validation\n  - Ensure unique combination of template name and version\n  - Implement error handling for duplicate entries\n- Related API Endpoint: POST /api/v1/governance-templates\n\n#### 1.2 Retrieve Governance Template\n- Backend API Story\n- As a project manager, I want to retrieve a specific governance template, so that I can view its details and associated workflows.\n- Acceptance Criteria:\n  - Given I am authenticated as a project manager\n  - When I send a GET request to `/api/v1/governance-templates/{id}`\n  - Then the API returns the requested governance template with its associated workflow templates\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement MongoDB aggregation to fetch associated workflow templates\n  - Handle 404 errors for non-existent templates\n- Related API Endpoint: GET /api/v1/governance-templates/{id}\n\n#### 1.3 Update Governance Template\n- Backend API Story\n- As a governance administrator, I want to update an existing governance template, so that I can modify its details or version.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a PUT request to `/api/v1/governance-templates/{id}` with valid update data\n  - Then the governance template is updated in the database\n  - And the API returns the updated template with a 200 status code\n- Architecture Design Notes:\n  - Implement optimistic concurrency control using version numbers\n  - Ensure that the update doesn't create a duplicate name-version combination\n- Related API Endpoint: PUT /api/v1/governance-templates/{id}\n\n#### 1.4 Delete Governance Template\n- Backend API Story\n- As a governance administrator, I want to delete a governance template, so that I can remove outdated or unnecessary templates from the system.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a DELETE request to `/api/v1/governance-templates/{id}`\n  - Then the governance template and all its associated workflow templates and checklist items are deleted from the database\n  - And the API returns a 204 No Content status\n- Architecture Design Notes:\n  - Implement cascading delete for associated workflow templates and checklist items\n  - Use MongoDB transactions to ensure atomicity of the delete operation\n- Related API Endpoint: DELETE /api/v1/governance-templates/{id}\n\n#### 1.5 List All Governance Templates\n- Backend API Story\n- As a project manager, I want to retrieve a list of all available governance templates, so that I can choose an appropriate template for my project.\n- Acceptance Criteria:\n  - Given I am authenticated as a project manager\n  - When I send a GET request to `/api/v1/governance-templates`\n  - Then the API returns a list of all governance templates with their basic details\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement pagination to handle large numbers of templates\n  - Include sorting options (e.g., by name, version, creation date)\n- Related API Endpoint: GET /api/v1/governance-templates\n\n### 2. Workflow Template Management\n\n#### 2.1 Create Workflow Template\n- Backend API Story\n- As a governance administrator, I want to create a new workflow template within a governance template, so that I can define a structured process for project governance.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a POST request to `/api/v1/workflow-templates` with valid workflow details and a governanceTemplateId\n  - Then a new workflow template is created and associated with the specified governance template\n  - And the API returns the created workflow template with a 201 status code\n- Architecture Design Notes:\n  - Validate the existence of the referenced governance template\n  - Automatically assign an order value based on existing workflows in the governance template\n  - Ensure unique names within a governance template\n- Related API Endpoint: POST /api/v1/workflow-templates\n\n#### 2.2 Retrieve Workflow Template\n- Backend API Story\n- As a project team member, I want to retrieve a specific workflow template, so that I can view its details and associated checklist items.\n- Acceptance Criteria:\n  - Given I am authenticated as a project team member\n  - When I send a GET request to `/api/v1/workflow-templates/{id}`\n  - Then the API returns the requested workflow template with its associated checklist item templates\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement MongoDB aggregation to fetch associated checklist item templates\n  - Include the parent governance template information in the response\n- Related API Endpoint: GET /api/v1/workflow-templates/{id}\n\n#### 2.3 Update Workflow Template\n- Backend API Story\n- As a governance administrator, I want to update an existing workflow template, so that I can modify its details or order within the governance template.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a PUT request to `/api/v1/workflow-templates/{id}` with valid update data\n  - Then the workflow template is updated in the database\n  - And the API returns the updated workflow template with a 200 status code\n- Architecture Design Notes:\n  - Handle order changes by updating other workflow templates' orders if necessary\n  - Validate that the new name (if changed) is unique within the governance template\n- Related API Endpoint: PUT /api/v1/workflow-templates/{id}\n\n#### 2.4 Delete Workflow Template\n- Backend API Story\n- As a governance administrator, I want to delete a workflow template, so that I can remove unnecessary steps from the governance process.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a DELETE request to `/api/v1/workflow-templates/{id}`\n  - Then the workflow template and all its associated checklist item templates are deleted from the database\n  - And the remaining workflow templates' orders are adjusted accordingly\n  - And the API returns a 204 No Content status\n- Architecture Design Notes:\n  - Implement cascading delete for associated checklist item templates\n  - Use MongoDB transactions to ensure atomicity of the delete and reorder operations\n- Related API Endpoint: DELETE /api/v1/workflow-templates/{id}\n\n#### 2.5 List Workflow Templates\n- Backend API Story\n- As a project manager, I want to retrieve a list of workflow templates for a specific governance template, so that I can understand the structure of the governance process.\n- Acceptance Criteria:\n  - Given I am authenticated as a project manager\n  - When I send a GET request to `/api/v1/workflow-templates` with a governanceTemplateId query parameter\n  - Then the API returns a list of all workflow templates associated with the specified governance template\n  - And the workflow templates are sorted by their order\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement filtering by governanceTemplateId\n  - Ensure efficient sorting by the 'order' field\n- Related API Endpoint: GET /api/v1/workflow-templates\n\n### 3. Checklist Item Template Management\n\n#### 3.1 Create Checklist Item Template\n- Backend API Story\n- As a governance administrator, I want to create a new checklist item template within a workflow template, so that I can define specific tasks or approvals required in the governance process.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a POST request to `/api/v1/checklist-item-templates` with valid checklist item details and a workflowTemplateId\n  - Then a new checklist item template is created and associated with the specified workflow template\n  - And the API returns the created checklist item template with a 201 status code\n- Architecture Design Notes:\n  - Validate the existence of the referenced workflow template\n  - Automatically assign an order value based on existing checklist items in the workflow template\n  - Implement validation for the 'type' field (e.g., 'approval', 'document', 'task')\n  - Handle the creation of dependencies between checklist items\n- Related API Endpoint: POST /api/v1/checklist-item-templates\n\n#### 3.2 Retrieve Checklist Item Template\n- Backend API Story\n- As a project team member, I want to retrieve a specific checklist item template, so that I can view its details and dependencies.\n- Acceptance Criteria:\n  - Given I am authenticated as a project team member\n  - When I send a GET request to `/api/v1/checklist-item-templates/{id}`\n  - Then the API returns the requested checklist item template with its details and dependencies\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement MongoDB aggregation to fetch dependency information\n  - Include the parent workflow template information in the response\n- Related API Endpoint: GET /api/v1/checklist-item-templates/{id}\n\n#### 3.3 Update Checklist Item Template\n- Backend API Story\n- As a governance administrator, I want to update an existing checklist item template, so that I can modify its details, type, or dependencies.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a PUT request to `/api/v1/checklist-item-templates/{id}` with valid update data\n  - Then the checklist item template is updated in the database\n  - And the API returns the updated checklist item template with a 200 status code\n- Architecture Design Notes:\n  - Validate that the update doesn't create circular dependencies\n  - Handle order changes by updating other checklist item templates' orders if necessary\n  - Implement type-specific validation for metadata updates\n- Related API Endpoint: PUT /api/v1/checklist-item-templates/{id}\n\n#### 3.4 Delete Checklist Item Template\n- Backend API Story\n- As a governance administrator, I want to delete a checklist item template, so that I can remove unnecessary steps from the workflow process.\n- Acceptance Criteria:\n  - Given I am authenticated as a governance administrator\n  - When I send a DELETE request to `/api/v1/checklist-item-templates/{id}`\n  - Then the checklist item template is deleted from the database\n  - And any dependencies referencing this checklist item are updated\n  - And the remaining checklist item templates' orders are adjusted accordingly\n  - And the API returns a 204 No Content status\n- Architecture Design Notes:\n  - Use MongoDB transactions to ensure atomicity of the delete, dependency update, and reorder operations\n  - Implement a check to prevent deletion if the item is referenced by existing project instances\n- Related API Endpoint: DELETE /api/v1/checklist-item-templates/{id}\n\n#### 3.5 List Checklist Item Templates\n- Backend API Story\n- As a project manager, I want to retrieve a list of checklist item templates for a specific workflow template, so that I can understand the detailed steps required in the governance process.\n- Acceptance Criteria:\n  - Given I am authenticated as a project manager\n  - When I send a GET request to `/api/v1/checklist-item-templates` with a workflowTemplateId query parameter\n  - Then the API returns a list of all checklist item templates associated with the specified workflow template\n  - And the checklist item templates are sorted by their order\n  - And the response includes dependency information for each checklist item\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement filtering by workflowTemplateId\n  - Use MongoDB aggregation to include dependency information efficiently\n  - Ensure proper indexing for performance optimization\n- Related API Endpoint: GET /api/v1/checklist-item-templates\n\n### 4. Project Management\n\n#### 4.1 Create Project\n- Backend API Story\n- As a project manager, I want to create a new project based on a governance template, so that I can start managing the governance process for my AI project.\n- Acceptance Criteria:\n  - Given I am authenticated as a project manager\n  - When I send a POST request to `/api/v1/projects` with valid project details and a governanceTemplateId\n  - Then a new project is created and associated with the specified governance template\n  - And workflow instances are created based on the selected workflow templates\n  - And checklist item instances are created for each workflow instance\n  - And the API returns the created project with a 201 status code\n- Architecture Design Notes:\n  - Implement a transaction to ensure all related entities (workflow instances, checklist item instances) are created atomically\n  - Copy metadata and order information from templates to instances\n  - Initialize status fields for workflow and checklist item instances\n- Related API Endpoint: POST /api/v1/projects\n\n#### 4.2 Retrieve Project\n- Backend API Story\n- As a project team member, I want to retrieve a specific project, so that I can view its details and associated workflows.\n- Acceptance Criteria:\n  - Given I am authenticated as a project team member\n  - When I send a GET request to `/api/v1/projects/{id}`\n  - Then the API returns the requested project with its details and associated workflow instances\n  - And the response has a 200 status code\n- Architecture Design Notes:\n  - Implement MongoDB aggregation to fetch associated workflow instances\n  - Include summary information about the completion status of workflows and checklist items\n- Related API Endpoint: GET /api/v1/projects/{id}\n\n#### 4.3 Update Project\n- Backend API Story\n- As a project manager, I want to update an existing project, so that I can modify its details or metadata.\n- Acceptance Criteria:\n  - Given I am authenticated as a project manager\n  - When I send a PUT request to `/api/v1/projects/{id}` with valid update data\n  - Then the project is updated in the database\n  - And the API returns the updated project with a 200 status code\n- Architecture Design Notes:\n  - Implement validation to ensure that critical fields (e.g., govern"
}
